Each Machine on a network is called a Node. A machine could be anything; a computer, a coca-cola machine, whatever.
Whilst a Host is a general-purpose computer. Any Node that is a general-purpose computer, is also a Node.

Every node has a adress, which act like a group of Byte sequences. The more bytes in each adress, the more addresses are available and computers can connect to it.

A protocol is what defines the rules of which computers communicate across the internet, which thus defines the addresses, how data is split into packets, and so on.
There are many different protocols defining different aspects of networking.

for instance, HTTP (Hyper Text Transfer PRotocol) defines how browsers and servers communicate.  Where as of on the other end,
the IEEE 802.3 standard defines a protocol for how bits are encoded as signals on a particular wire.

Networking, is generally split into several layers of abstraction. To which they handle each thing seperately.
The reason for this, is because there are many aspects to networking, such as avoiding colission of packets being sent, 
correct errors, route from host to host, handling different OSes stacked etc.

in theory, each layer only speaks to one above it, one below it.

As long as the interface stays the same, we can change the layers - meaning that we use whatever, Wifi, Ethernet, PPP, etc.

The general structure can be seen as follows:


														The Internet 
															^
													<<<<<<<<v>>>>>>>>>>
													V	   Wifi		  V
												   PPP	    ^		Ethernet
												   	^		v 		  ^   ^
												   	>>>>>>>>V<<<<<<<<<<   V
												   			V 		     ARP
														    v
												    V<<>>>>>IP
													V	  	V
													V	  	V
													V	  	>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
													V	  	V									v
													V	  	V								   ICMP
													V 		V 									^
												   UDP	   TCP 									^
												   	V		^							<<<<<<<< >>>>>>>>
											<<<<<<<<		^							v 				v
											V 				^							V 				V
										<<<<V>>>>			V						Traceroute 		   Ping
										V 		V 			V
									   DNS 	   NFS 			V
									   						V
									   						V
									   			<<<<<<<<<<<<V>>>>>>>>>>>>
									   			V			V 			V
									   			V		   HTTP 		V
									   		   FTP 			V		   SMTP
									   		   				V
									   		   				V
									   		   	<<<<<<<<<<<<V>>>>>>>>>>>>
									   		   	V			V 			V
									   		   	V		  XML-RPC 		V
									   		   SOAP 				  REST APIs


There are several different layer models, each organized to fit each of the particular kind of networks there are.
This book, uses standard TCP/IP four-layer model appropiate for the internet. In this model, Apps like Firefox or Warcraft
run in the app layer and talk only to the transport layer.

The transport layer only talks to the App layer and the internet layer. The Internet layer in turn, only talks to
host-to-network layer and the transport layer, never directly to the app layer.

The host-to-network layer moves the data across the wires, fiber-optic cables, or other medium to the host-to-network layer
on the remote system, which then moves the data up the layers to the APP on the remote system.


App Layer 					<<< Logical Path >>> 			App Layer
Transport Layer (TCP/UDP) 								Transport Layer (TCP/UDP)
Internet Layer (IP) 									Internet Layer (IP)
					V 											^
					V 											^
					>>>>>> Host-To-Network Layer >>>>>>>>>>>>>>>> 
						(Wifi, LTE, Ethernet)
						 Physical Path

For example, when a web browser sends a request to a web server to retrive a page, the browser is actually talking to the transport layer on the local client.
The transport layer breaks it down into TCP segments, add some sequence numbers and checksums to the data, and then passes the request to the local internet layer.

The internet layer fragments the segment into IP datagrams of the necessary size for the local network and passes them to the host-to-network layer for
transmission onto the wire.

The host-to-network layer on the remote system decodes the analog signals into digital data, then passes the resulting IP datagrams to the Server's internet layer.
The internet layer does some simple checks to see that the IP datagrams aren't corrupt, ressembles them if they've been fragmented, and passes them to 
the server's transport layer.

The server's transport layer checks to see that all data has arrived, and re-requests corrupt data pieces. The request then goes back down through
the server's internet layer, through the server's host-to-network layer and back to the client system, where it goes back up to the client's transport layer,
which retransmits the data backdown through the layers.

Once the server's transport layer has recieved enough contigous, sequential datagrams, it reassembles them and writes them onto a stream read by the 
web server running in the server app layer. THe server responds to the request and sends its response back down through the layers on the server
system for transmission back across the Internet and delivery to the web client.

As you can guess, the real process is much more elaborate. The host-to-network layer is the most complicated one, and a lot if it has been deliberately hidden.
For example, it's entirely possible that data sent across the Internet will pass through several routers and their layers before reaching the final destination.

It might be radio waves needing to be converted into electrical signals to light pulses etc.
However, 90% of the time, your Java code will work in the app layer and only need to talk to the transport layer.
The other 10% of the time, you are in the transport layer and talking to the app layer or the internet layer.

The complexity of the host-to-network layer is hidden from you: that's the point of the layer model.

If you read the network litterature, you're likely to encounter an alternative seven-layer model called the Open Systems Interconnection 
(OSI) reference model. For network programs in Java, the OSI model is overkill. The biggest difference between the OSI model and
the TCP/IP model used in this book, is that the OSI model splits the host-to-network layer into data link and physical layers
and inserts presentation and session layers in between the app and transport layers.

The OSI model is more general and better suited for non-TCP/IP networks, although most of the time it's still overly complex.
In any case, Java's network classes only work on TCP/IP networks and always in the application or transport layers, so for the purposes
of this book, absolutely nothing is gained by using the more complicated OSI model.

To the app layer, it seems as if it is talking directly to the app layer on the other system; the network creates a logical path
between the two app layers. It's easy to understand the logical path if you think about an IRC chat session. Most participants in
an IRC chat would say they are talking ot another person.

They might say that they talking to their computer (application layer), which is talking to the other computer, talking ot hteo ther person.

everything beyond one layer deep, is invisible.

In Java, we are pretty high level. In the standard reference model for IP-based Internets (The only kind Java understands), the hidden parts of the
network belongs to the host-to-network layer (Also known as the link layer, data link layer, or network interface layer).

The host-to-network layer defines how a particular network interface - such as an Ethernet card or a WiFi antenna - sends IP datagrams over its
physical connection to the local network and the world.

The part of the host-to-network layer made up of the hardware that connects different computers (wires, fiber-optic cables, radio waves, or smoke signals) is sometimes called
the physical layer of the network. Java, never sees the physical layer. So that is irrelevant to us.

The primary reason we have to think of the host-to-network layer and the physical layer, if you need to about them at all, is performance. For instance,
if your clients reside on fast, reliable fiber-optic connections, you will design your protocol and applications differently than if they're on high-latency satellite connections
on an oil rig in the North Sea.

You'll make still ddifferent chocies if your clients are on a 3G data plan where they're charged by the byte for relativily low bandwith. And if you're writing a 
general consumer app that could be used by any of these clients, you'll try to hit a sweet spot in the middle, or perhaps even detect and dynamically
adapt to individual client capacities. However, whichever physical links you encounter, the APIs you use to communicate across those networks are teh same. Thanks to the Internet Layer.

The next layer of the network, and the first that you need to concern yourself with, is the internet layer. In the OSI model, the intenret layer goes by the more generic name of
network layer. A network layer protocol defines how bits and bytes of data are organized into the larger groups called packets, and the addressing scheme by which different
machines find one another. The Internet Protocol (IP) is the most widely used network layer protocol in the world and the only network layer protocol Java understands.

In fact, there are two : IpV4 (32-bit) and IpV6 (128-bit addresses). Java hides most of the differing interaction regarding these, as they do not interoperate on the same network
without special gateways and/or tunneling protocols.

In both IpV4 and IPv6, data is sent across the internet layer in packets called data-grams. Each IPv4 datagram contains a header between 20 and 60 bytes long
and a payload that contains up to 65,515 bytes of data. (In practice, almost all IPv4 datagrams are much smaller.)

A IPv6 datagram contains a larger header and up to four gigabytes of Data.

The structure of a IPV4 Diagram can be organized as follows:

Bytes

0 				4 			 8 			12 			 16 			20 			24 			28 			31
version 		header len   type of service 		 Datagram length 	

identification 										 flags 			fragment offset

time-to-live (TTL)           protocol 				header checksum

Source address

destination address

Options

Data

Besides routing and addressing, the second purpose of the Internet Layer is to enable different types of Host-to-Network layers
to talk to each other. Internet routers translate between WiFi and Ethernet, Ethernet and DSL, DSL and fiber-optic backhaul protocols,
and so forth. Without the internet layer or something like it, each computer could only talk to other computers that shared 
its particular type of network.

The internet layer is responsible for connecting heterogenous networks to each other using homogenous protocols.

The Transport Layer:

Raw datagrams have some drawbacks. Most notably, there's no guarantee that they will be delivered. Even if they are delivered,
they may have been corrupted in transit. The header checksum can only detect corruption in the header, not in the data portion
of a datagram. Finally, even if the datagrams arrived uncorrupted, they do not nessecarily arrive in the order in which they
were sent.

Individual datagrams may follow different routes from source to destination. Just because datagram A is sent before datagram B
does not mean that Datagram A arrives before B.

The transport layer is responsible for ensuring that packets are recieved in the order they were sent and that no data is lost or corrupted. 
If a Packet is lost, the transport layer can ask the sender to retransmit the packet. IP networks implement this by adding an
additional header to each datagram that contains more information. There are two primary protocols at this level.

The first, The Transmission Control Protocol (TCP), is a high overhead protocol that allows for transmissions of lost or corrupt data
and delivery of bytes in the order they were sent. The second protocol, the User Datagram Protocol (UDP), allows the reciever 
to detect corrupted packets but does not guarantee that packets are delivered in the correct order (at all).

However, UDP is often much faster than TCP. TCP is a reliable protocol, UDP is a unreliable one. Unreliable ones are still very useful.

The Application Layer:

The layer that delivers data to the user is called the app layer. The three lower layers all work together to define how data
is transferred from one computer to another. The application layer decides what to do with the data after it's transferred.

For example, an application protocol like HTTP (for WWW), makes sure that your web browser displays a graphic image as a picture,
not a long stream of numbers. The app layer is where most of the network parts of your programs spend their time.

There is an entire alphabet soup of application layer protocols: in addition to HTTP for the Web, there are SMTP, POP, and IMAP for email.
FTP, FSP, and TFTP for file transfer. NSF for file access. Gnutella and BitTorrent for file sharing.

The Session initaition protocol (SIP) or Skype for voice com. And many more! In addition, your program can
define its own app layer protocols as necessary.

IP, TCP and UDP:

IP, the internet protocol, was made by the Military during the Cold war. It built with intention of circumventing damaged routers, to be Robust.
Thus, it allows for multiple routes between any two points and to route packets of data around damaged routers.

IP is platform independant, as well.

To account for the fact of multiple routers on the way, they layered TCP onto it - To account for damaged packets and to arrange them in relevant order.
TCP, however, carries a distinct overhead. Thus, if the order matters not and small loss does not cause complete corruption, we can use UDP.

We can use UDP for instance for Video or Audio, as small losses does not cause major corruption. Where as of file transfer, has to be safe, cause it is more sensitive.
UDP can incorporate error-correction in the datastreams at the App level, though.

You can run more protocols on top of IP, most commonly being ICMP, to use raw IP datagrams to relay error messages between hosts.
For instance, used to send pings. JAva does not support ICMP (Internet Control Message Protocol), nor does it allow for sending of raw IP datagrams, opposed
to the TCP segments or UDP datagrams. 

The only thing java supports, is TCP and UDP, and application layer protocols built on top of these. All other transport
layer, internet layer and lower layer protocls such as ICMP, IGMP, ARP, RARP, RSVP and others can only be implemented in Java programs
by linking to native code.

IP Adresses and Domain Names:

As a Java programmer, we don't have to care about inner workings of IP, but we do have to worry about addressing. Every computer
on an IPV4 network is identified by a four-byte number. This is normally written in a dotted quad format like 199.1.32.90,
where each of the four numbers is one unsigned byte ranging in value from 0 to 255.

Every computer attached to an IPv4 network has a unique four-byte address. When data is transmitted across the network,
the packet's header includes the address of the machine that sent the packet (the source address).

Routers along the way choose the best route on which to send the packet by inspecting the destination address. The source address
is included so the recipient will know who to reply to.

There are little more than four billion possible IP addresses, not even one for every person on the planet,
much less for every computer. We ran out of IP addresses for places at around 2012, meaning we are starting to integrate into IPv6,
which uses 16-byte addresses. 

IPv6 addresses are custom written as eight blocks of four hexadecimal digits sperated by colons, such as :

FEDC:BA98:7654:3210:FEDC:BA98:7654:3210

Leadings zeros need not be present. A double colon can be present, if we are doing multiple zero blocks, to which
there need only be one double colon.

For example: 0000:0000:0000:0000:00DC:0000:7076:0010 could be written more compactly as: FEDC::DC:0:7076:10. 
In mixed networks of IPv6 and IPv4, the last four bytes of the IPV6 address are sometimes written as an IPv4 dotted quad address.
Which means that we just slam on the Ipv4 on the end of the Ipv6.

In java, we can process the DOmain Name Systems (DNS) (the name of the Hosting places) and the IP adress of said target place,
with a class called java.net.InetAddress.

Some computers, especially servers, have fix addresses. Others, especially clients on local area networks 
and wireless connections, recieve a different address every time they boot up, often provided by a DHCP server.

Mostly you just need to remember that IP addresses may change over time, and not write any code that relies
on a static IP. For instance, don't save the IP when saving app states.

Instead, look it up fresh each time the program starts. It's also possible, while less likely,
that the IP changes during the programs course. (for example if a DHCP lease expires), so you may want
to check the current IP address every time you need it rather than caching it.

Otherwise, the difference between dynamically and manually assigned address is not significant to Java programs.

Several address blocks and patterns are special. All Ipv4 addresses that begin with 10., 172.16. through 172.31 and 192.168.0 are unassigned.
They can be used on internal networks, but no host using addresses in these blocks is allowed on the global internet.

These non-routable addresses are useful for building private networks that can't be seen on the internet. 127.0.0.1 always means the Localhost loopback address.
That means, that regardless of computer, that address always points to the local computer.

In Ipv6, ::1 (or 0:0:0:0:0:0:1) is the loopback address. The 0.0.0.0 always refers to the originating host, but may only be used
as source, not destination.

Simiarly, any Ipv4 that begins with 0, assumes to refer to a host on the same local network.

The Ipv4 address that uses the same number for all 4, such as 255.255.255.255 is a boardcast address. Sending to all computers on the local network,
but not beyond it. It is commonly used for discovery. For instance, when an ephemeral client such as a laptop boots up, it will send a particular
message to the 255.255.255.255 to find the local DHCP server. All nodes on the network recive the packet, but only the DHCP server responds.

In particular, it sends the laptop information about the local network config, including the IP address that laptop should use for the 
remainder of its session and the address of a DNS server it can use to resolve hostnames.

Ports:

Addresses would be all you needed if each computer did no more than one thing at a time. However, modern computers do many
different things at once. Email needs to be separated from FTP requests, which need to be separated from web traffic. This is 
accomplished  through ports. Each computer with an IP address has several thousand logical ports (65,535 per transport layer protocol, to be precise).

They are purea bstractions of the Computers memory, like a USB port. Each port is identified by a number between 1 and 65535. Each port can be
allocated to a particular service.

For example, HTTP, the underlying protocol of the Web, commonly uses port 80. We say that 
a web server listens on port 80 for incoming connections. When data is sent to a web server
on a particular machine at a particular IP address, it is also sent on a particular port (usually 80).

The reciever checks the port of the incoming data pack, and relegates it to a relevant program listening on that port.

Port numbers between 1 and 1023 are reserved for services for well known services, such as finger, FTP, HTTP, and IMAP.
On Unix systems (Linux included), only programs running as root can recieve data from these ports, but all programs may send 
data to them.

On Windows, any program may use these ports without special privileges. A web server may very well not run on 80, tho,
due to needing to run several servers on the same computer, or because the person who install it, does not have the root priv to 
run it on port 80. On UNix systems, you can find a fairly complete list in: etc/services.

The following is a list of wellknown ports that we might end up discussing in this book:

Protocol 		Port 		Protocol 		Purpose

echo 			7 			TCP/UDP 		Echo is a test protocol used to verify that two machines are able to connect by having one echo back the other's input

discard 		9 			TCP/UDP 		Discard is a less useful test protocol in which all data recieved by the server is ignored.

daytime 		13 			TCP/UDP 		Provides an ASCII representation of the current time on the server.

FTP data 		20 			TCP 			FTP uses two well-known ports. This port is used to transfer files.

FTP 			21 			TCP 			This port is used to send FTP commands like put and get.

SSH 			22 			TCP 			Used for encryption, remote logins.

Telnet 			23 			TCP 			Used for interactive, remote command-line sessions.

smtp 			25 			TCP 			The Simple Main Transfer Protocol is used to send email between machines.

time 			37 			TCP/UDP 		A time server returns the number of seconds that have elapsed on the server since midnight,
											January 1, 1900, as a four-byte, unsigned, big-endian integer.

whois 			43 			TCP 			A simple dir service for internet network admins.

finger 			79 			TCP 			Returns info about user/users on the local system.

HTTP 			80 			TCP 			Underlying protocol for WWW

POP3 			110 		TCP 			Post OFfice Protocol version 3 is a protocol for the transfer of accumulated email from the host to sporadically connected clients.

NNTP 			119 		TCP 			Usenet news tranfer; more formally known as the "Network News Transfer Protocol"

IMAP 			143 		TCP 			Internet Message Access Protocol is a protocol for accessing mailboxes stored on a server.

dict 			2628 		TCP 			A UTF-8 encoded dir service that provides definitions of Words.

The internet:

There are localized and disconnected versions (disconnected in that they are local networks), of the INternet, where Companies internalize communications between
computers. Every computer has a IP adress, and many of them at least have one name that maps to that IP.

To account for the unqiuness of IP address allocations, ISPs designated blocks to people.

For instance, if you get 216.254.85 as a prefix, you will be able to use 216.254.85.0 to 216.254.85.255

Because the block fixes the 24 first bits, its called a /24. A /23 specifies the first 23 bits, leaving 9 bits (or 2^9) IP adresses, meaning its 512 local IP adresses.
A /30 is the smallest, with 2 bits, meaning 4 ip addresses.

However, the smallest is 2 - one for the network itself and one for broadcasting.

Network Address Translation:

Most networks today, use something called NAT (Network address translation). In NAT-based networks,
most nodes only have local, non-routable addresses selected from either 10.x.x.x, 172.16.x.x to 172.31.x.x or 192.168.x.x.
The routers that connect the local networks to the ISP translate these local addresses to a much smaller set of routable addresses.

For instance, the dozen or so IP nodes in my apartment all share a single externally visible IP Address. 

And even tho our IP perhaps may be: 192.168.1.5, we'd have to map to a completely other IP (216.254.85.72), which again,
only would get through if the NAT router was configed to pass incoming connections to that IP.

IPv6 makes NAT pointless. However, for IPv4, it actually is so that External packets get converted to local IP targets and local IP targets get converted to the NAT address.

Firewalls are used to filter what kind of packets we accept, we might only accept from a specific domain or we might only allow calls to a specific address.

We can also use something called Proxy Servers, which means that we go through a second hand to which we connect to the external servers - And they cannot trace back from the Proxy to you.
Proxies can also be used for FTP connections and other types.

Firewalls operate on the Internet or transport layer, where as Proxy servers normally operate on the Application layer.
It has a detailed understanding of some application-level protocols, such as HTTP and FTP.  (The notable exception being SOCKS proxy servers that operate at the transport layer, 
and can proxy for all TCP and UDP connections regardless of app layer protocol.)

Packets that pass through the proxy server can be examined to ensure that they contain data appropiate for their type. For instance, 
FTP packets that seem to contain Telnet can be rejected.

Generally Proxy just adds another layer to communicate through, by virtue of adding another "middleman".

If everything is run through the proxy, everything can be tightly monitored to as of what is being done on what computer.
Proxy servers can also be used to cause local caching to speed up transfer interaction.

Which effectively means that it serves a file if its in its cache, if not, it saves it in its cache and sends it forward.

The biggest downside of PRoxy servers is that they do not allow for customized protocols or newer ones.
They may accept HTTP, FTP and SMTP. But not stuff like BitTorrent.

Some, thus, tunnel their applications throug HTTP, most notably with SOAP. However, that does not render support
by the firewall, which means its a security risk.

Applets that run in web browsers normally use the proxy server settings of the web browser itself, though these can 
be overridden in the Java Control Panel. Standalone Java Apps can indicate the proxy server to use by setting the
socksProxyHost and socksProxyport props (if you're using a  SOCKS proxy server),

or http.proxySet, http.proxyHost, http.proxyPort, https.proxySet, https.proxyHost.

There is these prefixes for <>.proxySet, <>.proxyHost and <>.proxyport:

http

https

ftp

gopher

we can set these system priorities from the cmd line if we wish to use protocol-specific-proxies:

java -DsocksProxyHost=socks.cloud9.net -DsocksProxyPort=1080 MyClass

The Client/Server model:

Most oftenly, we use the Client/Server Model, where the server or 
cloud of servers saves the data, whilst the Client handles the program logic.

IN most cases, a server primarily sends data while a client primarily recieves it; but
it is rare for one program to send or recieve exclusively. A more reliable distinction
is that a client initiates a conversation while a server waits for clients to start conversations with it.

In some cases, the same program may be both a client and a server.

Almost all data, aside from the original request for a page, at least on the Web,
is done in direction of Server > Client.

FTP is an older service that fits the client/server model. FTP uses different 
applications protocols and different software, but is still split into FTP servers
that send files and FTP clients that receive files. 

People often use FTP to upload files from the client to the server, so it's harder
to say that the data transfer is primary in one direciton. But it is still true
that an FTP client initiates the connection and the FTP server responds.

The general pattern can be described as follows:


SERVER 									CLIENT

Port 80 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Port 41 232

			Client initiates connection
			to a known port on the server
			from whichever port is 
			avabile on the client

Port 80
(input stream) <<<<<<<<<<<<<<<<<<<<<< Port 41 232 (Output Stream)

Port 80
(Output stream)>>>>>>>>>>>>>>>>>>>>>> Port 41 232 (Input Stream)

		The server accepts the connection
		input and output streams are connected
		to the sockets on the specified ports.


Not all apps work in the client/server model. For instance, in networked
games, both send to each other.

This, usually then, denotes a peer to peer connection. 

Java per say does not provide peer-to-peer communication in its core networking API.
However, apps can easily offer peer-to-peer communications in several ways,
most commonly by acting as both a server and client.

Alternatively, the peers can communicate with each other through an intermediate
server program that forwards data from one peer to other peers. This solves the problem
of how two peers finde ach other.

Internet Standards:

This book discusses several application layer Internet protocols, most notably HTTP.
However, this is not a book about those protocols. if you need detailed info
about said protocols, go to documentation.

The two biggest companies relevant for standards of the internet, is W3C and IETF (Internet Engineering Task Force).
IETF is a open, informal, democratic body that bases itself on rough consensus and working code and tend to
follow rather than lead implementations.

IETF standards hold up to TCP/IP, MIME, and SMTP. 

W3C is a vendor organization, controlled by paying co-orporations. They define standards
in advance of implementation. They include HTTP, HTML and XML.

IETF RFCs:

These are finished works on the current process of things.
They are not open for comments, as the ones that are, are called INternet Drafts.

They are a good source of specific info about protocols.

Before an RFC is written, a working prototype must exist.

RFC 			Title 					Desc

RFC 5000 		Internet Official 		Describes the standardization process and the current status of the different
				Protocol Standards 		Internet Protocols. Periodically updated in new RFCs.

RFC 1122 		Host Requirements 		Documents the protocols that must be supported by all Internet hosts at different
RFC 1123 								layers (data link layer, IP layer, transport layer, and app layer)

RFC 791 		Internet Protocol 		The IP internet layer protocol
RFC 919
RFC 922
RFC 950

RFC 768 		User Datagram Protocol 	An unreliable, connectionless transport layer protocol.

RFC 792 		Internet Control 		An internet layer that uses raw IP datagrams but is not supported by Java 
				Message  				its most familiar uses are ping and traceroute
				Protocol (ICMP)

RFC 793 		Transmission Control 	A reliable, connection-oriented, streaming transport layer protocol.
				Protocol

RFC 2821 		Simple Main Transfer 	The app layer protocol by which one host transfers email to another host.
				Protocol 				This standard doesn't say anything about email user interfaces; it covers the
										mechanism for passing email from one computer to another.

RFC 822 		Format of Electronic 	The basic syntax for ASCII text email messages. MIME is designed to extend this to
				Mail Messages 			support binary data while ensuring that the messages transfered still conform
										to this standard.

RFC 854, 		Telnet Protocol 		An app layer remote login service for command-line env based around an abstract
RFC 855 								network virtual terminal (NVT) and TCP.

RFC 862 		Echo Protocol 			An app layer protocol that echoes back all data it recieves over both TCP and
										UDP; useful as a debugging tool.

RFC 863 		Discard Protocol 		An app layer protocol that recieves packets of data over both TCP and UDP
										and sends no response to the client; useful as a debugging tool.

RFC 864 		Character Generator 	An app layer protocol taht sends a indefinite ASCII sequence of chars to any client that connects over TCP or UDP.
				Protocol 				Useful for Debugging.

RFC 865 		Quote of the Day 		App layer protocol that sends a quote of the day and then closes connection.

RFC 867 		Daytime Protocol 		An app layer protocol that sends a human-readable ASCII string indicating 
										the current date and time at the server to any client that connects over TCP or UDP.
										Contrats to other NTP and Time Server protocols, whom do not return a human friendly reading format.

RFC 868 		Time Protocol 			An app layer protocol that sends the time in seconds since midnight, January 1, 1900, to a client
										connecting over TCP or UDP. The time is sent as machine-readable, 32-bit unsigned int.
										The standard is incomplete, in taht it does not specify how the int is encoded in 32 bits,
										but in practice a big-endian int is used.

RFC 959 		File Transfer 			An optional authenticated, two-socket app layer protocol for file transfer that uses TCP. 
				Protocol 

RFC 977 		Network News 			The app layer by which Usenet news is transferred from machine to machine over TCP;
				Transfer Protocol 		used by both news clients talking to news servers and news servers talking to each other.

RFC 1034, 		Domain Name System 		The collection of distributed software by which hostnames that human beings can 
RFC 1035								remember, like www.orelly.com, are translated into numbers that computers can 
										understand, like 198.112.201.11. This RFC defines how DNS servers on different
										hosts communicate with each other using UDP.

RFC 1112 		Host Extensions  		The internet layer methods by which conforming systems can direct a single packet
				for IP Multicasting 	of data to multiple hosts. This is called multicasting.  Java supports this.

RFC 1288 		Finger Protocol 		An app layer protocol for requesting info about a user at a remote site.
										it can be a security risk.

RFC 1305 		Network Time Protocol 	A more precise app layer protocol for synching clocks between systems that attempt to account for latency.
				(V3)

RFC 1939 		Post Office Protocol 	A app layer protocol used by sporadically connected email clients such as Eudora to retrieve mail from a server over TCP.

RFC 1945 		HTTP 1.0 				Version 1.0 of the application layer protocol used by web browser talking to web servers over TCP. Developed by w3c, not IETF.

RFC 2045, 		Multipurpose Internet 	A means of encoding binary data and non-ASCII text for transmission through Internet email and other ASCII-oriented protocols.
RFC 2046, 		Mail Extensions
RFC 2047

RFC 2141 		Uniform Resource Names 	Similar to URLs but intended to refer to actual resources in a persistent fashion rather than the transient location of those resources.
				(URN) Syntax

RFC 2616 		HTTP 1.1 				V1.1 of app layer protocol used by web browsers talking to web servers over TCP.

RFC 2373 		IP V6 Addressing 		The format and meaning of IPv6 adresses.
				Architechture

RFC 3501 		Internet Messages 		A protocol for remotely accessing a mailbox stored on a server including downloading messages, deleting messages, and moving messages into and out of different folders.
				Access Protocol
				V 4rev1

RFC 3986 		Uniform Resource 		Similar to URLs but cut a broader path. For instance, ISBN numbers may be URIs even if the book  cannot be retrieved over the Internet.
				identifiers (URI);
				Generic Syntax

RFC 3987 		Internaitonalized 		URIs that can contain non-ASCII chars. 
				Resource Identifiers
				(IRIs)

Whilst IETF managed to standardize a lot of the Internet things, the Web, they failed colossaly with, due to historical ignorance and refusal of other parts.

Thus, W3C was formed.

In it's wake, W3C has made web standards, albeit bigget parts like Mozilla and Microsoft refuse to abide this corporation.

The 5 basic W3C level of standards:

1. Note:
A note is generally one of two things: either an unsolicited submission by a W3C member (similar to an IETF Internet Draft) or random musings by
W3C staff or related parties that do not actually describe a full proposal (Similar to an IETF informational RFC). Notes will not nessecarily 
lead to the info of a working group or a W3C recommendation.

2. Working Drafts:
A reflection of the current thinking of some of the W3C staff. it should eventually lead to a propsoed reocmmendation, but might change a lot during the way.

3. Candidate Recommendation:
A candidate recommendation indicates that the working group has reached consensus on all major issues and is ready for third-party comment and implemetnations.
If the implementations do not uncover any obstructions, the spec can be promoted to a candidate recommendation.

4. Proposed Recommendation:

A proposed recommendation is mostly complete and unlikely to undergo more than minor editorial changes. The main purpose of a propsoed recommendation
is to work out bugs in the specification document rather than in the underlying tech being documented.

5. Recommendation:

A recommendation is the highest level of W3C standard. However, the W3C is very careful to not actually call this a standard, for fear of running afoul
on distrust issues. It is just a recommendation they reached.

STREAMS:

A large part of network programs, is just handling input and output: moving bytes from one system to another.

In Java, we use streams to write and read data. We can chain filter streams unto them as well, creating compression, modification or encryption to the data written or read.

Normal streams are Synch, but there are Asynch I/O streams as well. The Asynch version uses channels and buffers, and build on Streams, but we will cover Streams first.

For webservers, non-blocking I/O's are more efficient in higher volumes.

Basic streams is what we should use for clients, regardless.

The java.io.OutputStream is we class we use, and it has the following methods:

public abstract void write(int b) throws IOException ///takes a int between 0 and 255 to write as a byte

public void write(byte[] data) throws IOException

public void write(byte[] data, int offset, int length) throws IOException

public void flush() throws IOException

public void close() throws IOException

We then use particular writers for particular forms of media: 

FileOutputStream : For files

TelnetOutputStream : over network connections

ByteArrayOutputStream : writes data to expandable Byte arrays

Generally, we will just end up using OutputStream, because more specific streams do occur, but they are delibaretely hidden or put into other packages.

The reason write is abstract, is because inheriting classes need to define how its to handle their medium.

For instance, a ByteArrayOutputStream can implement this method with pure Java code that copies the byte into its array. However, a FileOutputStream
will need to use native code that understands how to write data in files on the host platform.

The 0-255 int is just a representation of a unsigned int, as a 8 bits number to be sent on the wire.

An example of implementing the writing method of 72-chars line:

public static void generateCharacters(OutputStream out) throws IOException{
	
	int firstPrintableCharacter = 33;
	int numberOfPrintableCharacters = 94;
	int numberOfCharactersPerLine = 72;

	int start = firstPrintableCharacter;
	while (true){
		for (int i = start; i < start + numberOfCharactersPerLine; i++){
			out.write((
				(i - firstPrintableCharacter) % numberOfPrintableCharacters) + firstPrintableCharacter);
		}
		out.write('\r'); //Carriage return
		out.write('\n'); //new line
		start = ((start + 1) - firstPrintableCharater) % numberOfPrintableCharacters + firstPrintableCharacter);
	}
}

The code terminates on closing connection, seeing it as a IOException. ugly way of handling it.

In terms of sending to the server, it has intervals of buffered amounts that must be overstepped to actually cause a sending. 
Albeit, normally it is so that there is a 40 byte overhead of routing and error correction. + host-to-network layer protocol.

Meaning that if we just sent bytes 1 by 1, it'd be terrible.

An example, would be this follow example, where we write a line at a time, instead:

public static void generateCharacters(OutputStream out) throws IOException
{
	int firstPrintableCharacter = 33;
	int numberOfPrintableCharacters = 94;
	int numberOfCharactersPerLine = 72;
	int start = firstPrintableCharacter;
	byte[] line = new byte[numberOfCharactersPerLine + 2]; //+2 for carriage return and /n

	while(true){
		for (int i = start; i < start + numberOfCharactersPerLine; i++){
			line[i - start] = (byte) ((i - firstPrintableCharacter) % numberOfPrintableCharacters + firstPrintableCharacter);
		}
		line[72] = (byte) '\r';
		line[73] = (byte) '\n';
		out.write(line);
		start = ((start + 1) - firstPrintableCharacter) % numberOfPrintableCharacters + firstPrintableCharacter;
	}
}

We can circumvent threshholds by virtue of running a flush, forcing the stack to empty and send it's data.

Streams can also be buffered in software, directly in Java code as well as in the network hardware. Typically, this is 
accomplished by chaining a BufferedOutputStream or a BufferedWriter to the underlying stream, a technique we'll explore shortly.

Consequently, if you are done writing data, it's important to flush the output stream. For example, suppose you've written a 300-byte request
to an HTTP 1.1 server that uses HTTP Keep-Alive. You generally want to wait for a response before sending any more data.

However, there might be implacations that the data will be sent when a response of the server is received, albeit you won't get one 
cause you ahve not triggered the limit. That, is when you flush, to force a dispatch ot hte server.

NOTE: Flush all streams after you are done with them. And close it.

Some streams, can have their remaining data converted to their respective data forms, even if closed.

An example of handling a output stream is as follows:

OutputStream out = null;
try{
	out = new FileOutputStream("/tmp/data.txt");
	//Work with the contents
} catch (IOException ex){
	System.err.println(ex.getMessage());
} finally {
	if (out != null){
		try{
			out.close();
		} catch (IOException ex) {
			//ignore
		}
	}
}

The above is called the disposal pattern, to which is the normalized way of how we handle processing of streams. Declare them outside, see if they're not null, and close them.

We could also do a try with resources if we wish:

try (OutputStream out = new FileOutputStream("/tmp/data.txt")){
	//Work with the output stream
} catch (IOException ex){
	System.err.println(ex.getMessage());
}

Input streams use the following methods:

public abstract int read() throws IOException
public int read(byte[] input) throws IOException
public int read(byte[] input, int offset, int length) throws IOException
public long skip(long n) throws IOException
public int available() throws IOException
public void close() throws IOException

Concrete subclasses of InputStream use these methods to read data from particular media.
For instance, a FileInputStream reads data from a file. A TelenetInputStream
reads data from a network connection. A ByteArrayInputStream reads data from array of bytes.

The read method returns the byte data as a value from 0 to 255. In case it's EOF, it returns -1.

I/O can be slow, thus, delegate it to other than the main thread of processing.

The read() method is abstract, due to that we need to adapt ot the medium ourselves.
a ByteArrayInputStream can implement this method with pure Java code, however, a TelenetInputStream needs to use
a native library that understands how to read data from the network interface on the host platform.

To convert a unsigned bit, we just perform a ternary operator check on the values.

read() returns a int, instead of a byte.

As per before, there are overloaded versions which allow for more reading at once.

The first trying to full the input byte array, the other starting at offset and continuing for length into the array.

Sometimes not all the bytes are ready and in place, so, we have to make accounting logic for the situations where they are not ready or available.

An example:

int bytesRead = 0;
int bytesToRead = 1024;
byte[] input = new byte[bytesToRead];
while (bytesRead < bytesToRead){
	bytesRead += in.read(input, bytesRead, bytesToRead - bytesRead);
}

The above technique is especially good when reading from networks, that can be slower than CPUs. Leading to that
they might empty the buffer before all the data has arrived. 

However, the last byte will always be -1, as that is EOF. However, the above might run forever, since it might never arrive and it does not account for the -1 on the end,
so to fix that:

int bytesRead = 0;
int bytesToRead = 1024;
byte[] input = new byte[bytesToRead];
while (bytesRead < bytesToRead){
	int result = in.read(input, bytesRead, bytesToRead - bytesRead);
	if (result == -1) break;
	bytesRead += result;
}

We can also, just settle for the minimum, with running available() to determine how many can be read.

Example:

int bytesAvailable = in.available();
byte[] input = new byte[bytesAvailable];
int bytesRead = in.read(input, 0, bytesAvailable);

At EoF, available returns 0. And if the length of the array is 0, it will also return 0.

As per expected, we can skip things by skip() and we must always close the connection after we are done reading stuff.

We can, beyond this, mark and reset on InputStreams, with the following methods:

public void mark(int readAheadLimit)
public void reset() throws IOException
public boolean markSupported()

Mark is like a pointer of which it will return to. The readAheadLimit defines how far back you can go to re-read the data. Reset triggers the reset to point.
There can only be one Mark, at a time.

To check if they support this behavior, just run markSupported().

Usually the way of implementation is that it stores it in a internal buffer. 

The only input streams that always support this behavior in java.io is BufferedInputStream and ByteArrayInputStream.

However, others, such as TelnetInputStream may support it as well, if they're chained to a buffered input stream first.

Filter Streams:

InputStream and OutputStream are fairly raw classes. They read and write bytes singly or in groups, but that's all.

However, we also have filterStreams. And fact is, a lot of the time, the data we encounter, is the same format, so we can filter them or
target them, as they are usually as follows:

network protocols ints are usually 32-bit big-endian integers.

Most ASCII is 7-bit ASCII, 8-bit Latin-1 or multibyte UTF-8.

Many files transfered by FTP are stored in the ZIP format.

Java also provides a number of filter classes to append to raw streams to filter them.

The filters come in two versions: filter streams, and readers/writers.

filter streams deal with compression, or interpetation as binary numbers.

Readers and Writers handle special case of text in a variety of encodings such as UTF-8 and ISO 8859-1.

In the following example, a compressed and encrypted text file arrives from the local network interface, where native code
presents it to the undocumented TelnetInputStream. A BufferedInputStream buffers the data to speed up the entire process.
A CipherInputStream decrypts the data.

A GZIPInputStream decompresses the deciphered data. An InputStreamReader converts the decompressed data to Unicode text. 
Finally, the text is read into the app and processed:

					raw compressed encrypted data  						  buffered compressed encrypted data  						buffered, compressed data  					 buffered Data 							Text
TelnetInputStream >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> BufferedInputStream >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> CipherInputStream >>>>>>>>>>>>>>>>>>>>>>>>>>>>> GZIPInputStream >>>>>>>>>>>>>>>>>> InputStreamReader >>>>>>>>>>>>>>>>>>> App


The filters overall have the same write, close and flush interactions, albeit some of them have a bit more than that, at times.
There are moments when they have completely different methods, but thoose are notable examples like BufferedInputStream and BufferedOutputStream or PushbackInputStream (which has unread()).

Filters are connected to streams by their constructors. For example:

FileInputStream fin = new FileInputStream("data.txt");
BufferedInputStream bin = new BufferedInputStream(fin);

NOTE: always use the last filter to read and write with.

One way to assert this, is to overwrite the earlier reference:

InputStream in = new FileInputStream("data.txt");
in = new BufferedInputStream(in);

The reason we do like this, is two fold - We can do it because both inherit from the same superclass,
and it causes overriding so that we can't re-read from the same place of which has closed connection, so we cannot accidentaly read from it and corrupt the buffer.

The reason it also works, is because we do not need access to further differentiating methods. But in case we would need to explicitly have a different one, we could do as follows, where we put a new stream in another one into another one:

DataOutputStream dout = new DataOutputStream(new BufferedOutputStream(new FileOutputStream("data.txt")));

NOTE: The connection is permanent. Filters CANNOT be removed, from a stream, once applied.

There are times when we need to access methods of several different methods of different streams due to sequencing of processing data or due to ordering
of which we wish to do things, as follows:

Reading a unicode text file, wishing to read the byte order mark in the first three bytes to determine wether file is encoded as big-endian UCS-2, little-endian UCS-2 or UTF-8, and then
matching Reader filter for the encoding.

Or

if we're connected to a web server, maybe we wish to read the header the server sends to find the Content-encoding and then use that content encoding to pick the
right Reader filter to read the body of the response.

or

Send a floating-point number across a network connection using a DataOutputStream and then retrieve a MessageDigest from the DigestOutputStream that the 
DataOutputStream is chained to.

In all of these cases, we need to save and use references of said streams, but we should ALWAYS just read and write, from the last Stream in the chain.

Buffered Streams:

The BufferedOutputStream class stores written data in a buffer (a protected byte array field named buf) until the buffer is full or the stream is flushed.
Then it writes the data onto the underlying output stream all at once. A single write of many bytes is almost always faster than many small pieces chaining to do the same thing.

This is especially true of network connections because each TCP segment or UDP packet carries a finite overhead, generally about 40 bytes of worth.

Generally, network cards and TCP implementations provide some level of buffering themselves. Thus, we should always run with buffers, as it is a performance win.

The interaction of reading is still on the point of that it attempts to access the buffer first, in BufferedOutputStream, to which it if it cannot,
reads everything it can into the buffer and then takes it from there.

BufferedInputStream has two constructors, as follows, one overloaded version each:

public BufferedInputStream(InputStream in)

public BufferedInputStream(InputStream in, int bufferSize)

public BufferedOutputStream(OutputStream out)

public BufferedOutputStream(OutputStream out, int bufferSize)

The default sizing of the buffer size, is 512 bytes for an Output stream and 2,048 for a input stream.

The ideal size of a buffer depends on the stream. For a Network connection, you want to have a little bit larger than the typical packet size.
This can be hard to predict, because of speeds of the connection and situation of protocols etc. - But generally, it is so that TCP segments
are no larger than a kilobyte, usually.

a BufferedInputStream does not declare any new methods of its own. It only overrides methods from InputStream.
It does support markin and resetting.

The two multiByte read() method attemps to read until the specified array as many times as is nessecary.

It will only stop for the following reasons:

It is full.

EOF reached.

or the underlying stream would block on further reads.

The differential here being that it keeps reading repeatedly comparedly to others.

BufferedOutputStream works in the way of placing data in the output buffer, rather than in the stream.
Thus, it is nessecary to flush the stream when you reach a point at which the data needs to be sent from the Buffer.

Akin to printing, we thus have the PrintStream, which is the System.out.println for instance.
This form of stream works akin to Outputstreams - And should explicitly be flushed.

However, there is a overloaded argument for autoflushing - Albeit, like i said, it should be done explicitly. For security reasons.

The print methods and println methods of the outputStream is 9-10 overloaded methods for each type, meaning booleans, chars, ints, double etc.

PrintStream is a bad thing to use in Networking connections, due to that it appends \n, when some protocols like HTTP or Gnutella require you to put a end carriage \r or linefeed pair \r\n,
which means that printLn might work on windows when writing network streams, but not on Unix or Mac.

The second problem is the fact of that it defaults to encoding of the System platforms encoding. Meaning, that whilst the Server might expect UTF-8 or UTF-16,
it might print completely other encoded formats, to which the Server won't handle them.

The last problem, is how PrintStreams flag errors. They use a outdated form of flaggning system that once set, cannot be unset - and they also eat all the exceptions encountered their way.
Meaning they do not throw an exception, upon failing - more so than they flag for it and no further thing is processed with it.

Meaning, that we should just not use PrintStreams for Network connections, because Network connections CAN and WILL at times, fail.

Data streams, both input and output, are used for parsing out numbers of Java by converting primtive or string data, into Binary formats.
The encoding of which they use, 32 bit big-endian ints, are just like Java's int data type.

Thus, it can happen that the protocols we use, use the same encoding as these.

The controlled-load network element service uses 32-bit IEEE 754 floating point numbers,
just like Java's float data type.

However, it does not apply to everything, such as NTP (Network Time Protocol), which uses 64 bit unsigned fixed point numbers with the int part in the first 32 bits
and the fraction part in the last 32 bits. It does not conform to any of the primtive data type formats of any programming language, but is straight forward to work with in regards of NTP.

as far as dataStreams go in java, they can be as follows:

public final void writeBoolean(boolean b) throws IOException

public final void writeByte(int b) throws IOException

public final void writeShort(int s) throws IOException
//etc for char and numbers

public final void writeChars(String s) throws IOException

public final void writeBytes(String s) throws IOException

public final void writeUTF(String s) throws IOException

All data is written in big-endian format. Ints are written in two's complement in the minimum number of bytes possible.

Thus, a byte is written as one byte, short as two, int as four, long as eight, floats and doubles is 4 and 8 respectively, etc.

Booleans are 0 or 1 (false and true), Chars are two unsigned bytes.

The last 3 are a bit more complicated.

the writeChars() iterates through the String arg, writing each char in turn as a two-byte, big-endian Unicode char (a UTF-16 code point)

the writeBytes() writes the least significant byte, but this causes loss of chars outside of Latin-1 charsets. Thus, avoid it. It is only useful
on some network protocols that specify ASCII encoding.

Neither writeChars() nor writeBytes() encodes the length of the string in the output. Thus, we can't distinguish between carriage returns or linefeeds and just the string.

The writeUTF(), does, however, specify the length. It uses a variant of UTF-8, which makes it non-compatible for a lot of other languages. Meaning this should only be used
to pipe data from Java platform to Java Platform, that use a DataInputStream to read strings.

For exchanging UTF-8, just use a Input StreamReader with appropicate encoding for other cases.

The rest is as per expect, the output streams having write(), flush(), close()

and the Input streams having read(), available(), skip(), close()

There are 9 read methods of OutputStreams, whilst read of writing bytes and reading of writing Chars is handeled one at a time, at least for chars, Bytes is just done bytestyle.

There are two relevant cases tho, that does not come from Java, but can come from C related things:

public final int readUnsignedByte() throws IOException

public final int readUnsignedShort() throws IOException

DataInputStream has the usual two multibyte read() methods that read into an array or subarray and return the 
number of bytes read. It also has two readFully() methods that repeatedly read data from the underlying input stream into
an array until the requested number of bytes have been read.

If enough data cannot be read, then an IOException is thrown. These methods are especially useful when you know in advance
exactly how many bytes you have to read. This might be the case when you've read the Content-length field out of an HTTP header and thus
know the lenght.

public final int read(byte[] input) throws IOException

public final int read(byte[] input, int offset, int length) throws IOException

public final void readFully(byte[] input) throws IOException

public final void readFully(byte[] input, int offset, int length) throws IOException

Note, there is one more, but because of it being deprecated due to failure of recognizing carriage returns and what not, i will not write it.

A lot of the time, coders have a bad habbit of assuming that everything would run in the native code format of ASCII.

The problem is twofold - platforms support different things, and the rule of chars being bytes when broken down, does not uphold true,
upon the facing of the fact that it's not longer ASCII chars.

The general superclasses of said writers and readers, is the java.io.Reader and java.io.Writer.

Readers and writers can be applied to other reads and writers to provide additional services or interfaces.

The general idea is the fact of that having subclasses that target specific things in regards to reading nad writing..

There are some classes that allow for raw reading without a stream, though, as follows:

Filereader

Filewriter <^ work with files

StringReader <v work with Java

StringWriter

CharArrayReader

CharArrayWriter

Writers:

The Writer class mirrors the java.io.OutputStream class. It's abstract and has two
protected constructors. Like OutputStream, the Writer class is never used directly.

Instead, it is used polymorphically, through one of it's subclasses. It has five write()
methods as well as flush() and a close() method:

protected Writer()

protected Writer(Object lock)

public abstract void write(char[] text, int offset, int length) throws IOException //All of the write methods derive from this, albeit this must be overwritten in the child class

public void write(int c) throws IOException

public void write(char[] text) throws IOException

public void write(String s) throws IOException

public void write(String s, int offset, int length) throws IOException

public abstract void flush() throws IOException

public abstract void close() throws IOException

Some examples of interactions with writers:

char[] network = {'N', 'e', 't', 'w', 'o', 'r', 'k'};
w.write(network, 0, network.length);

The same can be accomplished with:

w.write(network);
for (int i = 0; i < network.length ; i++) w.write(network[i]);
w.write("Network");
w.write("Network", 0, 7);

Depending on what bytes and what order they are written in, is defined by the encoder which you choose.

If we are using big-endian UTF-16 it will write the following 14 bytes:

00 4E 00 65 00 74 00 77 00 6F 00 72 00 6B

On the other hand, if we use little-endian UTF-16 this sequence of 14 bytes is written:

4E 00 65 00 74 00 77 00 6F 00 72 00 6B 00

If we use Latin-1, UTF-8 or MacRoman this sequence of 7 bytes is written:

4E 65 74 6F 72 6B

Writers may be buffered, either directly by being chained to a BufferedWriter or indirectly because their
underlying output stream is buffered. To force a write to commited to the output medium, invoke the flush() method:

w.flush();

The close() method flushes the connection and then closes it and releases the underlying resources.

OutputStreamWriter is the most important concrete subclass of Writer. An OutputStreamWriter recieves chars
from a Java program. it converts these into bytes according to a specified encoding and writes them onto an underlying
output stream.

It's constructor is as follows:

public OutputStreamWriter(OutputStream out, String encoding) throws UnsupportedEncodingException

Valid encodings are listed in the documentation for Sun's native2ascii included with the JDK.
If no encoding is specified, the default encoding for the platform is used. In 2013, the default encoding is
UTF-8 on the Mac and more often than not on Linux.

However, on Linux it can vary if the local operating system is configured to use some other character set by default.
On windows, it varies depending on country and configuration, but in the US it's Windows-1252 a.k.a CP1252 more often than not.

Default char sets can cause unexpected problems at unexpected times. You're generally almost always better off
explicitly specifying the character set rather than letting Java pick one for you.

For example, this code fragment writes the first few words of Homer's Odyssey in the CP1253 Windows Greek encoding:

OutputStreamWriter w = new OutputStreamWriter(new FileOutputStream("OddyseyB.txt"), "Cp1253");
w.write(); //Cyrellian letters should go here, but i dont have the char set on this keyboard or installed, atm, i think

the OutputStreamWriter can also return the encoding of the object:

public String getEncoding()

Readers:

The Reader class mirrors the java.io.InputStream class. It's abstract with two protected constructors.
Like InputStream and Writer, the Reader class is never used directly, only through one of its subclasses.

It has three read() methods, as well as skip(), close(), ready(), mark(), reset() and markSupported():

protected Reader()

protected Reader(Object lock)

public abstract int read(char[] text, int offset, int length) throws IOException

public int read() throws IOException

public int read(char[] text) throws IOException

public long skip(long n) throws IOException

public boolean ready()

public boolean markSupported()

public void mark(int readAheadLimit) throws IOException

public void reset() throws IOException

public abstract void close() throws IOException

Most of the methods explain themselves.

The Read() returns a single Unicode char as a int with a value from 0 to 65,535 or -1 on EOF.
(Technically a UTF-16 code point)

the read(char[] text) method tries to fill the array text with chars and return the actual number of chars read or -1 on EOF.

The read(char[] text, int offset, int length) methods attempts to read length chars into the subray of text beginning
at offset and continuing for length chars. It also returns the number of chars read or -1 on EOF.

The skip(long n) skips n chars.

mark(int readAheadLimit) marks with X ahead

mark() and reset() acts as per expected with marking and resetting

The rule of exception in this case, is the ready() method which has teh same general purpose as available() but not quite the
same semantics, even modulo the byte-to-char-con version.

Whereas available returns the amount of bytes available before blocking, ready() only returns if it can be read, without blocking.

the problem is that some chars encodings, like UTF-8 use different numbers of bytes for different chars. Thus,
it's hard to tell how many chars are waiting in the network or filesystem buffer without reading them out of the buffer.

InputStreamReader is the most important concrete subclass of Reader. An Input StreamReader reads bytes from an underlying input stream
such as a FileInputStream or TelnetInputStream. It converts these into chars according to a specified encoding and returns them.

The constructor specifies the input stream to read from and the encoding to use:

public InputStreamReader(InputStream in)

public InputStreamReader(InputStream in, String encoding) throws UnsupportedEncodingException

If no encoding is specified, the default encoding for the platform is used. If an unknown 
encoding is specified, an UnsupportedEncodingException is supported.

For example, this methods reads an input stream and converts it all to one Unicode string
using the Macryllic encoding:

public static String getMacCryllicString(InputStream in) throws IOException
{
	InputStreamReader r = new InputStreamReader(in, "MacCryllic");
	StringBuilder sb = new StringBuilder();

	int c;
	while ((c = r.read()) != -1) sb.append((char) c);
	return sb.toString();
}

Filter Readers and Writers:

The InputStreamReader and OutputStreamWriter classes act as decoration on top of Input and Output streams
that change the interface from a byte-oriented interface to a character-oriented interface.

Once this is done, additional character-oriented filters can be layered on top of the reader or writer
using the java.io.FilterReader and java.io.FilterWriter classes. As with filter streams, there are a variety of 
subclasses that perform specific filtering, including:

BufferedReader

BufferedWriter

LineNumberReader

PushbackReader

PrintWriter

The BufferedReader and BufferedWriter classes are the character-based equviilants of the byte-oriented
BufferedInputStream and BufferedOutputStream classes. Where BufferedInputStream and BufferedOutputStream use 
an internal Array of bytes as a buffer, BufferedReader and BufferedWriter use an internal array of chars.

When a program reads from a BufferedReader, text is taken from the buffer rather 
than directly from the underlying input stream or other text source. When the buffer
empties, it is filled again with as much text as possible, even if not all of it is immedeatly needed, making future reads much faster.

When a program writes writes to a BufferedWriter, the text is placed in the buffer. The text is moved to the underlying
output stream or other target only when the buffer fills up or when the writer is explicitlly flushed.

This is per as the normal interactin of the Buffer of Buffered streams.

BufferedReader and BufferedWriter have the usual methods associated with readers and writers, like read(), ready(), write(), and close().
They each have two constructors that chain the BufferedReader or BufferedWriter to an underlying reader or writer and set the size of the buffer.

If the size is not set, the default size of 8,192 chars is used:

public BufferedReader(Reader in, int bufferSize)

public BufferedReader(Reader in)

public BufferedWriter(Writer out)

public BufferedWriter(Writer out, int bufferSize)

For example, the earlier getMacCyrillicString() example was less than efficient because it read characters one at a time.
Because MacCyrillic is a 1-byte char set, it also read bytes one at a time. However, it's straightforward to make it run faster
by chaining a BufferedReader to the InputStreamReader like this:

public static String getMacCyrillicString(InputStream in) throws IOException
{
	Reader r = new InputStreamReader(in, "MacCyrillic");
	r = new BufferReader(r, 1024); //Just run a BufferReader on the INputStreamReader
	StringBuilder sb = new StringBuilder();

	int c;
	while ((c = r.read()) != -1) sb.append((char) c);
	return sb.toString();
}

The BufferedReader has a readLine() method akin to the DataInputStream, which has mostly the same behavior. Just that this one is not deprecated.

The big difference with this one is that by chaining a BufferedReader to an InputStreamReader, you can correctly read lines in char sets other than
the default encoding for the platform.

The BufferedWriter() class adds one new method not included in its superclass, called newLine(), also geared towards writing lines:

public void newLine() throws IOException

This method inserts a platform-dependant line-seperator string into the output. The line.seperator system property
determines exactly what the string is: probably a linefeed on Unix and Mac OS X, and a carriage return/linefeed pair on Windows. 
Because network protocols generally specify the required line terminator, you should not use this method for
network programming.

Instead, explicitly use a line terminator of the kind to which the protocl requires. More often than not, it's /r/n

PrintWriter:

The PrintWriter class is a replacement for Java 1.0's PrintStream class that properly handles multibyte
chars set and international text. Sun originally planned to deprecate PrintStream in favor of PrintWriter but backed out of it.

Regardless, you should use PrintWriter instead of PrintStream.

The PrintWriter class has the following methods:

public PrintWriter(Writer out) //constructor

public PrintWriter(Writer out, boolean autoFlush)

public PrintWriter(OutputStream out)

public PrintWriter(OutputStream out, boolean autoFlush)

public void flush()

public void close()

public boolean checkError()

public void write(int c) //The rest is just write statements both with arrays of chars or strings (non array) and rest is just print/println functions

The big difference is actually the write methods, which uses chars instead of bytes.

PrintWriter still suffers from platform dependency and minimal error reporting, though, and should still not be used for network programming.

Threads:

The problem of interaction of servers is the fact of how to handle many simultaneous requests and connections, is the fact of thread usage.
Which means that we can solve this by two different ways:

1. Reuse processes instead of spawning new ones. Meaning we could cycle requests based on a queue system and the power of 300 threads could go to handle that of 1000. Give or take.

2. Use lightweight threads to handle connections, instead of heavyweight processes. Whereas each seperate process has its own block of memory, threads share memory. Using threads
instead of processes, combined with the re-usage of threads, allows for much faster processing.

NOTE: If a app needs thousands of simultanoues long-lived connections (That's rare), we could use asynch I/O instead of Threads.
Selectors enable one thread to query a group of sockets to find out which ones are ready to be from or written to, and then process
the ready sockets sequentially. In this case, the I/O has to be designed around channels and buffers instead of streams.

Given the high roof of Threading , we should use that until we hit a proven wall. To which, after that we should considering sharding to redundant servers (Share burden),
albeit that brings issues as well with consistency.

As per usual, if we have multi-threaded approaches, we need to consider thread safety. Albeit, we also have to counter deadlocks.

a thread with a small t in java, is a independant path of execution in the virtual machine. 
A thread with a T is a instance of java.lang.Thread class. There is a one-to-one relationship between
threads executing in the VM and Thread objects constructed by the VM.

Most of the time it's obvious from the context which one is meant if the difference is really important.

To run a new thread, we just create one:

Thread t = new Thread();
t.start();

We have to delegate tasks to it, tho.

To do this, we subclass the thread class and override the Run() method in it, or implement the Runnable interface and pass the Runnable
object to the Thread constructor. 

All the interaction of a thread, and the lifespan of a thread, plays out in run(), when both main and run finishes, the program exits.

The difference of thread interaction comes in terms of the Daemon threads, as thoose threads are delegated background threads that use garbage collection and do not prevent the VM from exiting.

Subclassing Threads:

Consider a program that calculates the Secure Hash Algorithm (SHA) digest for many files. To large extent, this is an I/O-bound program
(i.e it's speed is limited by the amount of time it takes to read the files from the disk). If you write it as a standard program that processes
the files in a series, the program is going to spent a lot of time waiting for the return of data from the hard drive.

The case is even worse with network, as the program executes faster than the network has speed.

An example of a script that calculates a 256-bit SHA-2 message digest for a specified file. It does so by reading the file with a DigestInputStream.
When done, the hash algorithm is available from the digest():

import java.io.*;
import java.security.*;
import javax.xml.bind.*;

public class DigestThread extends Thread {
	private String filename;

	public DigestThread(String filename){
		this.filename = filename;
	}

	@Override
	public void run(){
		try{
			FileInputStream in = new FileInputStream(filename);
			MessageDigest sha = MessageDigest.getInstance("SHA-256");

			DigestInputStream din = new DigestInputStream(in, sha);
			while (din.read() != -1) ; //While we have not reach EOF; keep reading 
			din.close();

			byte[] digest = sha.digest();

			StringBuilder result = new StringBuilder(filename);
			result.append(": ");
			result.append(DatatypeConverter.printHexBinary(digest));

			System.out.println(result);
		} catch (IOException ex) {
			System.err.println(ex);
		} catch (NoSuchAlgorithmException ex){
			System.err.println(ex);
		}
	}

	public static void main(String[] args){
		for (String filename : args){
			Thread t = new DigestThread(filename); //Create a new thread for each file we are feeding in and start that thread
			t.start();
		}
	}
}

Since we cannot change the inarguments of run(), the easiest way of passing in params is dependency injection into the constructor.

The biggest problem with Threads is fact of asynch completion, thus getting back the value is a question of implementation and assertion of when it is done.

NOTE: We should never overwrite the original methods of the Thread class, except Run(), because they have deep integration into the VM.

The easiest way to achieve this, is just to implement the runnable interface and run a Thread with that:

Thread t = new Thread(myRunnableObject);
t.start();

An example of having recast the previous example to implement the Runnable interface instead:

import java.io.*;
import java.security.*;
import java.xml.bind.*; 

public class DigestRunnable implements Runnable{
	private String filename;

	public DigestRunnable(String filename){
		this.filename = filename;
	}

	@Override
	public void run(){
		try{
			FileInputStream in = new FileInputStream(filename);
			MessageDigest sha = MessageDigest.getInstance("SHA-256");

			DigestInputStream din = new DigestInputStream(in, sha);
			while (din.read() != -1); 
			din.close();

			byte[] digest = sha.digest();

			StringBuilder result = new StringBuilder(filename);
			result.append(": ");
			result.append(DatatypeConverter.printHexBinary(digest));
			System.out.println(result);
		} catch (IOException ex){
			System.err.println(ex);
		} catch (NoSuchAlgorithmException ex){
			System.err.println(ex);
		}
	}

	public static void main(String[] args){
		for(String filename : args){
			DigestRunnable dr = new DigestRunnable(filename);
			Thread t = new Thread(dr);
			t.start();
		}
	}
}

There is no real strong case for implementing the Runnable, really. Since that it depends on the situation.
To some extent, we might do it, where we will need to call the class methods in the constructor, which demands a subclass.

In other cases, we might need to extend Runnable for reasons of putting run() in a class that extends another class, such as when
we will be using HTTPServlets.

Returning Info from a Thread:

One of the hardest things for synched programmers to grasp in asynch thread handling, is getting info from threads completions.

So, how do we get info, from Asynch calls? Simple. We do a callback structure. By virtue of creating a structure that forces the code to tell us when it is done
and delegate responsibility upon completion.

In our example, we define 2 classes that handles this, the first being for the callback of each respective thread, the second being where its run:

import java.io.*;
import java.security.*;

public class CallbackDigest implements Runnable{
	private String filename;

	public CallbackDigest(String filename){
		this.filename = filename;
	}

	public void run(){
		try{
			FileInputStream in = new FileInputStream(filename);
			MessageDigest sha = MessageDigest.getInstance("SHA-256");

			DigestInputStream din = new DigestInputStream(in, sha);
			while(din.read() != -1) ; //keep reading
			din.close();

			byte[] digest = sha.digest();
			CallbackDigestUserInterface.recieveDigest(digest, filename);
		} catch (IOException ex) {
			System.err.println(ex);
		} catch (NoSuchAlgorithmException ex){
			System.err.println(ex);
		}
	}
}

The Callback User Interface that is a Class, is what we define next:

import java.xml.bind.*;

public class CallbackDigestUserInterface{
	
	public static void recieveDigest(byte[] digest, String name){
		StringBuilder result = new StingBuilder(name);
		result.append(": ");
		result.append(DatatypeConverter.printHexBinary(digest));

		System.out.println(result);
	}

	public static void main(String[] args) {
		for (String filename : args) {
			CallbackDigest cb = new CallbackDigest(filename);
			Thread t = new Thread(cb);
			t.start();
		}
	}
}

Another way of doing it, is simply running a instace version of a CallbackDigest:

import java.io.*;
import java.security.*;

public class InstanceCallbackDigest implements Runnable {
	private String filename;
	private InstanceCallbackDigestUserInterface callback;

	public InstanceCallbackDigest(String filename, InstanceCallbackDigestUserInterface callback){
		this.filename = filename;
		this.callback = callback;
	}

	@Override
	public void run(){
		try{
			FileInputStream in = new FileInputStream(filename);
			MessageDigest sha = MessageDigest.getInstance("SHA-256");
			DigestInputStream din = new DigestInputStream(in, sha);

			while(din.read() != -1) ; //Read the file
			din.close();

			byte[] digest = sha.digest();
			callback.receiveDigest(digest);
		} catch (IOException | NoSuchAlgorithmException ex) {
			System.err.println(ex);
		}
	}
}

The second class just holds the digest and processes the callback recieved upon completion:

import javax.xml.bind*; 

public class InstanceCallbackDigestUserInterface{
	private String filename;
	private byte[] digest;

	public InstanceCallbackDigestUserInterface(String filename){
		this.filename = filename;
	}

	public void calculateDigest(){
		InstanceCallbackDigest cb = new InstanceCallbackDigest(filename, this);
		Thread t = new Thread(cb);
		t.start();
	}

	void receiveDigest(byte[] digest){
		this.digest = digest;
		System.out.println(this);
	}

	@Override
	public String toString(){
		String result = filename + ": ";
		if(digest != null){
			result += DatatypeConverter.printHexBinary(digest);
		} else {
			result += "digest not available!";
		}
		return result;
	}

	public static void main(String[] args){
		for (String filename : args) {
			InstanceCallbackDigestUserInterface d = new InstanceCallbackDigestUserInterface(filename);
			d.calculateDigest();
		}
	}
}

The advantages of doing instance methods, is amongst the fact that It's more flexible, we avoid race conditions and we don't waste CPU cycles (callback vs Static polling)

Callbacks also allow for much more complicated structure and building of threading systems etc.

We can stretch the results of the Callback by interfaces or a array of objects to send the info to in regards to completion of the Callback.

AWT uses the same pattern as this, to handle event listenrs and delegate tasks on a seperate task instead of blocking the main Thread.

Beyond this, we of course have futures, which is when a callback is completed, and a object that prevents the thread it has been delegated to, until the point of where it can actually be accessed:

import java.util.concurrent.Callable;

class FindMaxTask implements Callable<Integer>{
	private int[] data;
	private int start;
	private int end;

	FindMaxTask(int[] data, int start, int end){
		this.data = data;
		this.start = start;
		this.end = end;
	}

	public Integer call(){
		int max = Integer.MIN_VALUE;
		for (int i = start; i < end; i++){
			if (data[i] > max) max = data[i];
		}
		return max;
	}
}

//Then we just create the second class that returns the tasks together:

import java.util.concurrent.*;

public class MultithreadedMaxFinder{
	public static int max(int[] data) throws InterruptedException, ExcutionException {
		if (data.length == 1) {
			return data[0];
		} else if (data.length == 0) {
			throw new IllegalArgumentException();
		}

		//Split the job into 2
		FindMaxTask task1 = new FindMaxTask(data, 0, data.length/2);
		FindMaxTask task2 = new FindMaxTask(data, data.length/2, data.length);

		//Spawn 2 threads
		ExecutorService service = Executors.newFixedThreadPool(2);

		Future<Integer> future1 = service.submit(task1);
		Future<Integer> future2 = service.submit(task2);

		return Math.max(future1.get(), future2.get());
	}
}

Doing it this way allows for much ease in terms of handling threads, without having to do callbacks and what not.

To account for Thread safety, we can of course Synchronize the Threads with synchronize blocks:

synchronized (<thread>){
	//do stuff
}

The next example, showcases the idea of writing to a file, where several threads share the same object:

import java.io.*;
import java.util.*;

public class LogFile{
	private Writer out;

	public LogFile(File f) throws IOException {
		FileWriter fw = new FileWriter(f);
		this.out = new BufferedWriter(fw);
	}

	public void writeEntry(String message) throws IOException{
		Date d = new Date();
		out.write(d.toString());
		out.write('\t');
		out.write(message);
		out.write("\r\n");
	}

	public void close() throws IOException{
		out.flush();
		out.close();
	}
}

Now, we can synchornize a bit of things, we can synchronize the writentry:

public synchronized void writeEntry(String message) throws IOException{
	//stuff
}

The problem with oding this, is that not only does it slow down the code, it might also be misguided, if we do it on the wrong target.
In this case, we could do it because the out is private and not exposed in any other matter. Albeit, it is the same in this case as synchornizing the Log file object,
since only one log file handling should occur at any given time, really.

We can also use shortcuts to not have to use Synch in multithreading, like local variables, due to their temporary nature and instance binding.

More so, methods taking primitives (no reference, just value) - escape synch as well.

Strings are safe, cause immutable.

Objects are not safe, due to mutateable state.

We can also just declare whatever we are working with to be nonmutable, due to final and private.

Beyond this, we can in terms of if we need setting of variables, use the atomic versions of them, which can outspeed synched situations if used in asynch.

Note, even if a thing is synched, such as as synched map or synched list, if we iterate through them with a lot of atomic operations, we still need to synch that entire process.

Due to deadlock, use Synchronization as a last resort. Use non-mutable state instead.

We can, of course, scheduel our threads as well, which causes ordering in terms of priority to which one is most important, less so, etc.

we do this by <thread>.setPriority(<number>) //This number varies on OS, windows goes up to 9 max and 1 lowest. The ordering of low = high prio, is opposite to that of Unix.

There is also preempetive and cooperative designs around threads. Where preempetive will predict priority and relegate based on that. Cooperative waits for switching.

Cooperative can cause starvation though, so we should avoid that. Which is also why we must ensure pausing of threads so prevent starving, because Coop threads do not relegate based on prio.

There are 8 relevant ways a thread can stop:

It can block on I/O

It can block on a synch object

It can yield

it can sleep

It can join another thread

it can wait on an object

It can finish

it can be preemped by a higher prio thread

There are two more ways, but they are deprecated because they can leave the thread in a uncertain state:

It can be suspended.

It can stop.

However, we are going to go over these states and how they can come to be:

Blocking:

Blocking occurs at any time that a thread has to stop and wait for a resource it does not have.
The most common way a thread in a networking will voluntarily give up control, is blocking on I/O.

Due to the already stated fact of that CPUs speed > that of Networks, it means that threads will block - but delegate
info to other threads in turn due to that.

Threads can also block upon going into synchronized methods or blocks. If the Thread does not already posses
the lock for the object being synched and some other thread does posses that lock, the thread will pause until
the lock is released. If the lock never is released, the thread, is permanently stopped.

Neither blocking on I/o nor blocking on a lock will release any locks the thread already posses.
For I/O blocks, this is not such a big deal, because eventually the I/O will either unblock and the
thread will continue or an IOException will be thrown and the thread will exit the method or block and release it's locks.

However, if two locks wait for each other, deadlock occurs.

Yielding:

The second way for a thread to relinquish control is to explicitly yield. A thread does this by 
invoking the Static Thread.yield() method.

This signals a hint to the VM that it can run other threads if there are ones available. However,
the problem is the fact that alot of VMs will ignore this hint, and particularly real-time OS systems ignore this hint.

Before yielding, a thread should make sure that it or its associated Runnable object is in a consistent state that can be
used by other objects. Yielding does not release any locks the thread holds. Therefore, ideally, a thread should not
be synched on anything when it yields.

If the other threads are blocked due to the synched object having yielded it but not released the locks, the system will re-allocate
the resources back to the one that relinquished control.

To yield, we just call yield() on the thread. 

Sleeping:

Sleeping a thread makes so that any other thread, regardless of prio level, will have access to it - assuming it's not blocked due to being locked out of it.
There for, we should not sleep threads in a synched block.

A thread goes to sleep by invoking one of two overloaded static Thread.sleep() methods. The first takes the number of milliseconds to sleep
as an arg. The second does MS and NS. (milliseconds and Nanoseconds)

//They are of the long and int format, respectively.

Most modern computer clocks can't go down to nanoseconds, much less miliseconds. If there is no such level of accuracy, the 
time is rounded up to the closest place it can converge on.

An example of a loop that runs to try and find a page every 5 minutes, to which if it fails to findi t, will email an adress:

public void run()
{
	while (true){
		if (!getPage("http://www.ibiblio.org/")){
			mailError("webmaster@ibiblio.org");
		}
		try{
			Thread.sleep(300000); //300k miliseconds = 5 min
		} catch (InterupptedException ex){
			break;
		}
	}
}

There is no guarantee that the thread will sleep for htat long. If the VM need sit, it will wake it, or it will fail to wake 
it because it's busy doing other things.

To wake a sleeping thread, we can just run Thread.interuppt();

Note: Other awake threads can still call the interuppt() on the Object which has a sleeping thread, and wake up the thread.

The effect of causing a interuppt on a blocked thread varies on platform, some are designated to actually stop and others
will just ignore it. If the Architechture demands interupptable I/O, we should use non-blocking I/O rather than streams. Because
unlike streams, Buffers and Channels are made with interupption in mind.

Joining Threads:

It's not uncommon for a thread to need the result of another. For example a web browser loading an HTML page
in one thread might spawn a separate thread to retrieve every image embedded in a page.

If the IMG elements don't have HEIGHt and WIDTH attributes, the main thread might have to wait for all the images 
to load before it can finish by displaying the Page.

Java provides three join() methods to allow one thread to wait for another thread to finish before continuing:

public final void join() throws InterupptedException;

public final void join(long milliseconds) throws InterupptedException;

public final void join(long milliseconds, int nanoseconds) throws InterupptedException;

The first waits indefinitly, the second and third waits for the specified time. After the time runs out, the designated join threads
continue working, even if the joined thread has not finished.

An example of running thread joining by delegating the sorting to a new thread and then join the thread to await its results:

double[] array = new double[10000];
for (int i = 0; i < array.length; i++){
	array[i] = Math.random();
}
SortThread t = new SortThread(array);
t.start();

try{
	t.join();
	//print stuff
} catch (InterruptedException ex){
	//Do something
}

Here an implicit call to join the current thread happens. by virtue of just saying t.join(); , meaning, take the current thread and join it to that designated thread.

However, the problem, is that we cannot put this in the flow of Main(), cause there can be no explicit referals to the current thread in main.

If a thread that is joined is interuppted, which it can be, it is then jumping over to the catch.

An example of running a join structure to avoid a race structure of threads:

import java.xml.bind.DatatypeConverter;

public class JoinDigestUserInterface {
	public static void main(String[] args){
		ReturnDigest[] digestThreads = new ReturnDigest[args.length];

		for (int i = 0; i < args.length; i++){
			digestThreads[i] = new ReturnDigest(args[i]);
			digestThreads[i].start();
		}

		for (int i = 0; i < args.length; i++){
			try{
				digestThreads[i].join();

				StringBuffer result = new StringBuffer(args[i]);
				result.append(": ");
				byte[] digest = digestThreads[i].getDigest();

				result.append(DatatypeConverter.printHexBinary(digest));
			} catch (InterupptedException ex) {
				//Do stuff
			}
		}
	}
}

This causes a sort of synchronized row of calculations, as even when the results are available earlier, they will instead be printed in the
order that they were set to be.

Generally, we can avoid join structures by futures and executors, if we wish to have a Synched structure of Asynch calls.

Waiting on a Object:

The difference between waiting and joining, is that joining waits until execution finishes, waiting waits until a arbitrary point of which
we can state that "We have reached X state, now we can continue operations".

To wait on a locked object, we aquire the lock of the object using synchronized and then call the wait() method on it.
Akin to earlier situations, it has both the wait() //normal just wait method, and the ones where we accoutn for time with MS and (MS and NS).

The methods derive from java.lang.Object. When a wait occurrs, the thread which called the wait, will sleep, until one of three things happens:

The timeout expires.

the thread is interuppted.

The object is notified.

When the thread awakes from the wait, it carries on as per attempting to operation after the wait. It can still be locked if there are 
locks on the object, though.

Interuppts work as before. 

Notifications are invoked on the object with notify() or notifyAll(). They both derive from java.lang.Object.
They are called on the object, not the threads.

notify() notifies a random thread waiting on it, notifyAll() notifies all.
After the notify, they attempt to regain the lock of the thread, and execute after the wait after hte point of which they regain the lock.

For example, assuming we are reading a JAR from a network connection. The first entry in the acrhive is the manifest file.
Another thread might be interested in this file, even before the rest of the archive is ready.

Thus, the other thread could create a custom ManifestFile object, pass a reference to this object to the thread that would read
the JAR archive and wait on it. The thread reading the archive would first fill the ManifestFile with entires from the stream, then notify
the ManifestFile, then continue reading the rest of the JAR archive. When the reader thread notified the ManifestFile, the original Thread
would wake up and do whatever it planned to do.

The example:

ManifestFile m = new ManifestFile();
JarThread t = new JarThread(m, in); //in being the in stream of data from the connection
synchornized(m){
	t.start();
	try{
		m.wait();
		//Work with the manifest file
	} catch(InterupptedException ex){
		//handle exception
	}
}

The JarThread class would look as follows:

ManifestFile theManifest;
InputStream in;

public JarThread(Manifest m, InputStream in){
	theManifest = m;
	this.in = in;
}

@Override
run(){
	synchronized (theManifest){
		//Read the manifest from the stream in
		theManifest.notify();
	}
	//Rest of the stream
}

wait and notifyAll is used mostly when working with multiple threads handling things. 
The following example, assumes reading a logFile and processing them, where processing occurs on one thread, and reading on another:

private List<String> entries;

public void processEntry(){
	synchronized(entries){
		while(entries.isEmpty()){
			try{
				entries.wait();
				//Keep waiting until we are notified
			} catch (InterupptedException ex){
				//If we were interuppted, the last entry to enter has been processed
				return; 
			}
		}

		String entry = entries.remove(entries.size()-1);
		//Process the entry
	}
}

//And the reading of the logfile might look as follows:

public void readLogFile(){
	while (true){
		String entry = log.getNextEntry();
		if (entry == null){
			//The list is empty, interuppt all waiting threads
			for (Thread thread : threads) thread.interuppt();
			break;
		}
		synchronized (entries){
			entries.add(0, entry); //add the entry and notify all the threads to wake up and work on it
			entries.notifyAll();
		}
	}
}

Finishing:

The final way a thread relinquishes control, is by finishing.
Usually, in Networking, this concludes in context of downloading things or singular operations, so that it does not block the rest of the Applicaiton.

If the amount of time it takes to finish an operation is actually very small, it can come to be cheaper in terms of time of execution to just
not spawn a thread for thoose operations to begin with.

Thread Pools and Executors:

There is a finite amount of resources that is realistic to allocate threads for. Assuming we can delegate work to different threads, it can go
faster of course, such as in networking where we are doing a lot of I/O. But the problem, becomes rather when we spend so much time on it,
that we can slow down the program by virtue of garbage collection or by virtue of dividing all the realistic resources of idle time on
threading - Meaning we waste MIP and memory on thread management, because those threads are doing nothing.

Assume we have a program where we wish to GZIP all the files in our current dir. that is a very I/O process that takes a lot on the CPU
because it's data compression. So we don't want too many threads running.

However, since the main program listing the things, will most likely outpace the compressing of the files, we fill the pool and then
pull the trigger on running compression.

First, we define the class for doing the compressing of the actual file delegated:

import java.io.*;
import java.util.zip.*;

public class GZipRunnable implements Runnable{
	private final File input;

	public GZipRunnable(File input){
		this.input = input;
	}

	@Override
	public void run(){
		//Don't compress an already compressed file
		if (!input.getName().endsWith(".gz")){
			File output = new File(input.getParent(), input.getName() + ".gz");
			if (!output.exists()){ //Don't overwrite
				try( InputStream in = new BufferedInputStream(new FileInputStream(input));
					 OutputStream out = new BufferedOutputStream(new GZIPOutputStream(new FileOutputStream(output))); //Open the inputstream and outputstream
				){
					int b;
					while ((b = in.read()) != -1) out.write(b);
					out.flush(); //clear and close em
				} catch(IOException ex){
					//Print or some shit
				}
			}
		}
	}
}

We run buffered streams for performace here. (As we always should)

import java.io.*;
import java.util.concurrent.*;

public class GZipAllFiles{
	public final static int THREAD_COUNT = 4;

	public static void main(String[] args){
		ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);

		for(String filename : args){
			File f = new File(filename);
			if (f.exists()){
				if (f.isDirectory()){
					File[] files = f.listFiles();
					for (int i = 0; i < files.length; i++){
						if (!files[i].isDirectory()){ //go 1 layer deep
							Runnable task = new GZipRunnable(files[i]);
							pool.submit(task);
						}
					}
				} else {
					Runnable task = new GZipRunnable(f);
					pool.submit(task);
				}
			}
		}

		pool.shutDown(); //Abnormal usage of shutdown, tells pool to not add more tasks, in Internet Connective environemnts, we usually run more tasks until the pooint of manual shutdown in ADMIN area
		//if we wish to shut down ALL tasks current and pending, shutdownNow() does so 
	}
}

Internet Addresses:

A Hostname is the DNS address (www.example.com), address is the IP address, be that IPv4 or IPv6.

Usually, a name maps to an IP. Sometimes, they do to several IPs. 

Every computer connected to the internet generally should connec to a DNS located at a Unix box running a DNS software that knows
the mappings between different hostnames and IP addresses. 

Usually a DNS only knows the IP of that at it's local network, meaning that if a client requests the IP of something at another network,
it will chain to call to the other remote DNS server to access the location there. It then relays the answer to whoever sent the request.

Most of the time, you can use hostnames and let DNS handle the translation to IP addresses. As long as you can connect to a domain name server,
you don't need to worry about the details of how names and addresses are passed between your machine, the local DNS and the rest of the internet.

However, you will need access to at least one domain name server to use the examples in this chapter and most of the rest of this book.

The InetAddress class:

The java.net.InetAddress class is Java's high-level representation of 
an IP address, both IPv4 and IPv6. It is used by most of the other
networking classes, including Socket, ServerSocket, URL, DatagramSocket,
DatagramPacket, and more. Usually, it includes both a host name and an
IP address.

Creating New InetAddress objects:

There are no public constructors in the Inetaddress class, InetAddress
has static factory methods that connect to a DNS server to resolve a hostname.
The most common is InetAddress.getByName().

we generally look up addressses by:

InetAddress address = InetAddress.getByName("www.oreilly.com");

The method does not merely set a private String field in the InetAddress
class. It actually makes a connection to the local DNS server to look up the 
name and the numeric address. (If you've looked up this host previously,
the info may be cached locally, in which case a network connection is not required)

If the DNS server can't find the address, this method throws an UnknownHostException, a 
subclass of IOException.

An example of creating an InetAddress object for a url:

import java.net.*;

public class OReillyByName {
	public static void main (String[] args){
		try{
			InetAddress address = InetAddress.getByName("www.oreilly.com");
			//print
		} catch (UnknownHostException ex) {
			//Print
		}
	}
}

The reverse would be as follows:

% java OReillyByName
www.oreilly.com/208.201.239.36

We can also reverse lookup an IP by virtue of aquiring the name by feeding in an IP:

InetAddress address = InetAddress.getByName("208.201.239.100");
//print

If the address you are looking up does not have a hostname, getHostName() simply
returns the dotted quad address you supplied.

The supplied URL actually has two addresses , which we can aquire
as follows:

try{
	InetAddress[] addresses = InetAddress.getAllByName("www.oreilly.com");
	for(InetAddress address : addresses){
		//print
	}
} catch (UnknownHostException ex){
	//print
}

Finally, the getLocalHost() method returns an InetAddress object for the host on 
which your code is running:

InetAddress me = InetAddress.getLocalHost();

This method tries to connect to DNS to get a real hostname and IP address
 such as "elharo.laptop.corp.com" and "192.1.254.68"; But if it fails,
 it returns just the loopback 127.0.0.1

 An example:

 import java.net.*;

 public class MyAddress{
 	public static void main (String[] args){
 		try{
 			InetAddress address = InetAddress.getLocalHost();
 			//print
 		} catch(UnknownHostException ex)
 		{
 			//print
 		}
 	}
 }

THe output:

% java MyAddress
titan.oit.unc.edu/152.2.22.14

Wether you see a fully qualified name or a partial one, depends
on the local DNS server returns for hosts in the local domain.
If you're not connected to the internet and the system does not have a fixed ip
or domain name, you'll probably see localhost as the name and 127.0.0.1 as the ip.

If you know a numeric address, you can create an InetAddress object 
from that address without talking DNS using InetAddress.getByAddress().
This method can create addresses for hosts that do not exist or cannot be resolved:

public static InetAddress getByAddress(byte[] addr) throws UnknownHostException

public static InetAddress getByAddress(String hostname, byte[] addr) throws UnknownHostException

The first InetAddress.getByAddress() factory method create an IP address with no
hostname, where as the second does one with a name and IP.

An example of making a InetAddress object from an ip:

byte[] address = {107, 23, (byte) 216, (byte) 196};
InetAddress lessWrong = InetAddress.getByAddress(address);

InetAddress lessWrongWithname = InetAddress.getByAddress("lesswrong.com", address);

Unlike the other factory methods, these do not guarantee that such a host exists
or that the IP address is correctly mapped to the hostname.

They throw an UnknownHostException if a byte array of illegal size (neither 4 or 16 bytes long)
is passed as an arg.

This is very useful if a domain server is not available or might have inaccurate
info. For example, we could write a program that connects to 254 different connections
in order, to see which ones are active.

Caching:

Because DNS lookups can be relativily expensive (on the order of several
seconds for a request that has to go through several intermediate servers, or
one that's trying to resolve an unreachable host) the InetAddress class caches
the result of lookups. 

Once it has the address of a given host, it won't look it up again,
even if you create a new InetAddress object for the same host. As long as
IP addresses don't change while your program is running, this is not a problem.

Negative results (host not found errors) are slightly more problematic. 
It's not uncommon for an initial attempt to resolve a host to fail,
but the immedeat following one to succeed.

The first timed out while the info was in transit from the DNS, and the other
arrived instantly for the next one. For this reason, Java only caches
failed requests DNS queries for 10 seconds.

These times can be changed in system props, found at
networkaddress.cache.ttl and networkaddress.cache.negative.ttl,
where the first one is successful DNS queries and negative is for failed ones.

They can be changed to any value, albeit -1 means never expire.

Besides local caching inside the InetAddress class, the local host, the local
domain name server and other DNS servers elsewhere on the internet 
also cache the results of various queries. Java cannot control this.

As a result, it may take several HOURS for info about IP changes to propogate
across the internet, whilst in the meantime, your program can run into a range
of all possible errors , such as:

UnknownHostException, NoRouteToHostException and ConnectException, depending
on the changes made to the DNS.

Lookups by IP address:

When you call getByName() with an IP address string as an argument, it creates
an InetAddress object for the requested IP address without checking with DNS.
This means, that you can create InetAddress objects for hosts that don't exist.

The hostname of a InetAddress object created from a string containing an IP address
is initially set to that string. A DNS lookup for the actual hostname
is only performed when the hostname is requested, either explicitly via
a getHostName(). 

If at the time the hostname is requested from the IP address and it cannot be found,
the hostname remains to be the dotted IP format. However, no UnknownHostException is thrown.

Hostnames are much more stable than IPs. IPs can dynamically change and change several times,
where as Hostnames can remain the same for a long time.

We should only choose to use an IP, when a hostname is not available to us.

Security Issues:

Creating a new InetAddress object from a hostname is considered potentionally insecure
operation because it requires a DNS lookup. an untrusted applet under the 
control of the default security manager will only be allowed to get the IP
of the host that it came from and possibly the local host.

Untrusted code is not allowed to make InetAddress objects from any other hostname.
This is true for all InetAddress.<method> that aquire names, localhosts etc.

The reason for this, is because DNS requests leak data. They can be tricked by
virtue of running a DNS request akin to injection formats, where you append
direction of stuff to Hosts that don't exist - but whilst the host does not
exist, it will crash and the malicious person can find the problem in the error log
to extract where it came from and the message.

It could of course just go south from that point, what with abusing
the information to other places and what not.

untrusted code is, however, allowed to call getLocalHost(), which just
returns 127.0.1. Because it already should have the info - and if its 
behind a firewall it could be a malicious operation. It is reundant
to tell info that already should exist.

Of course, if it's trusted code, you can do DNS resolutions as per normal.
for instance, SecurityManager can use  to test against if a host can be resolved
with the following method:

public void checkConnect(String hostname, int port)

When the port arg is -1, this method checks wether DNS may be
invoked to resolve the specified host. (if the port argument is
greater than -1, this method checks wether a connection to the named host on
the specified port is allowed).

The host arg can be a hostname, a IPv4 or IPv6.

Getter Methods:

The InetAddress class contains four getter methods that return
the hostname as a string and the IP address as both a string and a byte array:

public String getHostName()

public String getCannonicalHostName()

public byte[] getAddress()

public String getHostAddress()

There are no co-responding set methods, meaning that packages outside 
of java.net can't change an InetAddress object's fields behind it's back.
It makes InetAddress immutable and thread safe.

The getHostName() method returns a String that contains the name 
of the host with the IP address represented by this InetAddress object.

If the machine in question doesn't have a hostname or if the security
manager prevents the name from being determined, a dotted quad format of
the numeric IP address is returned. 

for example:

InetAddress machine = InetAddress.getLocalHost();

String localhost = machine.getHostName();

The getCanonicalHostName() method is similar, but it's a bit more
aggressive about contacting DNS. getHostName() will only call DNS
if it doesn't think it already knows the hostname.

getCanonicalHostName(), contacts if it can, and can replace cached values as well.
Example of usage:

InetAddress machine = InetAddress.getLocalHost();

String localHost = machine.getCanonicalHostName();

It is especially useful if we just start with the IP adress and want the host name,
as following example showcases:

import java.net.*;

public class ReverseTest{
	public static void main(String[] args) throws UnknownHostException{
		InetAddress ia = InetAddress.getByName("208.201.239.100");
		System.out.println(ia.getCannonicalHostName());
	}
}

The result is as follows:

% java ReverseTest
oreilly.com

An example of getting the IP of the local machine:

import java.net.*;

public class MyAddress{
	public static void main(String[] args){
	try{	
		InetAddress me = InetAddress.getLocalHost();
		String dottedQuad = me.getHostAddress();
		System.out.println("My address is: " + dottedQuad);
	} catch (UnknownHostException ex){
		System.out.println("Im sorry, i don't know my own address. LOL");
	}
}

If you want to know the IP address of a machine (you rarely do), then use
the getAddress() method, which returns an IP address as an array of bytes 
in network byte order.

The most significant byte (i.e the first byte in the address quad format) is the
0:th element in the array. 

To be ready for IPv6 don't assume the length of the array.

If you must know the length, access length of the array:

InetAddress me = InetAddress.getLocalHost();
byte[] address = me.getAddress();

The bytes returned are unsigned, which poses a problem.
Java does not have unsigned bytes, which means that bytes above 127 get treated
as negative.

Thus, to account for this, we have to convert them and run them as int:

int unsignedByte = signedByte < 0 ? signedByte + 256 : signedByte;

The conversion is just to make it be positive so that we don't get out of range in terms
of going too far with the accessing of numbers above 127 in IP addresses.

To determine the length of an address, we do as expected:

import java.net.*;

public class AddressTest{
	public static int getVersion(InetAddress ia){
		byte[] address = ta.getAddress();
		if (address.length == 4) return 4; //ipv4
		else if (address.length == 16) return 16; //ipv6
		else return -1;
	}
}

Address Types:

Some IP addresse and patterns adhere to being special case scenarios or special meanings.
Such as 127.0.0.1 being loopback localhost.

iPv4 in range of 224.0.0.0 to 239.255.255.255 are multicast addresses, that send to several
subscribed hosts at once.

Java has 10 methods which tests for wether InetAddress object meet any of these criterias:

public boolean isAnyLocalAddress() //True if the address is a wildcard address, false otherwise.
//relevant for several Network Interfaces or Ethernet cards or a 802.11 Wifi interface
//in IpV4 the wildcard is 0.0.0.0, in IpV6 it's all 0's, or ::

public boolean isLoopbackAddress() //returns true if 127.0.0.1 (IPv4) or  IPv6 (::1), false otherwise
//Connecting to this does so without hardware, meaning it bypasses Ethernet, PPP and other drivers.
//can root out where a problem is.

public boolean islinkLocalAddress() //True if it's a IPv6 link-local address, false otherwise.
//This is an address used to help IPv6 self-configure, much like DHCP on IPV4 networks but without
//necessarily using a server. Routers do not forward packets addressed to a link-local address
//beyond the local subnet. All link-local IPs begin with FE80:0000:0000:0000. The next eight bytes
//are filled with a local address, often copied from the Ethernet MAC address assigned by the
//Ethernet card manufacturer.

public boolean isSiteLocalAddress() //Returns ture if it's a IPv6 site-local address, false otherwise.
//Like link-local addresses, except only forwards by router to that site, not further.
//Works like isLinkLocalAddress() for the rest part.
//Start bytes are: FEC0:0000:0000:0000

public boolean isMultiCastAddress() //returns true if the address is multicast address, false otherwise.
//Mutlicast sends to all subscribed computers rather than one. IPv4 ones all range from 224.0.0.0 to
// 239.255.255.255. In IPv6 they all begin with FF.

public boolean isMCGlobal() //Returns true if its a global multicast, false otherwise.
//MultiCast globals can have subscribers from all over the world.
//All multicast addresses begin with FF. In Ipv6, global multicasts begin with
//FF0E or FF1E depending on wether the multicast address is a well known permanently assigned
//address or a transient one. In IPv4, all multicast addresses are global, at least as far as this
//method cares. IPv4 defines TIL (time to live) for scope, rather than addressing.

public boolean isMCNodeLocal() //True if the address is an interface-local multicast address.
//false, otherwise. Packets addressed to an interface-local address are not sent beyond the
//network interface from which they originate, not even to a different network interface 
//on the same node. This is primarily useful for networking debugging and testing.
//Interface-local multicast addresses begin with the two bytes FF01 or FF11, depending
//on wether the multicast address is a well known permanently assigned address or it's transient.

public boolean isMCLinkLocal()//True if it's a subnet-wide multicast address, false otherwise.
//Packets addressed to a link-local address will only be transmitted within that subnet.
//They begin with FF02, or FF12, as per the normal rules.

public boolean isMCSiteLocal() //returns true if the address is a site-wide multicast address, false otherwise.
//Packets addressed to a site-wide address will only be transmitted within their local site.
//Site-wide multicast addresses begin with FF05 or FF15, depending on wether the multicast address
//is a well known permanently assigned address or a transient address.

public boolean isMCOrgLocal() //true if an address is an organization-wide multicast address
//false, otherwise. An organization-wide multicast address may have subscribers within all sites
//of a company or a organization, but not outside of that organization. Organization multicast
//addresses begin with FF08 or FF18, depending on wether the multicast address is a well known
//permanently assigned address or a transient one.

What follows is a program that tries out the 10 different methods on checking what kind of a connection
it is:

import java.net.*;

public class IPCharacteristics{
	public static void main(String[] args){
		try{
			InetAddress address = InetAddress.getByName(args[0]);

			if(address.isAnyLocalAddress()){
				System.out.println(address + " is a wildcard address");
			}
			if(address.isLoopbackAddress()){
				//print
			}
			if(address.isLinkLocalAddress()){
				System.out.println(address + " is a link-local address.");
			} else if (address.isSiteLocalAddress()){
				System.out.println(address + " is a site-local address");
			} else {
				System.out.println(address + " is a global address.");
			}

			if (address.isMulticastAddress()){
				if(address.isMCGlobal()){
					System.out.println(address + " is a global multicast address.");
				} else if (address.isMCOrgLocal()){
					System.out.println(address + " is an organization wide multicast address.");
				} else if (address.isMCSiteLocal()){
					System.out.println(address + " is a site wide multicast address.");
				} else if (address.isMCLinkLocal()){
					System.out.println(address + " is a subnet wide multicast address.");
				} else if (address.isMCNodeLocal()){
					System.out.println(address + " is an interface-local multicast address.");
				} else {
					System.out.println(address + " is an unknown multicast address type.");
				}
			else{
				System.out.println(address + " is a unicast address.");
			}
		} catch (UnknownHostException ex) {
			System.err.println("could not resolve " + args[0]);
		}
	}
}

Testing Reachability:

The InetAddress class has two isReachable() methods that test wether a particular
node is reachable from the current host (i.e, wether a network connection can be made).
Connections can be blocked for many reasons, be that firewalls, proxies, failing routers,
broken cabels, or remote host not being turned on.

There are two, that we can use:

public boolean isReachable(int timeout) throws IOException

public boolean isReachable(NetworkInterface interface, int ttl, int timeout) throws IOException

They use ICMP echo requests (Echo pings) to try and reach eahc other.

The first, just defines the amount of milliseconds we give before we timeout. If it amanges
before that, it returns true, otherwise false - if it fails to ping at all, it throws an IOException.

The second allows us to define from which interface we are performing the connection and
the "time-to-live" (the maximum number of network hops the connection will attempt before being discarded).

Object Methods:

Like every other class, java.net.InetAddress inherits from the Object superclass.
However, it overrides 3 of the inherited methods from that object:

public boolean equals(Object o)

public int hashCode()

public String toString()

An object is equal to an InterAddress object only if it is itself an instance
of the InetAddress class and it has the same IP address. It does not need
to have the same hostname. Thus, an InetAddress object from www.ibiblio.org is equal
to an InetAddress object for www.cafeaulit.org because both refer to the same IP.

A simple example of comparison:

import java.net.*;

public class IBiblioAliases{
	public static void main(String[] args){
		try{
			InetAddress ibiblio = InetAddress.getByName("www.ibiblio.org");
			InetAddress helios = InetAddress.getByName("helios.ibiblio.org");
			if (ibiblio.equals(helios)){
				//print something about them being equal
			} else {
				//They are not equal
			}
		}
		catch (UnknownHostException ex) {
			System.out.println("Host lookup failed");
		}
	}
}

The hashCode() runs its hash based on the IP. 

Inet4 Address and Inet6Address

Java uses two classes, Inet4Address and Inet6Address, in order to distingusih
IPv4 addresses from IPv6 addresses:

public final class Inet4Address extends InetAddress
public final class Inet6Address extends InetAddress

Most of the time, we should not care for wether it is a IPv4
address or IPv6 address. In the application layer where java Programs reside,
you simply don't need to know this.

And even if you do, it's quicker to check it's size by virtue of running size()
on the returned byte array of getAddress().

The only relevant difference between ipv4 and ipv6s calls, is to check if
a address is a ipv4 address stuffed into a ipv6 format:

public boolean isIPv4CompatibleAddress()

It only returns true if it is a Ipv4 stuffed into a ipv6

Which means that you can take the byte array of the address and pull off the 4
last bytes ot have a ipv4 address, since the last 4 will be 0.

The NetworkInterface Class:

The NetworkInterface class represents a local IP address. This can either
be a physical interface such as an additional Ethernet card (common on firewalls and routers)
or it can be a virtual interface bound to the same physical hardware as the machine's other
IP addresses.

The NetworkInterface class provides methods to enumerate all the local addresses,
regardless of interface, and to create InetAddress objects from them. These
InetAddress objects can then be used to create sockets, server sockets and so forth.

Factory Methods:

Because NetworkInterface objects repersent physical hardware and virtual addresses,
they cannot be constructed arbitrarily. As with InetAddresses class, there are static
factory methods that return the NetworkInterface object associated with a particular
network interface. You can ask for a NetworkInterface by IP address, by name or by 
enumeration.

public static NetworkInterface getByName(String name) throws SocketException

The getByName() method returns a NetworkInterface object representing the
network interface with the particular name. If there's no interface with that
name, it returns null. If the underlying network stack encounters a problem
while locating the relevant network interface, a SocketException is thrown,
but it is not too likely.

The format of the names is platform dependant. On a typical UNIX system,
the Ethernet interface names have the form eth0, eth1 and so forth.
The local loopback address is probably named something like "lo".

on Windows, its more akin to like "CE31" and "ELX100" that are derived
from the name of the vendor and model of hardware on that particular
network interface.

For example, this code fragment attempts to find the primary Ethernet
interface on a Unix system:

try{
	NetworkInterface ni = NetworkInterface.getByName("eth0");
	if(ni == null){
		System.err.println("No such interface: eth0");
	}
} catch (SocketException ex){
	System.err.println("Could not list sockets");
}

public static NetworkInterface getByInetAddress(InetAddress address) throws SocketException

The getByInetAddress() method returns a NetworkInterface object representing
the network interface bound to the specified IP address. If no network interface
is bound to that IP address on the local host, it returns null.

If anything goes wrong, it throws a SocketException. For example, this code fragment
finds the network interface for the local loopback address:

try{
	InetAddress local = InetAddress.getByName("127.0.0.1");
	NetworkInterface ni = NetworkInterface.getByInetAddress(local);
	if (ni == null){
		System.err.println("lol no loopback");
	}
} catch (SocketException ex){
	System.err.println("Could not list network interfaces.");
} catch (UnknownHostException ex){
	System.err.println("That's wierd. Could not look up 127.0.0.1");
}

public static Enumeration getNetworkInterfaces() throws SocketException

the getNetworkInterfaces() method returns a java.util.Enumeration listing all
the network interfaces on the local host. A simple example of this:

import java.net.*;
import java.util.*;

public class InterfaceLister{
	public static void main(String[] args) throws SocketException{
		Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();

		while(interfaces.hasMoreElements()){
			NetworkInterface ni = interfaces.nextElement();
			System.out.println(ni);
		}
	}
}

An example of a localhost running with 2 ethernet cards:

name:eth1 (eth1) index: 3 addresses:
/192.168.210.122;

name:eth0 (eth0) index: 2 addresses:
/152.2.210.122;

name:lo (lo) index: 1 addresses:
/127.0.0.1;

You can see that this host has two seperate Ethernet cards plus the local loopback address.
The Ethernet card with index 2 has the IP address 152.2.210.122 etc.

Getter Methods:

Once you have a NetworkInterface object, you can inquire about its IP address
and name. This is pretty much all you can do with them.

public Enumeration getInetAddresses()

A single network interface may be bound to more than one IP address. This situation
isn't common these days, but it does happen. the getInetAddresses() method returns
a java.util.Enumeration containing an InetAddress object for each IP address the
interface is bound to. For example, this code fragment lists all the IP addresses
for the eth0 interface:

NetworkInterface eth0 = NetworkInterface.getByName("eth0");
Enumeration addresses = eth0.getInetAddresses();
while(addresses.hasMoreElements()){
	System.out.println(addresses.nextElement());
}

public String getName()

The getName() method returns the name of a particular NetworkInterface object, such as
eth0 or lo

public String getDisplayName()

the getDisplayName() method allegedly returns a more human-friendly name for the
particular NetworkInterface - something like "Ethernet Card 0". However, on Unix,
it returns the same as getName(). 

Some Useful Programs:

The next section we will cover how to make two different programs, one for querying
DNS's interactively and another that can improve the performance of web server processing
logfiles offline.

SpamCheck:

To figure out a Spammer, you need to be able to establish very quick response to if it is a known
one, it should be cachable and the load should spread across several servers.

Albeit, it could be used concieveably with a web server, UDP, SOAP, a custom Protocol or some other
mechanism, we can single-handedly use DNS for this.

To find it out, we reverse the bytes of the IP address, add the domain of the blackhole service.
If we find it, it's a spammer, if it's an exception, it is not a spammer.

For instance, if we wish to ask sbl.spamhaus.org if 207.87.34.17 is a spammer, you
would look up 17.34.87.207.sbl.spam-haus.org.

If the DNS query returns 127.0.0.2, then the host is a spammer. If it fails,
it is not a spammer.

An example of the program to run this:

import java.net.*;

public class SpamCheck {
	public static final String BLACKHOLE = "sbl.spamhaus.org";

	public static void main(String[] args) throws UnknownHostException{
		for (String arg: args){ //Run through the commandline args
			if (isSpammer(arg)){ //if respective arg is triggered, it is a spammer
				//is a spammer
			} else{
				//Not a spammer
			}
		}
	}

	private static boolean isSpammer(String arg){
		try{
			InetAddress address = InetAddress.getByName(arg);
			byte[] quad = address.getAddress();
			String query = BLACKHOLE;
			for (byte octet : quad){
				//Convert the part if it's overriding the limit of byte
				int unsignedByte = octet < 0 ? octet + 256 : octet;

				//make the query
				query = unsignedByte + "." + query;
			}
			//run the query
			InetAddress.getByName(query);
			return true;
		} catch (UnknownHostException e){
			//it failed, so we know it's a spammer
			return false;
		}
	}
}

If you use this technique, stay up to date with the Blachole service.
They are subject to frequent DDOSing, meaning they can change IP or be down.

Some use different procotols, some return 127.0.0.1 on true triggers and others 127.0.0.2

Processing Web Server logfiles:

Web server logs track the hosts that access a website. By default, the log reports the IP
addresses for the sites that connect to the server. However, you can often get more
information from the names of those sites than from their IP addresses.

Most web servers have an option to store hostNames instead of ip addresses,
but this can cause performance hits because you make a query for every single hit.

It is much more efficnet to store the IPs and then process them on another ocassion
or on another machine.

Most web servers have standardized on the common logfile format. A typical line
in the common logfile format looks like this:

205.160.186.76 unknown - [17/Jun/2013:22:53:58 -0500] "GET /bgs/greenbg.gif HTTP 1.0" 200 50

This line indicates that a web browser at IP address 250.160.187.76 requested the file
/bgs/greenbg.gif from this web server at 11:53 PM (and 58 seconds) on June 17, 2013.

The file was found (response code 200) and 50 bytes of data were successfully transfered
to the browser.

The first field is the IP address or, if DNS resolution is turned on, the hostname from
which the connection was made. Thus, for our purposes of converting the IP address,
all we need to do is take account for the first space:

import java.io.*;
import java.net.*;

public class Weblog{
	public static void main(String[] args){
		try (FileInputStream fin = new FileInputStream(args[0]); //The file to be processed put into a input stream,
		//try with resources
			Reader in = new InputStreamReader(fin); //chain the reader to the input stream
			BufferedReader bin = new BufferedReader(in);) { //Run a BufferedReader on the inputStreamReader

			for (String entry = bin.readLine(); //Read a line
				entry != null; //if entry is not null, 
				entry = bin.readLine()){ //read a line and assign it
					//Seperate out the IP address
					int index = entry.indexOf(' ');
					//Break apart the string, with the IP first and the rest
					String ip = entry.substring(0, index);
					String theRest = entry.substring(index);

					//Ask DNS for the hostname
					try{
						InetAddress address = InetAddress.getByName(ip);
						System.out.println(address.getHostName() + theRest);
					} catch (UnknownHostException ex){
						System.err.println(entry);
					}
				}
			}
		catch(IOException ex){
			System.out.println("Exception: " + ex);
		}
	}
}

Whilst the program is functioning, it is not GOOD per say.
The problem lies in the fact of that the program takes approx > 1 second to wait
for the requests against the DNS.

And the problem with this program, is that we are running it on a single thread,
meaning it's not very optimized. Further more so, we need a thread pool, not just two threads,
because the matter of the fact that a web server can generate logfiles with thousands of lines.

The reason being that for each request a line is written, and for each graphic on the site,
one is written - and people can make several requests. It just overall means that we 
are going to get a shit ton of requests basically, and that causes slowdown
cause we are running in a slow situation.

And still, albeit the InteAddress caches the requests, which causes for faster lookups,
more so than the DNS - However, it is still, in total, slow.

Which means that we want to do a thread pool to resolve it, to handle concurrent Asynch operations.

However, we cannot just spam one thread for reach request, cause speed of reading is far greater
than that of DNS requests. Meaning we have to reuse threads. The number of threads
is stacked in a variable called numberOfThreads, so that it can be adjsuted ot the network stack
and VM. Launching too many DNs requests at once can also cause issues.

Thus, we have two classes.

The first, is a Callable that parses a logfile entry, looks up a single address and replaces
that address with the corresponding hostname. It is not a lot of work in a vacuum,
but it involves network connections, and possibly a hierachy series of network connections
between DNS servers, meaning it has a lot of downtime.

//First class

import java.net.*;
import java.util.concurrent.callable;

public class LookupTask implements Callable<String>{
	private String line;

	public LookupTask(String line){
		this.line = line;
	}

	@Override
	public String call(){
		try{
			//Separate out the IP address
			int index = line.indexOf(' ');
			String address = line.substring(0, index);
			String theRest = line.substring(index);

			//DNS lookup
			String hostName = InetAddress.getByName(address).getHostName();
			return hostName + " " + theRest;
		} catch (Exception ex){
			return line;
		}
	}
}

The second class, is the PooledWebLog, which contains the main method that reads
the file and creates one LookupTask per line. Each task is submitted to an
executor that can run multiple (though not all) tasks in parallel and in sequence.

The Future is returned from the submit() method is stored in a queue, along with
the original line (in case of error in the asynch thread). A loop reads values out
of the queue and prints them. This maintains order of the logfile.

import java.io.*;
import java.util.*;
import java.util.concurrent.*;

public class PooledWebLog{
	private final static int NUM_THREADS = 4;

	public static void main(String[] args) throws IOException{
		ExecutorService executor = Executors.newFixedThreadPool(NUM_THREADS);
		Queue<LogEntry> results = new LinkedList<LogEntry>();

		try (BufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(args[0]), "UTF-8"));){
			for (String entry = in.readLine(); entry != null; entry = in.readLine()){
				LookupTask task = new LookupTask(entry);
				Future<String> future = executor.submit(task);
				LogEntry result = new LogEntry(entry, future);
				results.add(result);
			}
		}

		//Start printing the results. This blocks each time a result isn't ready
		for (LogEntry result : results){
			try{
				System.out.println(result.future.get());
			} catch (InterupptedException | ExecutionException ex){
				System.out.println(result.original);
			}
		}

		executor.shutdown();
	}

	private static class LogEntry{
		String original;
		Future<String> future;

		LogEntry(String original, Future<String> future){
			this.original = original;
			this.future = future;
		}
	}
}

This improves the speed structure.

However, tehre is a downside to the design. Although it is much more efficient in speed,
it burns through a lot of memory. Cause Logfiles can be huge.

To avoid this, you could put output into a separate thread that shared the queue with the input thread.
Because early entries could be processed and output while the input was still being parsed,
the queue would not grow so large.

This gives another problem. That we need to have a separate signal to tell you
when the output was complete because an empty queue is no longer sufficient to prove
the job is complete.

The easiest way for this is to designate a manual counter and just compare input lines
and output lines (That they are equal, cause then we know we are up to speed).

URLs and URIs:

In the last chapter, you learned how to address hosts on the Interner via host names
and IP addresses. In this chapter, we increase the granuality by addressing resources,
any number of which may reside on any given host.

HTML is a hypertext markup language because it includes a way to specify links to other
documents identified by URLs. A URL unambigiously identifies the location of a resource
on the internet. A URL is the most common type of URI, or, uniform resource identifier.

A URI can identify a resource by its network location, as in a URL, or by its name,
number or other characteristics.

The URL class is the simplest way for a Java program to locate and retrieve data from
the network. You do not need to worry about the protocol being used or how to
communicate with the server, you simply tell Java the URL and it gets the data for you.

A URI is a uniform resource identifier. It could be anything, really. A file on a server,
a email address, a news message etc.

A resource is a thing that is identified by a URI. A URI is a string that identifies a Resource.
We need not worry about what a resource is, because the server gives us only a representation
of a resource in form of a byte array.

However, the representation of the resource may vary, as in file format, language etc.

We should always assign a URI to every entity that we find (every resource)

The Syntax of a URI is two-parted, with a scheme and a scheme-specific part, as follows:

scheme: scheme-specific-part

The syntax of the scheme-specific part depends on the scheme being used.
Current supported schemes are:

data //Base64-encoded data included directly in a link

file //a file on local disk

ftp //An FTP server

http //a WWW server using HTML

mailto //An email address

magnet //A resource downloadable via peer-to-peer networks such as BitTorrent

telnet //a connection to a Telnet-based service

urn //A uniform resource name

In additiona, Java uses a wide array of nonstandard custom schemes such as rmi, jar,
jndi, and doc.

There is no specific form for the scheme-specific part, albeit it generally is:

||authority|path?query

The authority part names the part responsible for resolving the rest of the URI.
For instance, the URI http://www.ieft.org/rfc/rfc3986.txt has the scheme http,
the authority www.ietf.org, and the path /rfc/rfc3986.txt (initial slash included)

This means that the server www.ietf.org is responsible for mapping the path /rfc/rfc3986.txt
to a resource. This URI does not have a query part. 

an example of a Query part would be the end of Youtueb addresses or what not, which is the 
part of which comes after, and including, the ?.

Most current examples of URIs use an Internet Host as an Authority, future schemeas might not.
However, if the authority is a internet host, optional username and passwords may be provided for
more specificity.

An example:

ftp://mp3:mp3@ci43198-a.ashvil1.nc.home.com:33/VanHalen-Jump.mp3 has the authority
of everything except the ftp part.

It has the username of mp3, password mp3, host is ci43198-a.ashvil1.nc.home.com, and the port 33.
it has the scheme ftp and the path /VanHalen-Jump.mp3

Including the PW in the URI is silly, unless everyone needs to know it.

The path is the String of which the Authority uses to identify resources.

It uses . and .. to navigate dirs as per Unix standards, and also /,
these were derived from the UNIX system where the Web and URLs were invented.

The path, however, may be extracting info from a DB, as in, not being
an actual part in on the local system.

For example: http://www.amazon.com/exec/obidos/ISBN%3D1565924851/cafeaulaitA/002-3777605-3043449

The isbn part is the book from the DB by it's ISBN number, cafeAulaitA is referal to who
gets the referall fee of purchases, and the last part is a session key used to
track the visitor's path through the site.

Some URI's aren't at all hierachybased, tho. At least in a filesystem sense. For example,
snews://secnews.netscape.com/netscape.devs-java has a path of /netscape.devs-java. Although
theres some hiearchy to the newsgroup names indicated by the period between netscape and
devs-java, it's not encoded as part of the URL.

If we do not convert special characters that are out of ASCII formats,
we define a IRI, a internationalized resource identifier, but this is faulty,
as most protocols and software expect ASCII URIs.

If you wish to include special characters in URIs, such as / or @, we need to escape
them in their coresponding format, such as / becoming %2F

URLs:

A URL is a URI that, as well as identifying a resource, provides a specific network
location for the resource that a client can use to retrieve a repesentation
of that resource.

By constrast, a generic URI may tell you what a resource is, but not actually where
or how to get that resource. Which means that URIs identify resources, URLs can identify them
and retrieve them.

The network location in a URL usually includes the protocol to accesss that part, as per FTP or HTTP,
the hostname or IP address of the server, and the path to the resource on that server.
A typical URL looks like http://www.ibiblio.org/javafaq/javatutorial.html

This specifies that there is a dir called javafaq on the server www.ibiblio.org and that this
file can be accessed via the HTTP protocol.

The syntax of a URL is:

protocol:||userInfo@host:port|path?query#fragment

Protocol is another word used for Scheme in URI. URI is for URI RFC.
Java calls ir potocol.

In a URL, the protocol can be a number of things: file, ftp, http, https, magnet, telnet or
various other stuff.

The host part of a URL is the name of the server that provides the resources
you want. It can be a hostname such as www.oreilly.com or utopia.poly.edu or an
IP address, such as <blah>

the userInfo is optional login info for a server, which can contain username and pw.

Port number is also optional, can be omitted if it runs on default (port 80 for HTTP servers)

Togerher, the userInfo, host, and port constitutes the Authority.

The path points to a particular resource on the specified server. It often
looks like a file system path such as /forum/index.php. However, it may or may not
actually map to the document root of the server, not nessecarily to the root
of the filesystem on the server.

As a rule, servers that are open to public, only show delimeted dirs as root dirs to
other remote machines. Meaning the specified dir becomes the document root,
to which all paths and files are relative.

The query string provides additional args for the server. It's commonly used
only in http URLs, where it contains form data for input to programs running
on the server.

Finally, the fragment references a particular part of the remote resource.
If the remote resource is HTML, the fragment identifier names an anchor
in the HTML document.

If the remote resource is XML, the fragment identifier is an Xpointer. Some
sources refer to the fragment part of the URL as a "section". Java refers
to it as a Ref.

Fragment identifier targets are created in HTML with id tags:

<h3 id="<blah>"></h3>

To refer to this point, a URL includes this by the entire URL and a #<blah>:

http://www.cafeaulait.org/javafaq.html#<blah>

Technically, if # is present with its fragment, its a URL reference, not a URL.
But Java does not distinguish between the two.

Relative URLs:

A URL tells a web browser alot about a document: the protocol used to retrieve the
document, the host where the document lives, and the path to the document on that
host. Most of this info is likely to be the same for other URLs that are referenced
in the document.

By this virtue, URLs can inherit protocols, paths etc. from their parent elemnets,
becoming relative URLs, instead of absolute ones.

For instance, assume we have a shorthanded a ref:

<a href="javafaq.html">

The browser then shorthandedly referes to <same url as before> + <a href link>,
meaning the total link becomes <whatever>/javafaq.html

If the path begins with /, it is relative to the document root, instead of 
the page. Meaning that it will replace the entire current relaive pathing,
and path from the document root.

An example:

<a href="/projects/ipv6/">

If we were on http://www.ibiblio.com/javafaq/javatutorial.html, we'd get:

http://www.ibiblio.com/projects/ipv6/

Relative URLs have a number of advantages, bust most importantly: They allow for serving
towards multiple protocols, such as FTP or HTTP. HTTP could be used for direct surfing and
FTP for mirroring the site. 

it also allows for entire trees of documents to be moved or copied from one site to another,
without breaking all the internal links.

The URL class:

The java.net.URL class is an abstraction of a Uniform Resource Locator such as http://www.lolcats.com or
whatever.

It inherits from java.lang.Object, and it is a final class, meaning it cannot be subclassed.

Rather than relying on inheritance to configure instances for different kinds of URLs, it uses
the stratergy design pattern. Protocol handlers are the stratergies, and the URL class itself
forms the context through which the different stratergies are selected.

Although storing a URL as a string would be trivial, java treats them as objects,
where each part (protocol, path, hostname, port, query string and fragment identifier) can be
set independantly.

URLs are immutable. After a URL object has been constructed, their fields do not change.

Creating new URLs:

Unlike the InetAddress objects since before, you can construct instances of java.net.URL.

A listing of the different constructors follow:

public URL(String url) throws MalformedURLException

public URL(String protocol, String hostname, String file) throws MalformedURLException

public URL(String protocol, String host, int port, String file) throws MalformedURLException

public URL(URL base, String relative) throws MalformedURLException

Which constructor you use depends on the information you have and the form it's in.
All these constructors throw a MalformedURLException if you try to create a 
URL for an unsupported protocol or if the URL is syntactically incorrect.

Exactly which protocols are supported is implementation dependent. The only
protocols that have been available in all VMs are http and file, and file is
unreliable.

Today, Java also supports https, jar and ftp. Some VMs support mailto and gopher as well
as some custom protocols like docs, netdoc, systemresource and verbatim used
internally by Java.

If the protocol you need isn't supported by a particular VM, you may be able
to install a protocol handler for that scheme to enable the URL class to speak
that protocol. In practice, this is way more trouble than it's worth.

You're better off using a lib that exposes a custom API just for that protocol.

Other than verifying it recognizes the URL scheme, Java does not check
the correctness of the URLs it contructs. All the forming responsibility goes
to the programmer.

Constructing a URL from a string:

The simplest URL constructor just takes an absolute URL in string form as its
single arg:

public URL(String url) throws MalformedURLException

Like all constructors, this may only be called after the new operator, and like
all URL constructors, it can throw a MalformedURL exception. 

An example:

try{
	URL u = new URL("http://www.audubon.org/");
} catch (MalformedURLException ex) {
	System.err.println(ex);
}

The next example, showcases how we could construct something to check
against what protocols a VM supports - by virtue of trying 15 different ones:

8 for standard ones, 3 for custom of various Java APIs, and 4 undocumented protocols used
internally by Java.

import java.net.*;

public class ProtocolTester{
	public static void main(String[] args){
		//Hypertext transfer protocol
		testProtocol("http://www.adc.org");

		//Secure http
		testProtocol("https://www.amazon.com/exec/obidos/order2/");

		//File transfer protocol
		testProtocol("ftp://ibiblio.org/pub/languages/java/javafaq/");

		//Simple mail tranfer protocol
		testProtocol("telnet://dibner.poly.edu/");

		//local file access
		testProtocol("file:///etc/passwd");

		//gopher
		testProtocol("gopher://gopher.anc.org.za/");

		//lightweight Directory Access protocol
		testProtocol("ldap://ldap.itd.umich.edu/o=University%20of%%20Michigan,c=US?postalAddress");

		//JAR
		testProtocol("jar:http://cafeulait.org/books/javaio/ioexamples/javaio.jar!" + "/com/macfaq/io/StreamCopier.class");

		//NFS, Network File System
		testProtocol("nfs://utopia.poly.edu/usr/tmp/");

		//a custom protocol for JDBC
		testProtocol("jdbc:mysql://luna.ibiblio.org:3306/NEWS");

		//rmi, a custom protocol for remote method invocation
		testProtocol("rmi://ibiblio.org/RenderEngine");

		//custom protocol for HotJava
		testProtocol("doc:/UsersGuide/release.html");
		testProtocol("netdoc:/UsersGuide/release.html");
		testProtocol("systemresource://www.adc.org/+/index.html");
		testProtocol("verbatim:http://www.adc.org");
	}

	private static void testProtocol(String url){
		try{
			URL u = new URL(url);
			System.out.println(u.getProtocol() + " is supported");
		} catch (MalformedURLException ex) {
			String protocol = url.substring(0, url.indexOf(':'));
			System.out.println(protocol + " is not supported"); 
		}
	}
}

The results of this program is dependant on the VM that runs it.
this is the result of Mac OS X with Java 7:

Is supported:

http
https
ftp
mailto
file
jar
netdoc

Is not supported:

telnet
gopher
ldap
nfs
jdbc
rmi
doc
systemresource
verbatrim

NOTE: Rmi and JDBC are supported in SQL formats in terms of packets there of,
it is not supported for URL formats, tho.

Dependant on which one we run, we can tell which one will work and won't.

Constructing a URL from its component parts:

You can also build a URL by specifying the protocol, the hostname and the file:

public URL(String protocol, String hostname, String file) throws MalformedURLException

This constructor sets the port to -1 so that the default port is used. The file
argument should begin with a slash and include a path, a filename and optioanlly
a fragment identifier.

An example:

try{
	URL u = new URL("http", "www.eff.org", "/blueribbon.html#intro");
} catch (MalformedURLException ex){
	throw new RuntimeException("SHould not occur, all VMs support http");
}

This creates a URL to http://www.eff.org/blueribbon.html#intro, using the default
port for the HTTP protocol (port 80). The file specification includes a reference
to a named anchor. The code catches the exception that would be thrown if the
VM did not support it, but in practice all do.

For the rare ocassion that the default port is not supported, we can feed in our own:

try{
	URL u = new URL("http", "fourier.dur.ac.uk", 8000, "/~dma3mjh/jsci");
} catch (MalformedURLException ex){
	throw new RuntimeException("shouldn't happen; all VMS recognize http");
}

builds: http://fourier.dur.ac.uk:8000/~dma3mjh/jsci/

Constructing relative URLs:

This constructor builds an absolute URL from a relative URL and a base URL:

public URL(URL base, String relative) throws MalformedURLException

For instance, you may be parsing an HTML document at http://www.ibiblio.org/javafaq/index.html
and encounter a link to a file called mailinglists.html with no further qualifying info.

In this case, you use the URL to the document that contains the link to provide the missing
info. The constructor computes the new URL as http://www.ibiblio.org/javafaq/mailinglists.html

For example:

try{
	URL u1 = new URL("http://www.ibiblio.org/javafaq/index.html");
	URL u2 = new URL(u1, "mailinglists.html");
} catch (MalformedURLException ex){
	System.err.println(ex);
}

This is especially useful for working with things in the same dir, where we have a base location
and then we just replace the last part with their filenames.

Other sources of URL objects:

Besides the constructors discussed here, a number of other methods in the Java class
library return URL objects. In applets, getDocumentBase() returns the URL of the page
that contains the applet and getCodeBase() returns the URL of the applet .class file.

The java.io.File class has a toURL() method that returns a file URL matching
the given file. The exact format of the URL returned by this method is platform
dependant. For example, on windows it may return something like:

file:/D:/JAVA/JNP4/05/ToURLTest.java

In practice, the toURL() file method is just, clunky, cause it depends on the platform
and is not interchangeable with other URLs, other versions of Java or other programs.

Class loaders are used not only to load classes but also to load resources such as images and 
audio files. The static ClassLoader.getSystemResource(String name) method returns a URL
from which a single resource can be read.

The ClassLoader.getSystemResource(String name) returns a Enumeration containing
a list of URLs from which the named resource can be read. And finally, the instance method
getResource(String name) searches th path used by the referenced class loader for a URL
to be named resource.

The URLs returned by these methods may be file URLs, HTTP URLs, or some other scheme.
The full path of the resource is a package qualified Java name with slashes instead
of periods such as:

/com/macfaq/sounds/swale.au or com/macfaq/images/headshot.jpg

The java VM will attempt to find the requested resource in the classpath,
potentionally inside a JAR archive.

There are a few other methods that return URL objects here and there, throughout the
class lib, but most are simple getter methods that return a URL, you probably already
know because you used it to construct the object in the first place, such as getPage() or getUrl().

Retrieving Data from a URL:

Naked URL's are not very exciting. What's interesting is the data contained in the 
documents they point to. The URL class has several methods that retrieve data from a URL:

public InputStream openStream() throws IOException

public URLConnection openConnection() throws IOException

public URLConnection openConnection(Proxy proxy) throws IOException

public Object getContent() throws IOException

public Object getContent(Class[] classes) throws IOException

The most basic and commonly used of these, is the openStream(), which
returns an InputStream from which you can read the data. If you need more
control over the download process, call openConnection() instead, which gives you 
a URLConnection which you can configure, and then get a InputStream from it.

We will bring this up later in Chapter 7.

Finally, you can ask the URL for its content with getContent() which
may give you a more complete object such as String or an Image. Then again,
it may just give you an InputStream anyway.

public final InputStream openStream() throws IOException

The openStream() method connects to the resource referenced by the URL,
performs any nessecary handshaking between the client and the server,
and returns an InputStream from which data can be read.

The data you get from this InputStream is the raw (uninterperted) content
the URL references. ASCII if you're reading an ASCII text file, raw HTML
if you're reading an HTML file, binary image data if you are reading an image file, etc.

It does not include any of the HTTP headers or any other protocol-related info.
You can read from this InputStream as you would read from any other InputStream.

For example:

try{
	URL u = new URL("http://www.lolcats.com");
	InputStream in = u.openStream();
	int c;
	while ((c = in.read()) != -1) system.out.write(c);
	in.close();
} catch (IOException ex){
	System.err.println(ex);
}

The preceeding code fragment catches an IOException, which also catches
the MalformedURLException that the URL constructor can throw, since MalformedURLException
subclasses IOException.

To close the stream, we do as follows:

try{
	URL u = new URL("http://www.lolcats.com");
	try (InputStream in = u.openStream()) {
		int c;
		while ((c = in.read()) != -1) System.out.write(c);
	}
} catch (IOException ex) {
	System.err.println(ex);
}

The next example, reads a URL from the commandline, opens a InputStream
from that URL, chains the resulting InputStream to an InputStreamReader using the
default encoding, and then uses InputStreamReader's read() method to
read successive chars from the file, each of which is printed on System.out.

That is, it prints the raw data located at the URL if the URL references an HTML file,
it outputs raw HTML.

import java.io.*;
import java.net.*;

public class SourceViewer{
	public static void main(String[] args){
		if (args.length > 0){
			InputStream in = null;
			try{
				//open a URL for reading
				URL u = new URL(args[0]);
				in = u.openStream();

				//Buffer the input to increase performance
				in = new BufferedInputStream(in);

				//Chain the inputstream to a reader
				Reader r = new InputStreamReader(in);
				int c;
				while ((c = r.read()) != -1) {
					System.out.println((char) c);
				}
			} catch (MalformedURLException ex){
				System.err.println(args[0] + " is not parsable URL");
			} catch (IOException ex){
				System.err.println(ex);
			} finally {
				if (in != null){
					try{
						in.close();
					} catch (IOException e){
						//ignore
					}
				}
			}
		}
	}
}

It will parse the HTML data from a website.

The problem with this program, is that it defaults to assume that the target is text.
It could be GIF, JPEG, mp3's etc.

And even if it does resolve to text, it might be so that it runs into the wrong encoding,
or that it's XML. Generally these are in the Head tag.
beyond this, Windows, Mac and Unixes interpet some chars between some ranges differently.

beyond this, the HTTP header has it's own encoding as well, You can't read this header
with the URL class, but you can with the URLConnection object returned by the openConnection()
method. Encoding detection and declaration is one of the hardest parts of Web programming.

public URLConnection openConnection() throws IOException

The openConnection() method opens a socket to the specified URL and returns a
URLConnection object. A URLConnection represents an open connection a network
resource. If the call fails, openConnection() throws an IOException.

For example:

try{
	URL u = new URL("https://news.ycombinator.com/");
	try{
		URLConnection uc = u.openConnection();
		InputStream in = uc.getInputStream();

		//Read from the connection
	} catch (IOException ex){
		System.err.println(ex);
	}
} catch (MalformedURLException ex){
	System.err.println(ex);
}

You should use this method when you want to communicate directly with the server.
The URLConnection gives you access to everything sent by the server: in addition
to the document itself in its raw form (e.g, HTML, plain text, binary image data),
you can access all the metadata specified by the protocol.

For example, if the scheme is HTTP or HTTPS, the URLConnection lets you access the
HTTP headers as well as the raw HTML. 

The URLConnection class also lets you write data to as well as read from
a URL - for instance, in order to send email to a mailto URL or post form data.
The URLConnection class will be the primary subject of Chapter 7.

An overloaded version of this method, specifies the proxy server of which
we pass the connection through:

public URLConnection openConnection(Proxy proxy) throws IOException

This overrides any proxy server set with the usual socksProxyHost, socksProxyPort,
http.proxyHost, http.proxyPort, http.nonProxyHosts and similar system properties.
If the protocol handler does not support proxies, the argument is ignored
and the connection is made directly if possible.

public final Object getContent() throws IOException

The getContent() method is the third way to download data referenced by a URL.
the getContent() method retrieves the data referenced by the URL and tries to make it
into some type of object. If the URL refers to some kind of text such as ASCII
or HTML file, the object returned is usually some sort of InputStream.

If the URL refers to an image, such as a GIF or JPEG file, getContent() usually 
returns a java.awt.ImageProducer. What unifies these two classes is that
they are not the thing themselves, but can construct the thing.

An example:

URL u = new URL("http://mesola.obspm.fr/");
Object o = u.getContent();
//Work with the object

getContent() operates by looking at the Content-type field in the header
of the data it gets from the server. If the server does not use MIME
headers or send an unfamiliar Content-type, getContent() returns some type
of InputStream from which the data can be read. An IOException is thrown
if it cannot be retrieved.

An example:

import java.io.*;
import java.net.*;

public class ContentGetter{
	public static void main(String[] args){
		if (args.length > 0){
			try{
				URL u = new URL(args[0]);
				Object o = u.getContent();
				System.out.println("I got a " + o.getClass().getName());
			} catch (MalformedURLException ex){
				//print that its not a parsable URL
			} catch (IOException ex){
				//print the error
			}
		}
	}
}

An example:

% java ContentGetter http://www.oreilly.com/
I got a sun.net.wwww.protocol.http.HttpURLConnection$HttpInputStream</programlisting>

The exact class may vary from one version of Java to the next, but it should be some
form of InputStream overall.

Here's what we get if we try to download a header image:

i got a sun.awt.image.URLImageSource</programListing>

Here's what you get when you try to load a Java applet using getContent():

%java ContentGetter http://www.cafeaulait.org/RelativeURLTest.class</userinput>
I got a sun.net.www.protocol.http.HttpURLConnection$HttpInputStream</programListing>

An audio:

I got a sun.applet.AppletAudioClip</programListing>

The last result is the most unusual because it is as close as the Java core API gets to
a class that represents a sound file. Its not just an interface of which you can
load the sound data.

It demonstrates the problem with getContent(), it's unpredictable. You may
never really know what you get from using it.

You could get a InputStream, you could get a ImageProducer or perhaps an AudioClip. 
This is where instanceof comes handy.

public final Object getContent(Class[] classes) throws IOException:

A URL's content handler may provide different views of a resource. This overloaded
variant of the getContent() method lets you choose which class you'd like the
content to be returned as. The method attempts to return the URL's content
in the first available format.

For instance, if you prefer an HTML file to be returned as a String, but your 
second choise is a Reader and your third choice is an InputStream write:

URL u = new URL("http://www.nwu.org");
Class<?>[] types = new Class[3]; //Wildcard array
types[0] = String.class; //Case 0
types[1] = Reader.class; //case 1
types[2] = InputStream.class; //Case 2
Object o = u.getContent(types);

If the content handler knows how to return a string presentation
of the resource, then it returns a String. If it doesn't know 
how to return a string, it goes to the next, etc.

We then have to test the returned object:

if (o instanceof String){
	System.out.println(o);
} else if (o instanceof Reader){
	int c;
	Reader r = (Reader) o;
	while ((c = r.read()) != -1) System.out.println((char) c);
	r.close();
} else if(o instanceof InputStream){
	int c;
	InputStream in = (InputStream) o;
	while ((c = in.read()) != -1) System.out.write(c);
	in.close();
} else {
	System.out.println("Error, unexepcted type");
}

Splitting a URL into Pieces:

URLs are composed of five pieces:

The scheme, also known as the protocol

The authority

The path

The fragment identifier, also known as the section of ref

The query string

For example, in the URL http://www.ibiblio.org/javafaq/books/jnp/index.html?isbn=<numbers>#toc,
http is the scheme, fragment identifier is toc, the query string is isbn=<numbers>.

However, not all URLs have all of these pieces, some only have the scheme, authority and path, etc.

The Authority may further be broken down into user info, host, and port.
For example, in the URL http://admin@www.blackstar.com:8080/, the authority is
admin@www.blackstar.com:8080. It has the user info admin, the host www.black-star.com and
the port 8080.

Read-only access to these parts of a URL is provided by nine public
methods: getFile(), getHost(), getPort(), getProtocol(), getRef(), getQuery(), getPath(), getUserInfo(),
and getAuthority()

public String getProtocol()

the getProtocol() method returns a String containing the scheme of the URL (http, https or file).
For example, this prints https:

URL u = new Url("https://<something>");
System.out.println(u.getProtocol());

public String getHost():

The getHost() method returns a String containing the hostname of the URL.
For example, this code fragment prints xkcd.com:

URL u = new URl("https://xkcd.com/727/");
System.out.println(u.getHost());

public int getPort():

the getPort() method returns the port number specified in the URL as an int.
If no port was specified in the URL, getPort() returns -1 to signify it does not
specify the Port specifically and resorts to default port for the protocol.

public int getDefaultPort():

the getDefaultPort() method returns port used for this URL's protocol
when none is specified in the URL. If no default port is defined
for the protocol, then getdefaultPort returns -1.

For http it is 80, for FTP it's 21.	

public String getFile():

The getFile() method returns a String that contains the path portion of the URL.
Java does not break into seperate path and file parts, where everything from
the first / after the hostname until the character preceeding the # sign
that begins the fragment idnetifier is considered part of the file.

Example:

URL page = this.getDocumentBase();
System.out.println("This page path is " + page.getFile());

If there is no file part of the URL, java sets it to a Empty String.

public String getPath():

The getPath() method is a near synonym for getFile(), it returns the path
and file of the URL string. However, it does not include the Query string in the String.

public String getRef():

Returns the fragment ref part of a URL (The part after the #):

URL u = new URL("http://www.something.com/java/java.html#abcdef");

Will give abcdef, returns null if no fragment idetifier is present.

public String getQuery():

returns the query part of a URL, if present, which is the ?:

URL u = new URL("http://<blah>?category=piano");

will give category=piano

public String getUserInfo():

Gets the user info, if it's present. Such as PW and Username.

public String getAuthority():

The authority is the main part that resolves the URL. It consists
of user info, host and port.

Example:

ftp://mp3:mp3@138.247.121.61:21000/c%3a/

will give

mp3:mp3@138.247.121.61:21000.

However, it might also just be the most basic URL part.
It returns it in the most "true" part it can, as in, it includes as many of the
present parts of the entire authority that there is.

The following is an example of a program that splits a URL into all of it's parts:

import java.net.*;

public class URLSplitter{
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				URL u = new URL(args[i]);
				System.out.println("The url is " + u);
				System.out.println("The scheme is " + u.getProtocol);
				System.out.println("The user info is " + u.getUserInfo());

				String host = u.getHost();
				if (host != null){
					int atSign = host.indexOf('@');
					if (atsign != -1) host = host.substring(atSign+1);
					System.out.println("The host is " + host);
				} else{
					System.out.println("the host is null");
				}

				System.out.println("the port is " + u.getPort());
				System.out.println("The path is " + u.getPath());
				System.out.println("The ref is " + u.getRef());
				System.out.println("The query string is " + u.getQuery());
			} catch (MalformedURLException ex){
				System.err.println(args[i] + " is not a URL i understand");
			}
			System.out.println();
		}
	}
}

Equality and Comparison:

They are as expected when it comes to equals() and hashCode(). 
Except, the equals() attempts to resolve the hostname with a DNS resolution
first.

This means that equals() is a potentionally I/O blocking operation, thus, you should
not use it with Network connections. Avoid using java.util.HashMap for purposes
like this, instead, use URI and convert between URL/URI as nessecary.

However, the equals() stops at that point, and does not recognize past the point of
matching names, meaning that if you just throw on a port or what not, equals
will not say that they are equal, even if they share the same hostname.

It can, however, fill out www before the name, to equate them.

We also have the sameFile() comparison:

public boolean sameFile(URL other)

sameFile is much like equals(), but does not care for fragment identifiers,
meaning that URLs that are equal up to that point, are "equal", in terms of sameFile.

Conversion:

URL has three methods that convert an instance to another form: toString(),
toExternalForm() and toURI().

toString() and toExternalForm(), in case of URLs, is basically the same.
The only difference being that toString() is called implicitly, and 
toExternalForm() is called explicitly, which gives a URL that is readable.

We can also convert URLs to URI, with :

public URI toURI() throws URISyntaxException

The URI is the superior choise in terms of detail level, absolution,
conversion and aquisition of data about the URL.  We can store
URLs in hashtables and other data, if we wish, with the URI format,
since it's equals() is not blocking.

The only time URL should be used, is for downloading content from a server.

The URI class:

A URI is a generalization of a URL that includes not only Uniform Resource Locators
but also Uniform Resource Names (URNs). Most URIs used in practice are URLs, but
most specifications and standards such as XML are defined in terms of URIs.

In Java, URIs are represented by the java.net.URI class. This class differs from
the java.net.URL class in three important ways:

The URI class is purely about identification of resources and parsing of URIs.
It provides no methods to retrieve a representation of the resource identifier by its URI.

The URI is more conformant to relevant specifications than the URL class.

A URI object can store a relative URI. URLs absolutize them before storage.

In practice, URL object is a representation of an app layer protocol for network
retrieval, whereas a URI object is purely for String parsing and manipulation.

The URI class has no network retrieval capabilities. The URL has many
broken string conversion methods, however, thus, we should use URL
for data retrieval, and we use URI to have URL in a representatie state,
such as showing a XML namespace.

If we need  to convert them, we just use toURL() or toURI().

Constructing a URI:

URIs are built from Strings. It has the following constructors:

public URI(String uri) throws URISyntaxException

public URI(String scheme, String schemeSpecificPart, String fragment) throws URISyntaxException

public URI(String scheme, String host, String path, String fragment) throws URISyntaxException

public URI(String scheme, String authority, String path, String query, String fragment) throws URISyntaxException

public URI(String scheme, String userInfo, String host, int port, String path, String query, String fragment)
	throws URISyntaxException

The URI, unlike the URL, does not need a underlying protocol to resolve whatever is stored into it.
This means, that as long as whatever is put in adheres to the pattern of URI forming, you can
store the info in URIs.

An example:

URI voice = new URI("tel:+1-800-9988-9938");

URI web   = new URI("http://www.xml.com/pub/a/2003/09/17/stax.html#id=_hbc");

URI book  = new URI("urn:isbn:1-565-92870-9");

If the argument does not follow URI syntax rules, such as it beginning with colon,
it will throw an URISyntaxException.

It is a checked one, so catch it or declare that it throws it.

One syntax rule is not checked for URI, though, which is String formatting in terms
of letters. They need not adhere to ASCII letters. They can also allow for relative URIs,
meaning that we can put in almost anything.

The second constructor takes scheme specific parts is mostly used for nonhierarchial URIs.
The scheme is the URI's protocol, such as http, urn,tel and so forth.

It must consist of ASCII and digits and +-.., it must begin with a letter. passing
null for the first arg makes a relative URI:

URI absolute = new URI("http", "//www.ibiblio.org", null);

URI relative = new URI(null, "/javafaq/index.shtml", "today");

It is basically protocol, host and the fragment.

The scheme-specific part depends on the syntax of the URI scheme, it's 
one thing for an http URL, another for a mailto URL, and something else again
for a tel URI. Because the URI class encodes illegal chars with % escapes,
you cannot make any syntax error on this part.

The third argument is the fragment identifier, illegal chars are escaped, null
designates to skip fragment.

The third constructor, is used for hierarchial URIs such as http and ftp URLs. The host
and path together (seperated by a /) form the scheme-specific part for this URI.
For example:

URI today = new URI("http", "www.ibiblio.org", "/javafaq/index.html", "today");

Provides the URI: http://www.ibiblio.org/javafaq/index.html#today

If the parts fed in does not coherently make ap attern, such as making a absolute path
but it does not start with /, then it will throw an URISyntaxException.

The fourth is the same as the third, except with a query string:

URL today = new URI("http", "www.ibiblio.org", "/javafaq/index.html", 
	"referrer=cnet&date=2014-02-23", "today");

As usual, any unescapeable syntax errors cause a URISyntaxException to be thrown and
null can be passed to omit any of the args.

The fifth constructor is the master hierarchical URI constructor that the previous
two invoke. It divides the authority into seperate user info, host and port parts,
each of which has it's own syntax rules.

URI styles = new URI("ftp", "anonymous:elharo@ibiblio.org", "ftp.oreilly.com", 21, "/pub/stylesheet", null, null);

However, if we are truly certain of our URI, we can just use the URI.create(),
which accepts one large input:

URI styles = URI.create("ftp://anonymous:elharo%40ibiblio.org@ftp.oreilly.com:21/pub/stylesheet");

If the URI does prove to be malformed, a IllegalArgumentException is thrown. It is a runtime
exception.

The Parts of the URI:

A URI reference has up to three parts: a scheme, a scheme-specific part, and a fragment
identifier.

The general syntax is:

scheme:scheme-specific-part:fragment

If the scheme is omitted, the URI refernece is relative. If the fragment identifier
is omitted, the URI reference is a pure URI. The URI class has getter methods
that return these three parts of each URI object.

The getRawFoo() methods form return raw, encoded data, whilst getFoo() formats return
decoded formats:

public String getScheme()

public String getSchemeSpecificPart()

public String getRawSchemeSpecificPart()

public String getFragment()

public String getRawFragment()

There is no getRawScheme(), because the URI specification demands URI-legal
ASCII chars, excluding % signs.

These methods all return null if the particular URI object does not have 
the relevant component: for example, a relative URI without a scheme or an http
URI without a fragment identifier.

A URI that has a scheme is an absolute URI. A URI without a scheme is a relative one.
The isAbsolute() returns true if the URI is absolute, false if relative.

public boolean isAbsolute():

The details of the scheme-specific part vary depending on 
the type of the scheme. For example, in a tel URL, the scheme-specific
part has the syntax of a phone number.

However, in many useful URIs, including the very common file and http URLs,
the scheme-specific part has a particular hierarchial format divided into an
authority, a path and a query string.

The authority is further divided into user info, host and port.
The isOpaque() method returns false if the URI is hierarchial, true if it's
not hierarchial - that is, if it's opauqe:

public boolean isOpaque()

If the URI is opaque, i.e non hierarchial, you can only extract
scheme, scheme-specific parts, and fragment identifiers.

However, if the URI is hierarchial, there are getter methods for all
the different parts of a hierarchial URI:

public String getAuthority()

public String getFragment()

public String getHost()

public String getPath()

public String getPort()

public String getQuery()

public String getUserInfo

They all return the decoded varians, and if we want the encoded variants, we just
use the raw getters:

public String getRawAuthority()

public String getRawFragment()

public String getRawPath()

public String getRawQuery()

public String getRawUserInfo()

The URI class allows for non-ascii chars, even if the URI standard does not.
Meaning that you can get non-ascii chars through raw returnal. Unless they
were encoded in their construction to begin with.

There are no getRawPort() and getRawHost(), as they follow ASCII standards.

In the event that the specific URI does not contain this info - for instance,
the URI http://www.example.com has no user info, path, port or query string -
the relevant methods return null. getPort() is the single exception,
since it returns -1 on omitted ports.

For various tech reasons, Java can't always initially detect syntax errors in
the authority component. The immediate symptom of this failing is normally
an inability to return the individidual parts of the authority, port, host and user info.

In this even, you can call parseServerAuthority() to force the authority to be reparsed:

public URI parseServerAuthority() throws URISyntaxException

The original URI does not change (URI objects are immutable), but the URI returned
will have seperate authority parts for user info, host and port. If the authority cannot
be parsed, a URISyntaxException is thrown.

The following example splits a URI into each consistence part it has:

import java.net.*;

public class URISplitter{
	public static void main(String[] args){
		for(int i = 0; i < args.length; i++){
			try{
				URI u = new URI(args[i]);
				System.out.println("The URI is " + u);
				if (u.isOpaque()){
					System.out.println("This is an opaque URI.");
					System.out.println("The scheme is " + u.getScheme());
					System.out.println("The scheme specific part is " + u.getSchemeSpecificPart());
					System.out.println("The fragment ID is " + u.getFragment());
				} else {
					System.out.println("This is a hierarchial URI.");
					System.out.println("The scheme is " + u.getScheme());
					try{
						u = u.parseServerAuthority();
						System.out.println("The host is " + u.getHost());
						System.out.println("The user info is " + u.getUserInfo());
						System.out.println("The port is " + u.getPort());
					} catch (URISyntaxException ex){
						//Must be a registry based authority
						System.out.println("The authority is " + u.getAuthority());
					}
					System.out.println("The path is " + u.getPath());
					System.out.println("The query string is " + u.getQuery());
					System.out.println("The fragment ID is " + u.getFragment());
				}
			} catch (URISyntaxException ex){
				System.err.println(args[i] + " does not seem to be a valid URI");
			}
			System.out.println();
		}
	}
}

Resolving Relative URIs:

The URI class has three methods for converting back and forth between relative and absolute URIs:

public URI resolve(URI uri)

public URI resolve(String url)

public URI relativize(URI uri)

THe resolve() methods compare the URI argument to this URI and use it to consturct
a new URI object that wraps an absolute URI. For example:

URI absolute = new URI("http://www.example.com");

URI relative = new URI("images/logo.png");

URI resolved = absolute.resolve(relative);

After htis executes, resolved becomes the absolute form of the two combined:

http://www.example.com/images/logo.png

if the invoking URI does not contain an absolute URI itself, the resolve()
method resolves as much of the URI as it can and returns a new relative URI object as 
a result. Example:

URI top = new URI("javafaq/books/");
URI resolved = top.resolve("jnp3/examples/07/index.html");

After they've executed, resolved now contains the relative URI javafaq/books/jnp3/examples/07/index.html
with no scheme or authority.

We can go the other way as well, by extracting a relative link from an absolute one, with relativize:

URI absolute = new URI("http://www.example.com/images/logo.png");
URI top = new URI("http://www.example.com");
URI relative = top.relativize(absolute);

relative now contains images/logo.png

Equality and Comparison:

URIs are tested for equality pretty much as you'd expect. It's not quite
direct string comparison. Equal URIs must either both be hierarchial or opaque.

The scheme and authority is compared without casing. The rest of the URI
is case-sensitive, and decoded info is not discarded, meaning that a encoded URI
compared to a non-encoded, are not the same, according to equal.

The hashCode() is similar to that of Equal.

URI implements comparable, meaning they can be sorted, the ordering is based on
string comparison of the individual parts, in this sequence:

1. If the schemes are different, the schemes are compared, without considering case.

2. Otherwise, if the schemes are the same, a hierarhial URI is considered to be
less than an opaque URI with the same scheme.

3. If both URIs are opaque URIs, they're ordered according to their scheme-specific parts.

4. If both the scheme and the opaque scheme-specific parts are equal, the URIs are
compared by their fragments.

5. If both URIs are hierarchial, they're ordered according to their authority
components, which are themselves orderd according to user info, host and port, in that order.
Hosts are case insensitive.

6. If the schemes and the authority are equal, the path is used to distinguish them

7. If the paths are also equal, the query Strings are compared

8. If the query strings are equal, the fragments are compared.

URIs are not comparable to anything but themselves. Attempting to compare
them to other things, will cause a ClassCastException.

String Representations:

Two methods convert URI objecs to strings, toString() and toASCIIString():

public String toString()

public String toASCIIString()

The toString() method returns an unencoded string form of the URI (i.e chars
like  and \ are not percent escaped.) It will bring a correct IRI, but might not
bring a correct URI. Thus, it is good for displaying, but not data retrieval.

We should always use toASCIIString() when handling URIs, because it ensures that
people do not use the "unsecured" format of toString() with unescaped chars.
toASCIIString() escapes non-ASCII chars.

x-www-form-urlencoded:

One of the challenges faced by the designers of the Web was dealing with 
the differences between OS's. These differences can cause issues with
URLs: for example, some OS's allow spaces in filenames, some don't.

Most OS's won't complain about a # in a filename, but that is a fragment beginning
and end of filename in URL context.

Chars in a URL must come from ASCII sets, as follows:

A-Z, a-z, 0-9 and -_.!~*',

Chars like :/&?@#;$+=% may be used, but if they occur in a path or query,
they must be encoded.

The encoding is %<two hexadecimal numbers>. Space is so common, that it can be done as +
or %20

plus is encoded with %2B, the / # = & ? should be encoded when they are used as part
of a name, and not as a seperator between parts of the URL.

The URL class does NOT automatically encode strings. All encoding must be ensured manually.

URLEncoder:

To URL encode a string, pass the string and the char set name to the URLEncoder.encode():

String encoded = URLEncoder.encode("This*string*has*asterikslol", "UTF-8");

This returns a copy where all non-alphanumberical characters are converted into % sequences,
(except spaces, underscore, hyphen, period, and asteriks chars). It also encodes all non-ASCII
chars. The space is converted into a plus sign. This specific method is a bit overaggresive,
converting tildes, single quotes, excalamtion points, and parantheses to % escapes.

Although it allows you to choose the char-set, you should always go with UTF-8,
as it is compatible with most of the areas out of encodings.

The problem, with the encoder, is that it is mostly used in terms of Query requests against
servers, as you do not wish to break the URL with no regards to / signs and other 
important chars to which URLs use.

Meaning, that we must encode each part by ourselves.

Thus, assume we have:

https://www.google.com/search?=hl=en&as_q=Java&as_epq=I/O

We must encode it as follows:

String url = "https://www.google.com/search?";
url += URLEncoder.encode("hl", "UTF-8");
url += "=";
url += URLEncoder.encode("en", "UTF-8");
url += "&";
url += URLEncoder.encode("as_q", "UTF-8");
url += "=";
url += URLEncoder.encode("Java", "UTF-8");
url += "&";
url += URLEncoder.encode("as_epq", "UTF-8");
url += "=";
url += URLEncoder.encode("I/O", "UTF-8");

The above code builds the URL as we wanted it.

Even if we see that a set does not contain illegal chars, we should
encode them to be safe - as they will be variables, not constants.

The following is an example of a Query building class:

import java.io.UnsupportedEncodingException;
import java.net.URLEncoder;

public class QueryString{
	private StringBuilder query = new StringBuilder();

	public QueryString{

	}

	public synchronized void add(String name, String value){
		query.append('&');
		encode(name, value);
	}

	private synchronized void encode(String name, String value)
	{
		try{
			query.append(URLEncoder.encode(name, "UTF-8"));
			query.append("=");
			query.append(URLEncoder.encode(value, "UTF-8"));
		} catch (UnsupportedEncodingException ex) {
			throw new RuntimeException("Broken VM, does not support UTF-8");
		}
	}

	public synchronized String getQuery(){
		return query.toString();
	}

	@Override
	public String toString(){
		return getQuery();
	}
}

Using the previous example, we can now use our new class for it:

QueryString qs = new QueryString();
qs.add("hl", "en");
qs.add("as_q", "Java");
qs.add("as_epq", "I/O");
String url = "http://www.google.com/search?" + qs;
System.out.println(url);

URLDecoder:

There is of course a corresponding URLDecoder as well:

public static String decode(String s, String encoding) throws UnsupportedEncodingException

Since the URLEncoder does not touch non-escaped chars, you can pass entire URLs to it.

An example:

String input = "https://www.google.com/" + "search?hl=en&as_q=Java&as_epq=I%2FO";
String output = URLDecoder.decode(input, "UTF-8");
System.out.println(output);

Proxies:

Many systems access the Web and sometimes other non-HTTP parts of the internet
through proxies. A proxy server recieves a request from a remote server from a local
client. The proxy server makes the request to the remote server and forwards the result
back to the local client.

Sometimes this is done for security reasons, such as to prevent remote hosts from
learning private details about the local network config. Other times it's done to
prevent users from accessing forbidden sites by filtering outgoing requests
and limiting which sites can be viewed. For instance, an elementary school
might want to block acess to http://www.playboy.com. 

And still, other times, it can be done for performance reasons, to allow
multiple users to retrieve the same popular documents from a local cache rather
than making repeated downloads from the remote server.

Java programs based on the URL class can work through most common proxy servers
and protocols. Indeed, this is one reason you might want to choose to use that
URL class rather than rolling own HTTP or other client on top of raw sockets.

System Properties:

For basic Operations, all you have to do is set a few system properties to
point to the addresses of your local proxy servers. If you're using a pure
HTTP proxy, set http.proxyHost to the domain name or the IP address of your proxy
server and http.proxyPort to the port of the proxy server (defualt is 80).

There are several ways to do this, including calling System.setProperty() from 
within your Java code or using the -D options when launching the program.
This example sets the proxy server to 192.168.254.254 and port to 9k:

<programlisting format="linespecific" id="I_7_tt264">% <userinput moreinfo="none">
 java -Dhttp.proxyHost=192.168.254.254 -Dhttp.proxyPort=9000 </userinput>
<emphasis role="bolditalic">com.domain.Program</emphasis></programlisting>

If the proxy requires a username or a PW, you will need to install a authenticator.

If you want to exclude a host from being proxied and connect directly instead,
set the http.noProxyHosts system property to its hostname or IPaddress.
To exclude multiple hosts, seperate their names by vertical bars.

For example, this code proxies everything EXCEPT java.oreilly.com and xml.oreilly.com:

System.setProperty("http.proxyHost", "192.168.254.254");
System.setProperty("http.proxyPort", "9000");
System.setProperty("http.nonProxyHosts", "java.oreilly.com|xml.oreilly.com");

We can also wildcard the hosts within a specific domain or subdomain to denote
that we want to proxy everything except from that network:

% java -Dhttp.proxyHost=192.168.254.254 -Dhttp.nonProxyHosts=*.oreilly.com
<emphasis role="bolditalic">com.domain.Program</emphasis></programlisting>

If you are using an FTP proxy server, set the ftp.proxyHost, ftp.proxyPort and
ftp.nonProxyHosts props in the same way.

Java does not support any other application layer proxies, but if you're
using a transport layer SOCKS proxy for all TCP connections, you can idetify it
with the socksProxyHost and socksProxyPort system props. 

Java does not provide an option for non-proxying with SOCKS. It's an all or nothing
decision.

The Proxy Class:

The Proxy class allows for more fine-grained control of proxy servers from
within a Java program. Specifically, it allows you to choose different proxy
servers for different remote hosts. The proxies themselves are represented 
by instances of the java.net.Proxy class.

There are still only three kinds of proxies, HTTP, SOCKS and direct connections (no proxy),
represented by three constants in the Proxy.Type enum:

Proxy.Type.DIRECT

Proxy.Type.HTTP

Proxy.Type.SOCKS

Besides its type, the other important piece of info about a proxy is it's
address and port, given as a SocketAddress object. For example, this code
fragment creates a Proxy object representing an HTTP proxy server on port
80 of proxy.example.com:

SocketAddress address = new InetSocketAddress("proxy.example.com", 80);
Proxy proxy = new Proxy(Proxy.Type.HTTP, address);

Althought there is only three kinds of proxy objects, there can be many
proxies of the same type for different proxy servers on different hosts.

The ProxySelector class:

Each running VM has a single java.net.ProxySelector object it uses
to locate the proxy server for different connections. The default
ProxySelector merely inspects the various system properties and the URL's
protocol to decide how to connect to different hosts.

However, you can install your own subclass of ProxySelector in place of
the default selector and use it to choose different proxies based on protocol,
host, path, time of day, or other criteria.

The key to the class, is the select() method:

public abstract List<Proxy> select(URI uri)

Java passes this method a URI object (not a URL object), repesenting the host
to which a connection is needed. For connections made with the URL class,
this object typically has the form http://www.example.com/ or 
ftp://ftp.example.com/pub/files, for example.

For a pure TCP connection made with the Socket class, this URI will have
the form socket://host:port:, for instance, socket://www.example.com:80. 

The ProxySelector object then chooses the right proxies for this type
of object and returns them in a List<Proxy>

The second abstract method of this class that you must implement is the connectFailed():

public void connectFailed(URI uri, SocketAddress address, IOException ex);

This is a callback method used to warn a program that the proxy server isn't
actually making the connection. The next example, showcases a ProxySelector
that attempts to use the proxy server at proxy.example.com for all HTTP connections
unless the proxy server has previously failed to resolved a connection to that
particular URL, to which, it suggest a Direct connection.

Basically a proxyConnector that recalls what it can connect to:

import java.io.*;
import java.net.*;
import java.util.*;

public class LocalProxySelector extends ProxySelector {
	private List<URI> failed = new ArrayList<URI>();

	public List<Proxy> select(URI uri){
		List<Proxy> result = new ArrayList<Proxy>();

		if(failed.contains(uri) || !"http".equalsIgnoreCase(uri.getScheme())){
			result.add(Proxy.NO_PROXY);
		} else{
			SocketAddress proxyAddress = new InetSocketAddress("proxy.example.com", 8000);
			Proxy proxy = new Proxy(Proxy.Type.HTTP, proxyAddress);
			result.add(proxy);
		}

		return result;
	}

	public void connectFailed(URI uri, SocketAddress address, IOException ex){
		failed.add(uri);
	}
}


Each VM has exactly one ProxySelector, to change said proxySelector, pass the new one
to ProxySelector.setDefault():

ProxySelector selector = new LocalProxySelector();
ProxySelector.setDefault(selector);

From this point forward, all connections opened by that VM will ask the 
ProxySelector for the right proxy to use. You normally should not use 
this in code running in a shared environment.

For instance,  you wouldn't change the proxySelector in a servlet, because
that would change the ProxySelector for all servlets running in the same container.

Communicating with Server-Side Programs Through GET:

The URL class makes it easy for Java applets and applications to communicate
with server-side programs such as CGIs, servlets, PHP pages and other that use the
GET method. 

Server-side programs that use the POST method require the URLConnection class and
are discussed later.

All you need to know is what combination of names and values the program expects
to recieve. Then you can construct a URL with a query string that provides the
requsite names and values. 

All names and values must be x-www-form-url-encoded - as by the URLEncoder.encode() method.

There are a number of ways to determine the exact syntax for a query string
that talks to a particular program. If you've written the server side program
yourself, you already know the name-value pairs it expects. If you've installed
a third-party program on your own server, the documentation of said program will tell you.

if you're talking to a documented external network API such as the eBay Shopping API,
that service usually tells you.

Many programs are designed to process form input. If this is the case,
it's straight forward to figure out what input the program expects. 
The method the form uses should be the value of the METHOD attribute of the FORM element.

This value should either be GET; to which case you use this described here, and if it's POST,
you use the one in chapter 7.

The part of the URL that preceeds the query string is given by the value of the 
ACTION attribute of the FORM element. Note that this may be a relative URL,
which case you'll need to determine the coresponding absolute URL.

Finally, the names in the name-value pairs are simply the values of the NAME
attributes of the INPUt elements. The values of these pairs are whatever the 
user types into the form.

For example, consider this HTML form for the local search engine on a site.
You can see that it uses a GET method. The program that processes the form
is accessed via the URL http://www.google.com/search, it has four
values, three of which are default:

<form name="search" action="http://www.google.com/search" method="get">
	<input name="q" />
	<input type="hidden" value="cafeconleche.org" name="domains" />
	<input type="hidden" name="sitesearch" value="cafeonleche.org" />
	<input type="hidden" name="sitesearch2" value="cafeconleche.org" />
	 <br />
	 <input type="image" height="22" width="55"
	   src="images/search_blue.gif" alt="search" border="0"
	   name="search-image" />
</form>

The type of the INPUT field doesn't matter. For instance, it does not matter
if its a set of checkboxes, a pop-up list, or a textfield. Only the name of
each INPUT field and the value you give it is significant. The submit input 
tells the web browser when to send the data but does not give the server any extra
info.

Sometimes, you find hidden INPUT fields that must have particular required
default values. This form has three hidden INPUT fields. There are many
different form tags in HTML that produces pop-up menus, radio buttons etc.

however, although these input widgets appear different to the user, the format
of data they send to the server is the same. Each form element provides a name
and a encoded String value.

In some cases, the program you're talking to may not be able to handle arbitrary
text strings for value of particular inputs. However, since the form is 
meant to be read and filled in by human beings, it should provide enough
clues to as of what input is expected.

Sometimes, there may not be forms, but just links to follow - to which
you just have to experiment what values are accepted and not.

You need not do this in Java, you can just hammer in the address bar.
The reason we do this is to protect against Injections and similar attacks.

Regardless of how you determine the set of name-value pairs the server expects, 
communicating with it once you know them is simple. All you have to do
is create a query string that includes the necessary name-value pairs,
then form a URL that includes that query string.

Send the Query string to the server and read its response using the same
methods you use to connect to a server and retrieve a static HTML page.
There's no special protocol to follow once the URL is constructed. 

There is, however, a special protocol for POST methods, which you must
follow.

To demonstrate this procedure, let's write a very simple command-line
program to look up topics in the Open dir.

On the Sit, there is a search field, which has its result sent to
http://search.dmoz.org/cgi-bin/search,which does the search.
The HTML looks like:

<form class="center mblem" action="search" method="GET">
	<input style="vertical-align:middle;" size="45" name="q" value="" class="qN">
	<input style="vertical-align:middle; *padding-top:1px;" value="Search"
			class="btn" type="submit">
	<a href="search?type=advanced"><span class="advN">advanced</span></a>
</form>

There are only two input fields in this form: the Submit Button and a text field
named q. Thus, to submit a search request to the Open Dir, you just need to
append q=searchTerm to http://www.dmoz.org/search. For example, to search for "java",
you would open the connection to the URL http://www.dmoz.org/search/?q=java and 
read the resulting input stream.

The following example, does this:

import java.io.*;
import java.net.*;

public class DMoz {
	public static void main(String[] args){
		String target = "";
		for (int i = 0; i < args.length; i++){
			target += args[i] + " ";
		}
		target = target.trim();

		QueryString query = new QueryString();
		query.add("q", target);

		try{
			URL u = new URL("http://www.dmoz.org/search/q?" + query);
			try(InputStream in = new BufferedInputStream(u.openStream())){
				InputStreamReader theHTML = new InputStreamReader(in);
				int c;
				while ((c = theHTML.read()) != -1){
					System.out.print((char) c);
				}
			}
		} catch (MalformedURLException ex){
			System.err.println(ex);
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

Of course, a lot more effort could be expended on parsing and displaying 
the results. 

Accessing Password-Protected Sites:

Many popular sites require a username and password for access. 
Some sites, such as the W3C member pages, implement this through HTTP authentication.
others, such as the New York Times website, implement it through cookies and HTML forms.

Java's URL class can access sites that use HTTP authentication, although you'll of course
need to tell it which username and password to use.

Supporting sites that use nonstandard, cookie-based authentication is more challenging,
not least because this varies a lot from one site to another. Implementing cookie
authentication is hard short of implementing a complete web browser with full HTML
forms and cookie support; We will discuss Javas cookie support later on.

Accessing sites that use HTTP authentication is much easier.

The Authenticator Class:

The java.net package includes an Authenticator class you can use to
provide a username nad password for sites that protect themselves using HTTP authentication:

public abstract class Authenticator extends Object

Since Authenticator is an abstract class, you must subclass it. Different subclasses
may retrieve the info in different ways. For example, a character mode program
might just ask the user to type the username and password on System.in.

A gui would put a dialog box and have a automated bot read the username from a encrypter file.

To make the URL class use the subclass, install it as the default authenticator by
passing it to the static Authenticator.setDefault() method:

public static void setDefault(Authenticator a)

For example, if you've written an Authenticator subclass named DialogAuthenticator,
you'd install it like this:

Authenticator.setDefault(new DialogAuthenticator());

You only need to do this once. From this point forward, when the URL class needs
a username and PW, it will ask the DialogAuthenticator using the static Authenticator.requestPasswordAuthentication() method:

public static PasswordAuthentication requestPasswordAuthentication(InetAddress address, int port,
	String protocol, String prompt, String scheme) throws SecurityException

The address argument is the host for which authentication is required. The port 
argument is the port on that host, and the protocol argument is the application layer
protocol by which the site is being accessed.

The HTTP server provides the prompt. It's servers such as www.ibiblio.org have multiple realms,
each of which requires different usernames and passwords).

the scheme is the authentication scheme being used. (Here the word scheme is not being
used as a synonym for protocol. IN this context, it is a HTTP authentication scheme.)

untrusted applets are not allowed to ask the user for a name and a password. Trusted
applets can do so, but only if they posses the requestPasswordAuthentication Net Permission.
Otherwise, Authenticator.requestPasswordAuthentication() throws a SecurityException

The authenticator subclass must override the getPasswordAuthentication() method.
Inside this method, you collect the username and password from the user or some
other source and return it as an instance of the java.net.PasswordAuthentication class:

protected PasswordAuthentication getPasswordAuthentication()

If you don't want to authenticate this request, return null, and Java tells the
server it does not know how to authenticate the connection. If you submit
an incorrect username or password, Java will call getPasswordAuthentication()
again to give you another chance to provide the PW.

You normally have 5 tries, then the openStream() throws a ProtocolException.

Usernames and PWs are cached within the same VM session. Once you set the
correct PW for a realm, you shouldn't be asked for it again unless you've
explicitly deleted the password by zeroing out the char array that contains it.

You can get more details about thq request by invoking any of these methods inherited
from the Authenticator superclass:

protected final InetAddress 	getRequestingSite()

protected final int 			getRequestingPort()

protected final String 			getRequestingProtocol()

protected final String 			getRequestingPrompt()

protected final String 			getRequestingScheme()

protected final String 			getRequestingHost()

protected final String 			getRequestingURL()

protected Authenticator.RequestorType getRequestorType()

These methods return info based on the last call to requestPasswordAuthentication() or return
null if that info is not available.

(if the port is not available, it returns -1)

The getRequestingURL() method returns the complete URL for which authentication
has been requested - an important detail if a site uses different names and passwords
for different files.

the GetRequestorType() returns either Authenticator.RequestorType.PROXY or Authenticator.RequestorType.SERVER
to indicate wether its a proxy or a server that is requesting the info.

The PasswordAuthentication Class:

PasswordAuthentication is a very simple final class that supports two read-only-properties:
username and password. The username is a String. The Password is a Char array so that
the password can be erased when it is no longer needed.

A String would have to wait to be garbage collected before it could be erased,
and even then it might still exist somewhere in memory on the local system, possibly
even on disk if the block of memory that contained it had been swapped out to virtual memory
at one point.

Both username and password is used in the constructor:

public PasswordAuthentication(String userName, char[] password);

Each is accessed via a getter method:

public String getUserName()

public char[] getPassword()

The JPasswordField class:

One useful tool for asking users for their PWs in a more or less
secure fashion is the JPasswordField component from Swing:

public class JPasswordField extends JTextField;

This lightweight component behaves almost exactly like a text field.
However, anything the user types into it is echoed as an asterisk. This way,
the PW is masked against others looking.

JPasswordField also stores the password as a char array so that when you're done
with the password, you can overwrite it with zeros. It provides the getPassword()
method to return this:

public char[] getPassword()

Otherwise, you mostly use the methods inherited from the JTextField superclass.
What follows is an example of making a Authenticator in Swing:

import java.awt.*;
import java.awt.event.*;
import java.net.*;
import java.swing.*;

public class DialogAuthenticator extends Authenticator {
	private JDialog passwordDialog;
	private JTextField usernameField = new JTextField(20);
	private JPasswordField passwordField = new JPasswordField(20);
	private JButton okButton = new JButton("OK");
	private JButton cancelButton = new JButton("Cancel");

	private JLabel mainLabel = new JLabel("Please enter username and PW: ");

	public DialogAuthenticator(){
		this("", new JFrame());
	}

	public DialogAuthenticator(String userName) {
		this(username, new JFrame());
	}

	public DialogAuthenticator(JFrame parent){
		this("", parent);
	}

	public DialogAuthenticator(String username, JFrame parent) {
		this.passwordDialog = new JDialog(parent, true);
		Container pane = passwordDialog.getContentPane();
		pane.setLayout(new GridLayout(4, 1));

		JLabel userLabel = new JLabel("Username: ");
		JLabel passwordLabel = new JLabel("Password: ");

		pane.add(mainLabel);
		JPanel p2 = new JPanel();
		p2.add(userLabel);

		p2.add(usernameField);
		usernameField.setText(userName);
		pane.add(p2);

		JPanel p3 = new JPanel();
		p3.add(passwordLabel);
		p3.add(passwordField);
		pane.add(p3);

		JPanel p4 = new JPanel();
		p4.add(okButton);
		p4.add(cancelButton);
		pane.add(p4);
		passwordDialog.pack();

		ActionListener al = new OKResponse();

		okButton.addActionListener(al);
		usernameField.addActionListener(al);
		passwordField.addActionListener(al);

		cancelButton.addActionListener(new CancelResponse());
	}

	private void show(){
		String prompt = this.getRequestingPrompt();
		if (prompt == null){
			String site  = this.getRequestingSite().getHostName();
			String protocol = this.getRequestingProtocol();
			int port = this.getRequestingPort();
			if(site != null & protocol != null){
				prompt = protocol + "://" + site;
				if (port > 0) prompt += ":" + port;
			} else {
				prompt = "";
			}
		}

		mainLabel.setText("Please enter a username and password for " + prompt + ": ");
		passwordDialog.pack();
		passwordDialog.setVisible(true);
	}

	PasswordAuthentication response = null;

	class OKResponse implements ActionListener {
		@Override
		public void actionPerformed(ActionEvent e){
			passwordDialog.setVisible(true);

			//The pw is returned as a char array for security reasons
			char[] password = passwordField.getPassword();
			String username = usernameField.getText();

			passwordField.setText("");
			response = new PasswordAuthentication(username, password);
		}
	}

	class CancelResponse implements ActionListener{
		@Override
		public void actionPerformed(ActionEvent e){
			passwordDialog.setVisible(false);
			//Erase the PW
			passwordField.setText("");
			response = null;
		}
	}

	public PasswordAuthentication getPasswordAuthentication(){
		this.show();
		return this.response;
	}
}

A program to download password-protected web pages:

import java.io.*;
import java.net.*;

public class SecureSourceViewer{
	public static void main (String args[]){
		Authenticator.setDefault(new DialogAuthenticator());

		for (int i = 0; i < args.length ; i++){
			try{
				//Open the URL for reading
				URL u = new URL(args[i]);
				try (InputStream in = new BufferedInputStream(u.openStream())){
					//Chain the InputStream to a Reader
					Reader r = new InputStreamReader(in);
					int c;
					while ((c = r.read()) != -1) {
						System.out.print((char) c);
					}
				}
			} catch (MalformedURLException ex){
				System.err.println(args[0] + " is not a parseable URL");
			} catch (IOException ex) {
				System.err.println(ex);
			}

			//Graphic formatting
			System.out.println();
		}

		//Since we used the AWT, we have to explicitly exit
		System.exit(0);
	}
}

HTTP:

The Hypertext Transfer protocol (HTTP) is a standard that defines how a web client
talks to a server and how data is transferred from the server back to the client.

Although HTTP is usually thought of as a means of transfering HTML files and the pictures
embedded in them, HTTP is a data format agnostic. It can be used to transfer TIFF pictures,
Microsoft Word documents, Windows .exe files, or anything else that can be represented in bytes.

To write programs using HTTP, we need to understand it, first. We will go behind the scenes
to see what occurs when you write a web address, such as http://www.google.com and press enter.

The Protocol:

HTTP is the standard protocol for communication between web browsers and web servers.
HTTP specifies how a client and a server establishes a connection, how the client
requests data from the server, how the server responds to that request, and finally
how the connection is closed.

HTTP connections use the TCP/IP protocol for data transfer. For each request from client to server,
there is a sequence of four steps:

1. The client opens a TCP connection to the server on port 80, by default: Others may be defined
in the URL.

2. The client sends a message to the server requesting the resource at a specified path.
The request includes a header, and optionally (depending on the nature of the request)
a blank line followed by data for the request.

3. The server sends a response to the client. The response begins with a response code,
followed by a header full of metadata, a blank data, and the requested document or an error message.

4. The server closes the connection.

This is the basic HTTP 1.0 procedure. In HTTP 1.1 and later, multiple request and responses
can be sent in series over a single TCP connection. That is, step 2 and 3 can repeat
multiple times in between step 1 and 4. Furthermore, in HTTP 1.1, requests and responses
can be sent in multiple chunks. This is more scalable.

Each request and response has the same basic form: a header line, an HTTP header containing metadata,
a blank line, and then a message body. A typical client request looks something like this:

GET /index.html HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:20.0)
 Gecko/20100101 Firefox/20.0
Host: en.wikipedia.org
Connection: keep-alive
Accept-Language: en-US, en;q=0.5
Accept-Encoding: gzip, deflate
Accept: text/html, application/xhmtl+xml, application/xml;q=0.9, */*; q=0.8

Get requests like this one do not contain a message body, so the request ends with a blank line.

The first line is the request line, and includes a method,a path to a resource and the version of HTTP.

The method specifies the operation being requested. The GET method asks the server to return a representation
of a resource. /index.html is the path to the resource requested from the server. 

HTTP/1.1 is the version of the protocol that the client understands.

Althought the request line is all that is required, a client request usually includes other
information as well in a header. Each line takes the following form:

Keyword: Value

Keywords are not case sensitive. Values sometimes are and sometimes are not. Both keywords and values
should be ASCII only. If a value is too long, you can add a space or tab to the beginning of the next
line and continue it.

Lines in the header are terminated by carriage-return linefeed pair.

The first keyword in this example is User-Agent, which lets the server know what
browser is being used and allows it to send files optimized for the particular browser
type.

An example of saying that hte request is coming from 2.4 of Lynx browser:

User-Agent: Lynx/2.4 libwww/2.1.4

All but the oldest first generation browsers also include a Host field specifying the
server's name, which allows web servers to distinguish between different named
hosts served from the same IP address:

Host: www.cafeaulait.org

The last keyword in this example is Accept, which tells the server the types of 
data the client can handle (though servers often ignore this). For example,
the following line says that the client can handle four MIME media types, corresponding
to HTML documents, plain text and JPEG and GIF images.

Accept: text/html, text/plain, image/gif, image/jpeg

MIME types are classified at two levels: a type and a subtype. The type shows
very generally what kind of data is contained: is it a picture, text, or movie?

The subtype identifies the specific type of data: GIF image, JPEG image, TIFF image.

For example, HTML's content type is text/html; the type is text and the subtype is HTML.
The content type for a JPEG image is image/jpeg, the type is image, the subtype being jpeg.

In total, there are 8 top-level types:

text/* for human-readable words

image/* for pictures

model/* for 3d models such as VRML files

audio/* for sound

video/* for moving pictures, possibly including sound

application/* for binary data

message/* for protocol-specific envelopes such as email messages and HTTP responses

mutlipart/* for containers of multiple documents and resources

Each of these have many different subtypes.

The most current list of registered MIME types is available from http://www.iana.org/assignments/media-types/.

In addition, nonstandard custom types and subtypes can be freely defined as long as they begin with
x-. for example, Flash files are commonly assigned the type application/x-shockwave-flash

Finally, the request is terminated with a blank line - that is, two carriage return/linefeed pairs:

\r\n\r\n

Once the server sees that blank line, it begins sending its response to the client over 
the same connection. The response begins with a status line followed by a header describing
the response using the same "name: value" syntax as the request header, a blank line,
and the requested resource.

A typical successful response looks something like this:

HTTP/1.1 200 OK //200 is the code for file found or request was succesful
Date: Sun, 21 Apr 2013 15:12:46 GMT
Server: Apache
Connection: close
Content-Type: text/html; charset=ISO-8859-1
Content-length: 115

<html>
<head>
<title>
A sample HTML file
</title>
</head>
<body>
The rest of the document goes here
</body>
</html>

The first line indicates that the server is using a 1.1 HTTP protocol, followed by the response code
(200, request succesful)

The other head liners determine the date the request was made in the server's time frame,
the server software (Apache), a promise that the server will close the connection
when its finished sending, the MIME media type, and the length of the document delivered.

What follows, is a list of some of the most common response codes you might get:

Code and Message 		Meaning 	 						HttpURLConnection constant

1xx 					Informational 	 					N/A

100 Continue 			The server is prepared to accept
 						the request body and the client 
 						should send it; allows clients to
 						ask wether the server will accept
 						a request before they send a large
 						amount of data as part of the request.

101 Switching 			The server accepts the client's request N/A
	Protocols 			in the Upgrade header field to change
						the application protocol (e.g from HTTP
						to WebSockets)

2XX Successful 			Request Succeeded 					HTTP_OK

200 OK 					The most common response code. If the  HTTP_OK
						request method was GET or POST,
						the requested data is contained 
						in the response along with the 
						usual headers. If the request 
						method was HEAD, only the header
						info is included.

201 Created 			The server has created a resource  		HTTP_CREATED
						at the URL specified in the body of 
						the response. The client should now
						attempt to load that URL.
						This code is only sent in response
						to POST requests.

202 Accepted 			This rather uncommon response indicates 	HTTP_ACCEPTED
						that a request (generally from POST)
						is being processed, but the processing
						is not yet complete, so no response 
						can be returned. However, the server
						should return an HTML page that explains
						the sitaution to the user and provide
						an estimate of when the request is
						likely to complete and ideally,
						a link to a status monitor of some
						kind.

203 Non-authorative 	The resource representation was returned 	HTTP_NOT_AUTHORITATIVE
Information 			from a caching proxy or other local source
						and is not guaranteed to be up to date.

204 No Content 			The server has successfully processed the 	HTTP_NO_CONTENT
						request but has no information to send back
						to the client. This is normally the result
						of a poorly written form-processing program
						on the server that accepts data, but does 
						not return a response to the user.

205 Reset Content 		The server has successfully proccessed the 	HTTP_RESET
						request but has no information to send
						back to the client. Furthermore, the client
						should clean the form to which the request
						is sent.

206 Partial Content 	The server has returned the part of the  	HTTP_PARTIAL
						resource the client requested using
						the byte range extension to HTTP, rather
						than the whole document.

226 IM Used 			Response is delta encoded 					N/A

3XX Redirection 		Relocation and Redirection 					N/A

300 Multiple Choices 	The server is providing a list of  			HTTP_MULT_CHOICE
						different representations (e.g
						PostScript and PDF) for the 
						requested document. 

301 Moved Permanently 	The resource has moved to a new URL 		HTTP_MOVED_PERM
						The client should automatically
						load the resource at this URL and
						update any bookmarks that point
						to the old URL.

302 Moved Temporarily 	The resource is at a new URL temporarily, 	HTTP_MOVED_TEMP
						but its location will change again in
						the forseeable future; therefore, bookmarks
						should not be updated. Sometimes used by
						proxies that require the user to log in
						locally before accessing the Web.

303 See Other 			Generally used in response to a POST form 	HTTP_SEE_OTHER
						request, this code indicates that the user
						should retrieve a resource from a different
						URL using GET.

304 Not Modified 		The If-Modified-Since header indicates that HTTP_NOT_MODIFIED
						the client wants the document only if it has
						been recently updated. This status code is
						returned if the document has not been 
						updated. In this case, the Client should
						load the document from its cache.

305 Use Proxy 			The Location header field contains the 		HTTP_USE_PROXY 
						address of a proxy that will 
						serve the response.

307 Temporary 			Similar to 302 but without allowing the 	N/A
Redirect 				HTTP method to change

308 Permanent 			Similar to 301 but without allowing the 	N/A
Redirect 				HTTP method to change 

4XX 					Client Error

400 Bad Request 		The client request to the server used 		HTTP_BAD_REQUEST
						improper syntax. This is rather 
						unusual in normal web browsing but 
						more common in custom client debugging

401 Unauthorized 		Authorization, generally a username 	 	HTTP_UNAUTHORIZED
						and PW is required to access this page.
						Either a username and PW have not yet 
						been presented or the username and PW
						are invalid.

402 Payment Required 	Not used today, But may be used in the 		HTTP_PAYMENT_REQUIRED
						future to indicate payment needed.

403 Forbidden 			The server understood the request, but 		HTTP_FORBIDDEN
						is deliberately refusing to process it.
						Authorization will not help. this is 
						sometimes used when a client has 
						exceeded its quota.

404 Not Found 			This most common error response indicates 	HTTP_NOT_FOUND
						that the server cannot find the requested
						resource. It may indicate a bad link,
						a document that has moved with no forwarding
						address, a mistyped URL or something akin.

405 Method Not Allowed 	The request method is not allowed for the 	HTTP_BAD_METHOD
						specified resource; for instance, you tried
						to PUT a file on a web server that doesn't
						support PUT or tried to POST to a URI
						that only allows GET.

406 Not Acceptable 		The requested resource cannot be provided 	HTTP_NOT_ACCEPTABLE
						in a format the client is willing to accept,
						as indiated by the Accept field of the
						request HTTP header.

407 Proxy 				An intermediate Proxy server requires   	HTTP_PROXY_AUTH
Authentication  		authentication from the client, probably
Required 				in the form of a username or a PW, before
						it will retrieve the requested resource.

408 Request Timeout 	The client took too long to send the 		HTTP_CLIENT_TIMEOUT 
						request, perhaps because of
						network congestion.

409 Conflict 			A temporary conflict prevents the request 	HTTP_CONFLICT
						from being fullfilled; for instance, two
						clients are trying to PUT the same file
						at the same time.

410 Gone 				Like a 404, but stronger assertion to 		HTTP_GONE
						where the resource is. The resource
						has been removed deliberately, and will
						not be restored. Links to it should be 
						removed.

411 Length Required 	The client must, but did not, send a  		HTTP_LENGTH_REQUIRED
						Content-Length field in the client
						request HTTP header.

412 Precondition 		A condition for the request that the 		HTTP_PRECON_FAILED
Failed 					client specified in the request 
						HTTP header is not satisfied.

413 Request Entity 		The body of the client request is  			HTTP_ENTITY_TOO_LARGE
Too Large 				larger than the server is able to 
						process at this time.

414 Request-URI 		The URI of the request is too long. 		HTTP_REQ_TOO_LONG
Too Long 				This is important to prevent certain
						buffer overflow attacks.

415 Unsupported 		The server does not understand or 			HTTP_UNSUPPORTED_TYPE
Media Type 				Accept the MIME content type of 
						the request body.

416 Requested range 	The server cannot send the byte range 		N/A
Not Satisfiable 		the client requested.

417 Expectation Failed 	The server cannot meet the client's 		N/A
						expectation given in a Expect-
						request header field.

418 I'm a teapot 		Attempting to brew coffee with a teapot.(?) N/A

420 Enhance Your Calm 	The server is limit the request. Nonstandard, N/A
						used only by Twitter.

422 Unprocessable  		The content type of the request  			N/A
Entity 					body is recognized, and the body
						is syntactically correct, but none
						theless the server can't proccess
						it

424 Failed  			Request failed as a result of the failure 	N/A
Dependency 				of a previous request

426 Upgrade 			Client is using a too old or insecure 		N/A
Required 				version of the HTTP protocol.

428 Precondition 		Request must supply an If-Match header. 	N/A
Required

429 Too Many 			The client is being rated limited and  		N/A
Requests 				should slow down  

431 Request 			Either the header as a whole is too large, 	N/A
Header Fields 			or one specific header field is too large.
Too Large

451 Unavailable 		Experimental; the server is prohibited by 	N/A
For Legal Reasons 		law from serving the request.

5XX 					Server Error.

500 Internal Server 	An unexpected condition occurred that the 	HTTP_SERVER_ERROR
Error  					server does not know how to handle. 		HTTP_INTERNAL_ERROR

501 Not Implemented 	The server does not have a feature that 	HTTP_NOT_IMPLEMENTED
						is needed to fullfill this request.
						A server that cannot handle PUT requests
						might send this response to a client that
						tried to PUT form data to it.

502 Bad Gateway 		The code is applicable only to servers  	HTTP_BAD_GATEWAY
						that act as proxies or gateways. It
						indicates that the proxy recieved an
						invalid response from a server 
						it was connecting to in an effort
						to fullfill the request.

503 Service 			The server is temporarily unable to handle 	HTTP_UNAVAILABLE
Unavailable 			the request, perhaps due to overloading or
						maintenance.

504 Gateway 			The proxy server did not recieve a response HTTP_GATEWAY_TIMEOUT
Timeout 				from the upstream server within a reasonable
						amount of time, so it can't send the desired
						response to the client.

505 HTTP Version 		The server does not support the version of 	HTTP_VERSION
Not Supported 			HTTP the client is using (e.g, the as-yet
						nonexistent HTTP 2.0)

507 Insufficient 		Server does not have enough space to store the supplied 
Storage 				request entity; typically used for POST or PUT.

511 Network 			The client needs to authenticate to gain 	N/A
Authentication 			network access (e.g, on a hotel wireless network)
Required

Regardless of version, a response code from 100 to 199 always indicates
an informational response, 200 to 299 always indicates success,
300 to 399 always indicates redirection,
400 to 499 always indicates a client error,
500 to 599 indicates a server error.

Keep-Alive:

HTTP 1.0 opens a new connection for each request. In practice, the
time taken to open and close all the connections in a typical web 
session can outweigh the time taken to transmit the data, especially
for sessions with many small documents.

This is even more problematic for encrypted HTTPS connections
using SSL or TLS, because the handshake to setup a secure socket is substanstially
more work than setting up a regular socket.

In HTTP 1.1 and later, the server doesn't have to close the socket
after it sends its response. It can leave it open and wait for a new request
from the client on the same socket.

Multiple requests and responses can be sent in series over a single TCP connection.
However, the lockstep pattern of a client request followed by a server response
remains the same.

A client indicates that it's willing to reuse a socket by including a Connection
field in the HTTP request header with the value Keep-Alive:

Connection: Keep-Alive

The URL class transparently supports HTTP Keep-Alive unless explicitly
turned off. That is, it will reuse a socket if you connect to the same
server again before the server has closed  the connection.

You can control Java's use of HTTP Keep-Alive with several system
properties:

Set http.keepAlive to "true or false" to enable/disable HTTP Keep-Alive.
(It is enabled by default)

Set http.maxConnections to the number of sockets you're willing to hold
open at one time. The default is 5.

Set http.keepAlive.remainingData to true to let Java clean up after abandoned
connections. It is false by default.

Set sun.net.http.errorstream.enableBuffering to true to attempt to buffer the
relativily short error streams from 400- and 500- level responses, so the
connection can be freed up for reuse sooner. It is false by default.

Set sun.net.http.errorstream.bufferSize to the number of milliseconds 
before timing out a read from the error stream. It is 300 millisecons by default.

The defaults are reasonable, except that you probably wish to set sun.net.http.errorstream.enableBuffering
to true unless you want to read the error streams from failed requests.

HTTP 2.0, which is mostly based on the SPDY-protocol invented at Google,
further optimizes HTTP transfers through header compression, pipelining requests and responses,
and asynch connection multiplexing. However, these optimizations are usually performed in
a translation layer that shields application programmers from the details, so the code
you write will still mostly follow the steps 1-4. Nothing should have to change 
upon the introduction of HTTP 2.0

HTTP Methods:

Communication with an HTTP server follows a request-response pattern: one stateless
request followed by one stateless response. Each HTTP request has two or three parts:

A start line containing the HTTP method and a path to the resource on which the 
method should be executed

A header of name-value fields that provide meta-information such as authentication
credentials and preferred formats to be used in the request

A request body containing a representation of a resource (POST and PUT only)

There are four main HTTP methods, four verbs, if you will, that identify the
operations that can be performed:

GET, POST, PUT, DELETE

If that seems like too few, it is because HTTP puts emphasis on the nouns,
the resources defined by the URI.

The uniform interface provided by these four methods is sufficient for
nearly all practical purposes.

Generally, they are as follows:

GET:

Retrieves a representation of a resource. GET is side-effect free,
and can be repeated without concern if it fails. Furthermore, its output
is often cached, though that can be controlled with the right headers,
as we will see soon.

In a proper system, GET requests can be bookmarked and prefetched without
concern. For example, one should not allow a file to be deleted merely
by following a link because a Browser may GET all links on a page before
the user asks it to.

By contrast, a well-behaved browser or web spider will not POST to a link
without explicit user action.

PUT:

Uploads a representation of a resource to a server at a known URL.
It is not side-effect free, but it is idempotent. That means, it can
be repeated without risk of consequence in failure.

I.e, putting the same file in the same place on the same server twice
in a row leaves the server in the same state as doing it twice.

DELETE:

The DELETE method removes a resource from a specified URL. It too,
is not side-effect free, but is idempotent. (Even if failure occurs,
it matters not).

If we end up in a situation of uncertaininy to the state of having removed
a file, we just run removal again on that file.

POST:

The POST method is the most general. It too uploads a representation
of a resource to a server at a known URL, but it does not specify
what the server is to do with the just uploaded file.

For example, it may not have to make it available at the target URL,
but may instead move it to a different URL. Or the server might
use the data to update the state of one or more completely different resources.

POST should be used for unsafe operations that should not be repeated,
such as making a purchase.

Because GET requests include all necessary info in the URL, they can be bookmarked,
linked to, spidered, and so forth.

POST, PUT, and DELETE, cannot. This is deliberate. GET is intended for noncommitial actions,
like browsing a static webpage or adding an item to a shop cart.

However, placing the Order, should be a POST request, as it is a commiting action.
That is why, if a webpage uses POST, warn you, when you route back to a earlier
part, as it may indicate duplication of action.

In practice, POST is way overused on the Web today. Any safe operation that
does not commit the user to anything should use GET rather than POST.
Only commiting actions should use POST.

One sometimes mistaken reason for preferring POST over GET is when forms
require large amounts of input. There is a outdated misconception that
browsers can only work with query strings of a few hundred bytes.

In todays society, we can support up to 2k length chars of a URL, 
if you have more form data to submit than that, you may need to support POST.
But safe operations should still prefer GET for nonbrowser clients.

We usually only exceed this limit when we upload data to a server to
create a new resource, rather than merely location an existing resource
on the server; and in these cases POST or PUT is usually the right answer anyway.

In addition to these four main HTTP methods, a few others are used in special
circumstances. The most common of them, being HEAD, which acts like GET, except it
only returns the header for the resource, not the actual Data.

This is commonly used for checking modification dates, to see wether a stored copy
in the local cache is still valid.

The other two that Java supports, is OPTIONS (which lets the client ask the server
what it can do with the specified resource) and TRACE (echoes back the client request
for debugging purposes, especially for when proxies are being wierd.)

Differnet servers also recognize other nonstandard methods like COPY and MOVE,
but Java does not send these.

The URL class described in the previous chapter uses GET to communicate
with HTTP servers. The URLConnection class can use all 4 of these methods.

The Request Body:

The GET method retrieves a representation of a resource identified by a URL.
The exact location of the resource you want to GET from a server is
specified by the various parts of the path and query string.

How different paths and query strings map to different resources is determined
by the server. The URL class doesn't really care about that. As long as
it knows the URL, it can download from it.

POST and PUT are more complex. In these cases, the client supplies the represetation
of the resource, in addition to the path and the query string. The represetation
of the resource is sent in the body of the request, after the header.

That is, it sends these four items in order:

1. A starter line including the method, path and query string, and HTTP version.

2. An HTTP header

3. A blank line (two successive carriage return/linefeed pairs)

4. The body

For example, this POST request sends form data to a server:

POST /cgi-bin/register.pl HTTP 1.0
Date: Sun, 27 Apr 2013 12:32:36
Host: www.cafeaulait.org
Content-type: application/x-www-form-urlencoded
Content-length: 54

username=Elliotte+Harold&email=elharo%40ibiblio.org

In this example, the body contains an application/x-www-form-urlencoded data,
but that's just one possibility. In general, the body can contain arbitrary bytes.
However, the HTTP header should include two fields that specify the nature of the body:

A Content-length field that specifies how many bytes are in the body (54 in the preceeding)

A Content-type field that specifies the MIME media type of the bytes (application/x-www-form-urlencoded
in the preceeding)

The application/x-www-form-urlencoded MIME type used in the preceeding example is
common because it's how web browsers encode most form submissions.
Thus, it's used by a lot of server-side programs that talk to browsers.

However, it's hardly the only possible type you can send in the body. For example,
a camera uploading a picture to a photo sharing site can send image/jpeg.
A text editor might send text/html. It's all just bytes in the end.

For example, here's a PUT request that uploads an ATOM document:

PUT /blog/software-development/the-power-of-pomodoros/HTTP/1.1
Host: elharo.com
User-Agent: AtomMaker/1.0
Authorization: Basic ZGFmZnk6c2VjZXJldA==
Content-Type: application/atom+xml;type=entry
Content-length: 322

<?xml version="1.0">
<entry xmlns="http://www.w3.org/2005/Atom">
	<title>The Power of Pomodoros</title>
	<id>urn:uuid:101a41a6-772b-4d9b-8afb-ccfb01d77499</id>
	<updated>2013-02-22T19:40:52Z</updated>
	<author><name>Elliotte Harold</name></author>
	<content>I hadn't paid much attention to Pomodoro..</content>
</entry>

Cookies:

Many websites use small strings of text known as cookies to store persistent
client-side between connections. Cookies are passed from server to client
and back again in the HTTP headers of requests and responses.

Cookies can be used by a server to indicate session IDs, shopping cart contents,
login credentials, user preferences, and more. For instance, a cookie set by
an online bookstore might have the value ISBN=0802099912&price=$34.95 to specify
a book that i've put in my shopping cart.

However, more likely, the value is a meaningless string such as <random values>,
which identifies some particular record in a DB of some kind where the real info is kept.
Usually, the cookie values do not contain the data, but merely point to it on the server.

Cookies are limited to nonwhitespace ASCII text, and may not contain commas or semicolons.

To set a cookie in a browser, the server includes a Set-Cookie header line in the HTTP
header. For example, this HTTP header sets the cookie "cart" to the value "ATVPDKIKX0DER":

HTTP/1.1 200 OK
Content-type: text/html
Set-Cookie: cart=ATVPDKIKX0DER

If a browser makes a second request to the same server, it will send the cookie
back in a Cookie line in the HTTP request header like so:

GET /index.html HTTP/1.1
Host: www.example.org
Cookie: cart=ATVPDKIKX0DER
Accept: text/html

As long as the server does not refuse cookies, this enables it to track individual
users and sessions across multiple, otherwise stateless, HTTP connections.

Servers can set more than one cookie. For example, a request i just made to Amazon
fed my browser five cookies:

Set-Cookie:skin=noskin
Set-Cookie:ubid-main=176-5578236-9590213
Set-Cookie:session-token=Zg6afPNqbaMv2WmYFOv57zCU106Ktr
Set-Cookie:session-id-time=2082787201l
Set-Cookie:session-id=187-4969589-3049309

In additiona to a simple name=value pair, cookies can have several attributes 
that control their scope including expiration date, path, domain, port, version,
and security options.

For example, by default, a cookie applies to the server it came from. If a cookie
is originally set by www.foo.example.com, the browser will only send the cookie back
to www.foo.example.com. However, a site can also indicate that a cookie applies within
an entire subdomain, not just the original server.

For example, this request sets a user cookie for the entire foo.example.com domain:

Set-Cookie: user=elharo;Domain=.foo.example.com

The browser will echo this cookie back not just to www.foo.example.com, but also
to lothar.foo.example.com, eliza.foo.example.com, enoch.foo.example.com and any
other that follow the pattern.

However, a server can only set cookies for domains it immedeatly belongs to.
www.foo.example.com cannot set a cookie for www.oreilly.com, example.com etc.
no matter how it sets the domain.

Websites work around this restriction by embedding an image or other content
hosted on one domain in a page hosted at a second domain. The cookies
set by the embedded content, not the page itself, are called third-party cookies.

Many users block all third-party cookies, and some web browsers are starting
to block them by default for privacy reasons.

Cookies are also scoped by path, so they're returned for some dirs on the server,
but not all. The default scope is the original URL and any subdirs. For instance,
if a cookie is set for the URL http://www.cafeconleche.org/XOM/, also applies
to subdirs of XOM, but not other "earlier" subdirs.

However, the default scope can be changed using a Path attribute in the cookie.
For example, this next response sends the browser a cookie with the name "user"
and the value "elharo" that applies only within the server's /restricted subtree,
not rest of the site:

Set-Cookie: user=elharo; Path=/restricted

When requesting a document in the subtree /restricted from the same server,
the client echoes that cookie back. However, it does not use the cookie
in other dirs on the site.

A cookie can include both a domain and a path. For instance, this cookie applies
in the /restricted path on any servers within the example.com domain:

Set-Cookie: user=elharo;Path=/restricted;Domain=example.com

The order of the different cookie attributes does not matter, as long as they
are all separated by semicolons and the cookie's own name and value come first.
However, this isn't true when the client is sending the cookie back to the server.

In the case of sending back to the server, the path must precede the domain:

Cookie: user=elharo; Path=/restricted; Domain=.foo.example.com

A cookie can expire at a certain point in time by setting the expires attribute
to a date in form of Wdy, DD-Mon-YYYY HH:MM:SS GMT. Weekday and month are
given as three letter abbreviations. 

The rest are numeric, padded with initial zeros if necessary. In the pattern
language used by java.text.SimpleDateFormat, this is E,
dd-MMM-yyyy H:m:s z. For instance, this cookie expires at 3:23 PM on December 21,
2015:

Set-Cookie: user=elharo; expires=Wed, 21-Dec-2015 15:23:00 GMT

The browser should remove this cookie from it's cache after the amount of time
has elapsed.

The Max-Age attribute that sets the cookie to expire after a certain number of 
seconds have passed instead of at a specific moment. For instance, this cookie
expires one hour (3600 seconds) after it's first set:

Set-Cookie: user="elharo"; Max-Age=3600

Because cookies can contain sensitive info such as passwords and session keys,
some cookie transactions should be secure. Most of the time this means using
HTTPS instead of HTTP, but whatever it means, each cookie can have a secure attribute
with no value, like so:

Set-Cookie: key=etrogl7*; Domain=.foo.example.com; secure

Browsers are suppsoed to refuse to send such cookies over insecure channels.

For additional security against cookie-stealing attacks like XSRF, cookies can
set the HttpOnly attribute. This tells the browser to only return the cookie
via HTTP and HTTPS and specifically not JavaScript:

Set-Cookie: key=etrogl7*; Domain=.foo.example.com; secure; httponly

That's how cookies work behind the scenes. Heres a complete set of cookies
sent by Amazon:

Set-Cookie: skin=noskin; path=/; domain=.amazon.com;
	expire=Fri, 03-May-2013 21:46:43 GMT

etc.

They can also contain session tokens.

If we were to keep writing all the cookies, we'd see some with
the expire date of 33 years. Of course, the browsers are free to ignore
all these requests, and users can delete or block cookies at any time.

CookieManager:

Java 5 included an abstract java.net.CookieHandler class that defines 
an API for storing and retrieving cookies. However, it does not include
any implemenation of that abstract class, so it requires a lot of grunt work.

Java 6 added a concrete CookieManager class, which is a subclass of CookieHandler.
However, it is not turned on by default. Before java will store and return cookies,
you need to enable it:

CookieManager manager = new CookieManager();
CookieHandler.setDefault(manager);

If all you want to do is receive cookies from sites and send them back to those sites,
you're done. That is all there is to it.

This will make Java store any cookie sent by HTTP servers you connect to with the URL class,
and will send the stored cookies back to those same servers in subequent requests.

However, you may wish to be a bit more careful about whose cookies you accept.
You can do this by specifying a CookiePolicy. Three policies are predefined:

CookiePolicy.ACCEPT_ALL //All cookies allowed

CookiePolicy.ACCEPT_NONE //No cookies allowed

CookiePolicy.ACCEPT_ORIGINAL_SERVER //Only first party cookies allowed

For example, this code fragment tells Java to block third-party cookies
but accept first-party cookies:

CookieManager manager = new CookieManager();
manager.setCookiePolicy(CookiePolicy.ACCEPT_ORIGINAL_SERVER);
CookieHandler.setDefault(manager);

That is, it will only accept cookies from servers you are talking to, not any
random ones on the internet.

If you want more fine-grained control, for instance to allow cookies from
some known domains but not others, you can implement the CookiePolicy interface
yourself and override the shouldAccept() method:

public boolean shouldAccept(URI uri, HttpCookie cookie)

The following example, shows setting a policy to accept any cookie except from .gov domains:

import java.net.*;

public class NoGovermentCookies implements CookiePolicy{
	@Override
	public boolean shouldAccept(URI uri, HttpCookie cookie){
		if (uri.getAuthority().toLowerCase().endsWith(".gov")
			|| cookie.getDomain().toLowerCase().endsWith(".gov")){
				return false;
			}
		return true;
	}
}

CookieStore:

It is sometimes nessecary to put and get cookies locally. For instance, when 
an application quits, it can save the cookie store to disk and load thoose cookies
again when it next starts up. You can retrieve the store in which the CookieManager
saves its cookies with the getCookieStore() method:

CookieStore store = manager.getCookieStore();

The CookieStore class allows you to add, remove, and list cookies so you can
control the cookies that are sent outside the normal flow of HTTP requests
and responses:

public void add(URI uri, HttpCookie cookie)

public List<HttpCookie> get(URI uri)

public List<HttpCookie> getCookies()

public List<URI> getURIs()

public boolean remove(URI uri, HttpCookie cookie)

public boolean removeAll()

Each cookie in store is encapsulated in an HttpCookie object that provides
methods for inspecting the attributes of the cookie summarized in Example 6-2:

package java.net;

public class HttpCookie implements Cloneable{
	public HttpCookie(String name, String value)

	public boolean hasExpired()
	public void setComment(String comment)
	public String getComment()
	public void setCommentURL(String url)
	public String getCommentURL()

	public void setDiscard(boolean discard)
	public boolean getDiscard()
	public void setPortlist(String ports)

	public String getPortList()
	public void setDomain(String domain)
	public String getDomain()

	public void setMaxAge(long expiry)
	public long getMaxAge()
	public void setPath(String path)

	public String getPath()
	public void setSecure(boolean flag)
	public boolean getSecure()
	public String getName()
	public void setValue(String value)

	public static boolean domainMatches(String domain, String host)
	public static List<HttpCookie> parse(String header)

	public String toString()
	public boolean equals(Object obj)
	public int hashCode()
	public Object clone()
}

Several of these attributes are not actually used anymore. In particular,
comment, commentURL, discard and version are only used by the now obsolete
Cookie 2 specification that never caught on.

URLConnections:

URLConnection is an abstract class that represents an active connection
to a resource specified by a URL. The URLConnection class has two different
but related purposes. 

First, it provides more control over the interaction with a server
(especially an HTTP server) than the URL class. A URLConnection
can inspect the header sent by the server and respond accordingly.
It can set the header fields used in the client request.

Finally, a URLConnection can send data back to a web server with POST,
PUT and other HTTP request methods. We will explore all of 
these techniques in this chapter.

Second, the URLConnection class is part of Java's protocol handler mechanism,
which also includes the URLStreamHandler class. The idea behind protocol
handlers is simple: they separate the details of processing a protocol
from processing particular data types, providing UIs, and doing other
work that a monolithic web browser does.

The base.java.net.URLConnection class is abstract; to implement a
specific protocol, you write a subclass. These subclasses can be loaded
at runtime by applications. For example, if the browser runs across
a URL with a strangs scheme, such as compress, rather than 
throwing an exception ,it downloads a protocl handler for the 
unkonwn protocol and use it to communicate with the servers.

Only abstract URLConnection classes are present in the java.net package.
The concrete subclasses are hidden inside the sun.net package hierarchy.
Many of the methods and fields as well as the single constructor
in the URLConnection class, are protected.

In other words, they can only be accessed by instances of the 
URLConnection class or its subclasses. It is rare to instansiate
URLConnection objects directly in your source code.

Instead, the runtime environment creates these objects as needed,
depending on the protocol in use. The class (which is unknown at compile time)
is then instansiated using the forName() and newInstance() methods of the 
java.lang.Class class.

URLConnection does not have the best-designed API in the Java class
lib. One of several problems is that the URLConnection class is too
closely tied to the HTTP protocol. For instance, it assumes that each
file transferred is preceeded by a MIME header or something very
much like one.

However, most classic protocols such as FTP and SMTP don't use
MIME headers.

Opening URLConnections:

A program that uses the URLConnection directly follows this basic
sequence of steps:

1. Construct a URL object

2. Invoke the URL object's openConnection() method to retrieve a URLConnection
object for that URI.

3. Configure the URLConnection

4. Read the header fields

5. Get an input stream and read data

6. Get an output stream and write data

7. Close the connection

You don't always perform all these steps. For instance, if the default 
setup for a particular kind of URL is acceptable, you can skip step 3.

If you only want the data from the server and don't care about any 
metainformation, or if the protocol doesn't provide any metainformation,
you can skip step 4.

If you just want to read and not write, skip step 6. Step 5 and 6 can be interlaced
or reversed, depending on the protocol.

The single constuctor for the URLConnection class is protected:

protected URLConnection(URL url)

Consequently, unless you're subclassing URLConnection to handle a new
kind of URL (i.e writing a protocol handler), you create one of these
objects by invoking the openConnection() method of the URL class:

try{
	URL u = new URL("http://www.overcomingbias.com/");
	URLConnection uc = u.openConnection();
	// read from the URL
} catch (MalformedURLException ex) {
	System.err.println(ex);
} catch (IOException ex){
	System.err.println(ex);
}

The URLConnection class is declared abstract. However, all of it's methods
except one, are already implemented. You may find it convenient or necessary
to override other methods in the class, but the single method that subclasses
must implement is connect().

Connect() makes a connection to the server and depends on the type of protocol,
(HTTP, FTP and so on). For example, a sun.net.www.protocol.file.FileURLConnection's connect()
method converts the URL to a filename in the appropiate dir, creates MIME info for the file,
and then opens a buffered FileInputStream to the file.

The connect() method of sun.net.www.protocol.http.HttpURLConnection creates
 a sun.net.www.http.HttpClient object, which is responsible for connecting to the
 server:

 public abstract void connect() throws IOException

 When a URLConnection is first constructed, it is unconnected; that is, the local
 and remote HOST cannot exchange DATA. However, the getters of info such as
 getInputStream(), getContent(), getHeaderField(), and others that require a open
 connection will call connect() if the connection isn't yet open.

 Thus, you rarely need to call the connect() directly.

 Reading Data from a Server:

 The following is the minimal set of steps needed to retrieve data from a URL
 using a URLConnection object:

 1. Construct a URL object.

 2. Invoke the URL object's openConnection() method to retrieve a
 URLConnection object for that URL.

 3. Invoke the URLConnection's getInputStream() method.

 4. Read from the input stream using the usual stream API.

 The getInputStream() method returns a generic InputStream that let's you
 read and parse the data that the server sends. 

 The following example showcases how to download a page with a URL connection:

 import java.io.*;
 import java.net.*;

 public class SourceViewer2{
 	public static void main(String[] args){
 		if (args.length > 0){
 			try{
 				//OPen the URLConnection for reading
 				URL u = new URL(args[0]);
 				URLConnection uc = u.openConnection();
 				try(InputStream raw = uc.getInputStream()){
 					InputStream buffer = new BufferedInputStream(raw);

 					//Chain the inputstream to a reader
 					Reader reader = new InputStreamReader(buffer);
 					int c;
 					while ((c = reader.read()) != 1){
 						System.out.println((char) c);
 					}
 				}
 			} catch (MalformedURLException ex){
 				System.err.println(args[0] + "is not a parseable URL");
 			} catch (IOException ex){
 				System.err.println(ex);
 			}
 		}
 	}
 }

 The differences between URL and URLConnection, are numerous, but the big ones are:

 URLConnection provides access to the HTTP header.

 URLConnection can configure the request parameters sent to the server.

 URLConnection can write data to the server as well as read data from the server

 Reading the Header:

 HTTP servers provide a substansial amount of info in the header that precedes
 each response. For example, here's a typical HTTP header returned by an Apache
 web server:

 HTTP/1.1 301 Moved Permanently
 Date: Sun, 21 Apr 2013 15:12:46 GMT
 Server: Apache
 Location: http://www.ibiblio.org/
 Content-Length: 296
 Connection: close
 Content-Type: text/html; charset=iso-8859-1

There is a lot of info there. In general, an HTTP header may include the content
type of the requested document, the length of the document in bytes, the charset
in which the document is encoded, the date and time, the date the content expires,
and the date the content was last modified.

However, the info depends on the server, as some send everything, some send parts,
others send nothing. The methods of this section, allows you to query 
a URL Connection to find out what metadata the server has provided.

Aside from HTTP, very few protocols use MIME headers (and technically speaking,
even the HTTP header isn't actually a MIME header; it just looks like one).

When writing your own subclass of URLConnection, it is often nessecary to override
these methods so that they return sensible values. The most important
piece of info you may be lacking is the content type.

URLConnection provides some utility methods that guess the data's content type
based on its filename or the first few bytes of the data itself.

Retrieving Specific Header Fields:

The first six methods request specific, particularly common fields 
from the header.

These are:

Content-type

Content-length

Content-encoding

Date

Last-modified

Expires

public String getContentType()

the getContentType() method returns the MIME media type of the 
response body. It relies on the web server to send a valid content type.
It throws no Exceptions and returns null if the content is not available.

text/html will be the most common content type you'll encounter when
connecting to web servers. Other commonly used types include text/plain,
image/gif, application/xml and image/jpeg.

If the content type is some form of text, this header may also contain
a characterset part identifying the document's character encoding:

Content-type: text/html; charset=UTF-8

or:

Content-type: application/xml; charset=iso-2022-jp

In this case, getContentType() returns the full value of the Content-type field,
including the char encoding. You can use this to improve on example 7.1
by using the encoding specified in the HTTP header to decode the document, or ISO-8859-1 (The HTTP
default).

If no such encoding is specified. If a nontext type is encountered, an exception is thrown.

An example of downloading the site with the correct charset:

import java.io.*;
import java.net.*;

public class EncodingAwareSourceViewer{
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				//Set default encoding
				String encoding = "ISO-8859-1";
				URL u = new URL(args[i]);
				URLConnection uc = u.openConnection();
				String contentType = uc.getContentType();

				int encodingStart = contentType.indexOf("charset=");
				if (encodingStart != -1){
					encoding = contentType.substring(encodingStart + 8);
				}
				InputStream in = new BufferedInputStream(uc.getInputStream());
				Reader r = new InputStreamReader(in, encoding);
				int c;
				while ((c = r.read()) != -1){
					System.out.println((char) c);
				}

				r.close();
			} catch (MalformedURLException ex){
				System.err.println(args[0] + " is not a parseable URL");
			} catch (UnsupportedEncodingException ex){
				System.err.println("Server sent an encoding Java does not support: " + ex.getMessage());
			} catch (IOException ex){
				System.err.println(ex);
			}
		}
	}
}

public int getContentLength():

The getContentLength() method tells you how many bytes there are in the content.
If there is no Content-length header, getContentLength() returns -1. The method throws
no exceptions.

It is used when you need to know exactly how many bytes to read or when you
need to create a buffer large enough to hold the data in advance.

As networks get faster and files get bigger, it is actually possible to find
resources whose size exceeds the maximum value of int. In this case, getContentLength()
returns -1. There is a getContentLengthLong() that is used for this case, that returns
a long instead, able to handle much larger files.

Earlier, we saw how to use the openStream() method of the URL class to download
text files from an HTTP server. Although in theory you should be able to use the same
method to download a binary file, such as a GIF image or a .class byte code file,
in practice this procedure presents a problem.

HTTP servers don't always close the connection exactly where the data is finished.
Therefore, we don't know where to stop reading. To download a binary file,
it is more reliable to use a URLConnection's getContentLength() method to find
the file's length, then read exactly the number of bytes indicates.

What follows, is an example of downloading a binary file from a website and saving it to disk:

import java.io.*;
import java.net.*;

public class BinarySaver{
	public static void main(String[] args){
		for(int i = 0; i < args.length; i++){
			try{
				URL root = new URL(args[i]);
				saveBinaryFile(root); //attempt to run the data saving on the fed in URLs
			} catch(MalformedURLException ex){
				System.err.println(args[i] + " is not a URL i understand!"); //malformed URL
			} catch (IOException ex){
				System.err.println(ex); //IO error
			}
		}
	}

	public static void saveBinaryFile(URL u) throws IOException{ //method
		URLConnection uc = u.openConnection(); //open the connection
		String contentType = uc.getContentType(); //Get the type of ontent
		int contentLength = uc.getContentLength(); //The length
		if (contentType.startsWith("text/") || contentLength == -1) { //if its a text file or its empty
			throw new IOException("This is not a binary file");
		}

		try (InputStream raw = uc.getInputStream()){ //get hte inputstream
			InputStream in = new BufferedInputStream(raw); //buffer it
			byte[] data = new byte[contentLength]; //assign the byte array

			int offset = 0; //the offset beings at 0
			while (offset < contentLength) { //while it is less than contentlength
				int bytesRead = in.read(data, offset, data.length - offset); //read
				if (bytesRead == -1) break; //if there is no more, break
				offset += bytesRead; //add
			}

			if (offset != contentLength) { //we didnt read enough
				throw new IOException("Only read " + offset  //Throw an IOEXeption
					+ " bytes; Expected " + contentLength + " bytes");
			}
			String fileName = u.getFile(); //get the filename
			filename = filename.substring(filename.lastIndexOf('/') + 1); //break out the filename
			try (FileOutputStream fout = new FileOutputStream(filename)){ //try making a fileoutputstream
				fout.write(data); //write the data from the file
				fout.flush(); //Flush the stream
			}
		}
	}
}

As usual, the main() method loops over the URLs entered on the command line,
passing each URL to the saveBinaryFile() method. saveBinaryFile() opens a
URLConnection to the URL. 

It puts the type into the variable contentType and the content length into
the variable contentLength. Next, an if statement checks wether the content type
is text or the Content-length field is missing or invalid (contentLength == -1).

If either of these are true, an IOException is thrown. If the checks both are false,
you have a binary file of known length; that's what you want.

Now that you have a genuine binary file on your hands, you prepare to read it
into an array of bytes called data. data is initialized to the number of bytes
required to hold the binary object, contentLength. Ideally, you would like to fill
data with a single call to read(), but you probably won't get all the bytes at once.

So, keep reading until it is done. The number of bytes read so far, is put into
the offset, which also keeps track of the location in the data array at which to start
placing the data read by the next read call.

The loop continues until we have read everything. 

The only rest of it that is interesting, is the fact of that AutoClosable is used
to clean throughout.

public String getContentEncoding():

The getContentEncoding() method returns a String that tells you 
how the content is encoded. If the content is sent unencoded (as is commonly
the case with HTTP servers), this method returns null. It throws no Exception.

The most commonly used content encoding on the Web is probably x-gzip, which can be straightforwardly decoded
using a java.util.GZipInputStream.

The content encoding is not the same as the character coding. The character encoding is
determined by the Content-type header or information internal to the document, and
specifies how characters are encoded in bytes. Content encoding specifies how the bytes
are encoded in other bytes.

public long getDate():

The getDate() method returns a long that tells you when the document was sent,
in milliseconds since midnight, GMT, January 1, 1970. We can convert it to java.util.Date:

Date documentSent = new Date(uc.getDate());

This is the time the document was sent as seen from the server; it may not agree
with the time on your local machine. If the HTTP header does not include a Date field,
getDate() returns 0.

public long getExpiration():

Some documents have server-based expiration dates that indicate when
the document should be deleted from the cache and reloaded from the server.

getExpiration() is very similar to getDate(), differing only in how they return
values interpetted. It returns a long indicating the number of MS after 12:00 AM
GMT January 1, 1970, at which the document expires. If the HTTP header
does not include a Expiration Field, getExpiration() returns 0, which
means that the document does not expire and can remain cached forever.

public long getLastModified():

The final date method, getLastModified(), returns the date on which 
the document was last modified. Again, the date is given as the number of MS,
since midnight, GMT, January 1, 1970. If the HTTP header does not include 
a Last-modified field (and many don't), this returns 0.

The following example, reads URLs from the command line and uses these six
methods to print their content type, content length, content encoding,
date of last modification, expiration date, and current date.

import java.io.*;
import java.net.*;
import java.util.*;

public class HeaderViewer{
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				URL u = new URL(args[0]);
				URLConnection uc = u.openConnection();
				System.out.println("Content-type: " + uc.getContentType());

				if(uc.getContentEncoding() != null){
					System.out.println("Content-encoding: " + uc.getContentEncoding());
				}

				if (uc.getDate() != 0){
					System.out.println("Date: " + new Date(uc.getDate()));
				}
				if (uc.getLastModified() != 0){
					System.out.println("Last modified:" + new Date(uc.getLastModified()));
				}
				if (uc.getExpiration() != 0){
					System.out.println("Expiration date: " + new Date(uc.getExpiration()));
				}

				if (uc.getContentLength() != -1){
					System.out.println("Content length: " + uc.getContentLength());
				}
			} catch (MalformedURLException ex){
				System.err.println(args[i] + " is not a URL i understand!");
			} catch (IOException ex){
				System.err.println(ex);
			}
			System.out.println();
		}
	}
}

An example output:

% java HeaderViewer http://www.oreilly.com
Content-type: text/html; charset=utf-8
Date: Fri May 31 18:08:09 EDT 2013
Last modified: Fri May 31 17:04:14 EDT 2013
Expiration Date: Fri May 31 22:08:09 EDT 2013
Content-Length: 83273

The content type of the file at http://www.oreilly.com is text/html.
No content encoding was used. etc.

Many servers don't bother to provide a content-length header for text files. 
However, a content-length header should always be sent with a Binary file.
Here's the HTTP header you get when you request the GIF image http://oreilly.com/favicon.ico:

% java HeaderViewer http://oreilly.com/favicon.ico
Content-type: image/x-icon
Date: Fri May 31 18:16:01 EDT 2013
Last modified: Wed Mar 26 19:14:36 EST 2003
Expiration date: Fri Jun 07 18:16:01 EDT 2013
Content-length: 2294

Retrieving Arbitrary Header Files:

The last Six methods requested specific fields from the header, 
but there is no theoretical limit to the number of header fields a
message can contain.

The next five methods inspect arbitrary fields in a header. Indeed,
the methods of the preceeding section are just thin wrappers over the
methods discussed here.

You can use these methods to get header fields that Java designers did not
plan for. If the request header is not found, it is returned.
Otherwise, it returns null.

public String getHeaderField(String name):

The getHeaderField() method returns the value of a named header field.
The name of the header is not case sensitive and does not include
a closing colon. for example, to get the value of the Content-type 
and Content-encoding header fields of a URLConnection object uc,
you could write:

String contentType = uc.getHeaderField("content-type");
String contentEncoding = uc.getHeaderField("content-encoding");

To get the date, content-length or expires headers, you'd do the same:

String data = uc.getHeaderField("date");
String expires = uc.getHeaderField("expires");
String contentLength = uc.getHeaderField("Content-length");

They all return String. If there is not a valid co-respondant it returns
null, thus, always check the value by this.

public String getHeaderFieldKey(int n):

This method returns the key (i.e, the field name) of the n^th header field
(e.g, Content-length or Server). The request method is header zero and has a null
key. The first header is one.

For example, in order to get the sixth key, you just write:

String header6 = uc.getHeaderFieldKey(6);

public String getHeaderField(int n):

This method returns the value of the n^th header field.
In HTTP, the starter line containing the request method and
path is header field zero and the first actual header is one.
(Basically they are not 0 indexed)

The following example, uses getHeaderField() with getHeaderFieldKey
to print the entire HTTP header:

import java.io.*;
import java.net.*;

public class AllHeaders{
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				URL u = new URL(args[i]);
				URLConnection uc = u.openConnection();
				for(int j = 1 ; j++){
					String header = uc.getHeaderField(j);
					if (header == null) break;
					System.out.println(uc.getHeaderFieldKey(j) + ":" + header);
				}
			} catch (MalformedURLException ex) {
				System.err.println(args[i] + " is not a URL i understand");
			} catch (IOException ex){
				System.err.println(ex);
			}
			System.out.println();
		}
	}
}

Besides the headers with named getter methods, this specific example would
provide Server, Accept-Ranges, Cache-control, Vary, Keep-Alive, and Connection headers.
Other servers can have different ones.

public long getHeaderFieldDate(String name, long default):

This method first retrieves the header field specified by the name arg,
and tries to convert the string to a Long that specifies the miliseconds since
midnight, January 1, 1970, GMT. getHeaderFieldDate() can be used to retrieve
a header field that represents a date (Expires, Date or Last-modified headers).

To convert the String to an integer, getHeaderFieldDate() use the parseDate() method
of java.util.Date. The parseDate() method does a decent job of understanding
and converting most common date formats, but it can be stumped.

For instance, if you ask for a header field that contains something other than
a date. if praseDate() doesn't understand the date or if getHeaderFieldDate()
is unable to find the requested header field, it returns the default arg.

Some examples:

Date expires = new Date(uc.getHeaderFieldDate("expires", 0));

long lastModified = uc.getHeaderFieldDate("last-modified", 0);

Date now = new Date(uc.getHeaderFieldDate("date", 0));

public int getHeaderFieldInt(String name, int default):

This method retrieves the value of the header field name, and tries
to convert it to an int. If it fails, either because it can't
find the requested header field or because that field does not
contain a recognizable int, getHeaderFieldInt() returns the default.

This method is often used to retrieve the Content-length field. 
For example, to get the content length from a URLConnection
uc, you would write:

int contentLength = uc.getHeaderFieldInt("content-length", -1); //Returns -1 if it doesn't exist

Caches:

Web browsers have been caching pages and images for years. 
If a logo is repeated on every page of a site, the browser normally
loads it from the remote server only once, stores it in it's cache
and reloads it from the cache whenever it's needed rather than 
requesting it from the server every time the logo is encountered.

Several HTTP headers, including Expires and Cache-control, can 
control caching.

By default, the assumption is tha a page accessed with GET over HTTP
can and should be cached. A page accessed with HTTPS or POST
usually should not be. However, HTTP headers can adjust this:

An expires header (primarily for HTTP 1.0) indicates that it's ok
to cache it until this time.

The cache-control header (HTTP 1.1) offers fine-grained cache policies:

max-age=[seconds]: number of seconds from now before the cached entry should expire

s-maxage=[seconds]: Number of seconds from now before the cached entry should expire
from a shared cache. Private caches can store the entry for longer.

public: Ok to cache an authenticated response. Otherwise, authenticated resposnes
are not cached.

private: Only a single user caches should store the response; shared caches should
not.

no-cache: Not quite what it sounds like. The entry may still be cached, but
the client should reverify the state of the resource with an ETag or Last-modified
header on each access.

no-store: Do not cache the entry no matter what.

Cache-control overrides Expires if both are present. A server can send multiple
Cache-control headers in a single header as long as they don't conflict.

The Last-modified header is the date when the resource was last changed.
A client can use a HEAD request to check this and only come back for a 
full GET if its local cached copy is older than the Last-modified state.

The ETag header (HTTP 1.1) is a unique identifier for the resource that 
changes when the resource does. A client can use a HEAD request to check
this and only come back for a full GET if its local cached copy has a differnet ETag.

For example, this HTTP response says that the resource may be cached for 
604,800 seconds (HTTP 1.1) or one week later (HTTP 1.0). It also says
it was last modified on April 20 and has an ETag, so if the local cache 
already has a copy more recent than that , there is no need to load
the whole document now.

HTTP/1.1 200 OK
Date: Sun, 21 Apr 2013 15:12:46 GMT
Server: Apache
Connection: close

Content-Type: text/html; charset=ISO-8859-1
Cache-control: max-age=604800
Expires: Sun, 28 Apr 2013 15:12:46 GMT
Last-modified: Sat, 20 Apr 2013 09:55:04 GMT
ETag: <string>

The following example is a example of how to parse and query
Cache-control headers:

import java.util.Date;
import java.util.Locale;

public class CacheControl{
	private Date maxAge = null;
	private Date sMaxAge = null;
	private boolean mustRevalidate = false;
	private boolean noCache = false;
	private boolean noStore = false;
	private boolean proxyRevalidate = false;
	private boolean publicCache = false;
	private boolean privateCache = false;

	public CacheControl(String s){
		if (s == null || !s.contains(":")){
			return; //Default policy
		}

		String value = s.split(":")[1].trim();
		String[] components = value.split(",");

		Date now = new Date();
		for (String component : components){
			try{
				component = component.trim().toLowerCase(Locale.US);
				if (component.startsWith("max-age=")){
					int secondsInTheFuture = Integer.parseInt(component.substring(8));
					maxAge = new Date(now.getTime() + 1000 * secondsInTheFuture);
				} else if (component.startsWith("s-maxage=")){
					int secondsInTheFuture = Integer.parseInt(component.substring(8));
					sMaxAge = new Date(now.getTime() + 1000 * secondsInTheFuture);
				} else if (component.equals("must-revalidate")){
					mustRevalidate = true;
				} else if (component.equals("proxy-revalidate")){
					proxyRevalidate = true;
				} else if (component.equals("no-cache")){
					noCache = true;
				} else if (component.equals("public")){
					publicCache = true;
				} else if (component.equals("private")){
					privateCache = true;
				}
			} catch (RuntimeException ex){
				continue;
			}
		}
	}

	public Date getMaxAge(){
		return maxAge;
	}

	public Date getSharedMaxAge(){
		return sMaxAge;
	}

	public boolean mustRevalidate(){
		return mustRevalidate;
	}

	public boolean proxyRevalidate(){
		return proxyRevalidate;
	}

	public boolean noStore(){
		return noStore;
	}

	public boolean noCache(){
		return noCache;
	}

	public boolean publicCache(){
		return publicCache;
	}

	public boolean privateCache(){
		return privateCache;
	}
}

A client can take advantage of this info:

If a representation of the resource is available in the local cache,
and its expiry date has not arrived, just use it. don't even bother talking to the server.

If a representation of the resource is available in the local cache,
but the expiry date has arrived, check the server with HEAD to see if the resource
has changed before performing a full GET.

Web Cache for Java:

By default, Java does not cache anything. To install a system-wide cache 
of the URL class to use, you need the following:

A concrete subclass of ResponseCache

A concrete subclass of CacheRequest

A concrete subclass of CacheResponse

You install your subclass of ResponseCache that works with your subclass
of CacheRequest and CachResponse by passing it to the static method
ResponseCache.setDefault()

This installs your cache object as the system default. A java VM
can only support a single shared cache.

Once a cache is installed whenever the system tries to load a new URL,
it will first look for it in the cache. If the cache returns the 
desired content, the URLConnection won't need to connect to the remote
server.

However, if the requested data is not in the cache, the protocol
handler will download it. After it's done so, it will put 
its response into the cache so the content is more quickly
available the next time the URL is loaded.

Two abstract methods in the ResponseCache class store and retrieve
data from the system's single cache:

public abstract CacheResponse get(URI uri, String requestMethod,
	Map<String, List<String>> requestHeaders) throws IOException

public abstract CacheRequest put(URI uri, URLConnection connection)
	throws IOException

The put() method returns a CacheRequest object that wraps an
OutputStream into which the URL will write cachable data it reads.
CacheRequest is an abstract class with two methods as follows:

package java.net;

public abstract class cacheRequest{
	public abstract OutputStream getBody() throws IOException;
	public abstract void abort();
}


the getOutputStream method in the subclass should return an OutputStream
that points into the cache's data store for the URI passed to the put()
method at the same time.

For instance, if you're storing the data in a file, you'd return a FileOutputStream
connected to that file. The protocol handler will copy the data it reads
onto this OutputStream. If a problem occurs while copying (i.e the server unexpectedly
closes the connection), the protocol handler calls abort().

This method should then remove any data from the cache that has been stored for this request.

The following example demonstrates a basic CacheRequest subclass that passes back
a ByteArrayOutputStream. Later, the data can be retrieved using the getData() method,
a custom method in this subclass just retrieving the data Java wrote onto the OutputStream
this class supplied.

An obvious alternative would be to store results in files and use a FileOutputStream instead.

THe example:

import java.io*;
import java.net.*;

public class simpleCacheRequest extends CacheRequest{
	private ByteArrayOutputStream out = new ByteArrayOutputStream();

	@Override
	public OutputStream getBody() throws IOException{
		return out;
	}

	@Override
	public void abort(){
		out.reset();
	}

	public byte[] getData(){
		if (out.size() == 0) return null;
		else return out.toByteArray();
	}
}

The get() method in ResponseCache retrieves the data and headers from the cache
and returns them wrapped in a CacheResponse object. It returns null if the desired
URI is not in the cache, in which case the protocol handler loads the URI from 
the remote server as per normal.

Again, this is a abstract class you have to implement in a subclass.
The following example will showcase the class.

It has two methods, one to return the data of the request and one to
return the headers. When caching the original response, you need to
store both. The headers should be returned in an unmodifiable map
with keys that are the HTTP header field names and values that are lists
of values for each named HTTP header.

public abstract class cacheResponse{
	public abstract Map<String, List<String>> getHeaders() throws IOException;
	public abstract InputStream getBody() throws IOException;
}

The next example, showcases a simple structure of a CacheResponse subclass that is tied
to a SimpleCacheRequest and a CacheControl. in this example, shared references pass
data from the request class to the response class.

If you were storing responses in files, you'd just need to share the filenames instead.
Along with the SimpleCacheRequest object from which it will read the data,
you must also pass the original URLConnection object into the constructor.

This is used to read the HTTP header so it can be stored for later retrieval.
The object also keeps track of the expiration date and cache-control (if any)
provided by the server for the cached representation of the resource.

An example of the concrete CacheResponse subclass:

import java.io.*;
import java.net.*;
import java.util.*;

public class SimpleCacheResponse extends CacheResponse{
	private final Map<String, List<String>> headers;
	private final SimpleCacheRequest request;
	private final Date expires;
	private final CacheControl control;

	public SimpleCacheResponse(SimpleCacheRequest request,
		URLConnection uc, CacheControl control) throws IOException{

		this.request = request;
		this.control = control;
		this.expires = new Date(uc.getExpiration());
		this.headers = Collections.unmodifiableMap(uc.getHeaderFields());
	}

	@Override
	public InputStream getBody(){
		return new ByteArrayInputStream(request.getData());
	}

	@Override
	public Map<String, List<String>> getHeaders() throws IOException{
		return headers;
	}

	public CacheControl getControl(){
		return control;
	}

	public boolean isExpired(){
		Date now = new Date();
		if (control.getMaxAge().before(now)) return true;
		else if (expires != null && control.getMaxAge() != null){
			return expires.before(now);
		}
		else{
			return false;
		}
	}
}

Finally, you need a simple ResponseCache subclass that stores and retrieves
the cached values as requested while paying attention to the original Cache-control
header.

The following example, showcases a simple class that stores a finite number 
of responses in memory in a big thread-safe HashMap. This class is suitable
for a single-user, private cache (Because it ignores the private and public
attributes of Cache-control)

Example of simple cache:

import java.io.*;
import java.net.*;
import java.util.*;
import java.util.concurrent.*;

public class MemoryCache extends ResponseCache{
	private final Map<URI, SimpleCacheResponse> responses = new ConccurentHashMap<URI, Simple
		CacheResponse>();

	private final int maxEntries;

	public MemoryCache(){
		this(100);
	}

	public MemoryCache(int maxEntries){
		this.maxEntries = maxEntries;
	}

	@Override
	public CacheRequest put(URI uri, URLConnection conn) throws IOException{
		if (responses.size() >= maxEntries) return null;

		CacheControl control = new CacheControl(conn.getHeaderField("Cache-Control"));
		if (control.noStore()){
			return null;
		} else if (!conn.getHeaderField(0).startsWith("GET ")){
			//Only cache GET
			return null;
		}

		SimpleCacheRequest request = new SimpleCacheRequest();
		SimpleCacheResponse response = new SimpleCacheResponse(request, conn, control);

		responses.put(uri, response);

		return request;
	}

	@Override
	public CacheResponse get(URI uri, String requestMethod, Map<String, List<String>> requestHeaders) 
		throws IOException{

		if("GET".equals(requestMethod)){
			SimpleCacheResponse response = response.get(uri);
			//Check the expiration date
			if (response != null && response.isExpired()){
				responses.remove(response);
				response = null;
			}
			return response;
		} else {
			return null;
		}
	}
}

Java only allows one URL cache at a time. To install or change the cache, use the static
ResponseCache.setDefault() and ResponseCache.getDefault() methods:

public static ResponseCache getDefault()

public static void setDefault(ResponseCache responseCache)

To then set the default ResponseCache we just did:

ResponseCache.setDefault(new MemoryCache());

Once a ResponseCache is installed, HTTP URLConnection always use it.

Each retrieved resource stays in the HashMap until it expires. This example
waits for a expired document to be requested again before it deletes 
it from the cache.

A more sophisticated implementation could use a low-priority thread to scan
for expired documents and remove them to make way for others. Instead of
or in addition to this, an implementation might cache the representations
in a queue and remove the oldest documents or those closest to their expiration
date as nessecary to make room for new ones.

An even more sophisticated implementation could track how often each document
in the store was accessed and expunge only the oldest and least-used documents.

I've already mentioned that you could implement a cache on top of the filesystem
instead of on top of the Java Collections API. You could also store the cache
in a DB, and you could do a lot of less-common things as well.

For instance, you could redirect requests for certain URLs to a local server
rather than a remote server halfway around the world, in essence using
a local web server as the cache. Or a ResponseCache could load a fixed set
of files at launch time and then only serve those out of memory.

This might be useful for a server that processes many different SOAP requests,
all of which adhere to a few common schemas that can be stored in the cache.
The abstract ResponseCache class is flexible enough to support all of  these
and other usage patterns.

Configuring the Connection:

The URLConnection class has seven protected instance fields that define
exactly how the client makes the request to the server. These are:

protected URL     url;

protected boolean doInput = true;

protected boolean doOutput = false;

protected boolean allowUserInteraction = defaultAllowUserInteraction;

protected boolean useCaches = defaultUseCaches;

protected long ifModifiedSince = 0;

protected boolean connected = false;

For instance, if doOutput is true, you'll be able to write data to the server
over this URLConnection as well as read data from it. If useCaches is false, 
the connection bypasses any local caching and downloads the file from the server fresh.

Because these fields are all protected, their values are accessed and modified via
obviously named setters and getters:

public URL getURL()

public void setDoInput(boolean doInput)

public boolean getDoInput()

public void setDoOutput(boolean doOutput)

public boolean getDoOutput()

public void setAllowUserInteraction(boolean allowUserInteraction)

public boolean getAllowUserInteraction()

public void setUseCaches(boolean useCaches)

public boolean getUseCaches()

public void setIfModifiedSince(long ifModifiedSince)

public long getIfModifiedSince()

You can modify these fields only before the URLConnection is connected (before you try to
read content or headers from the connection.) Most of the methods that set fields throw
an IllegalStateException if they are called while the connection is open.

In general, you can set the properties of a URLConnection object only before
the connection is opened.

There are also some getter and setter methods that define the default 
behavior for all instances of URLConnection. There are:

public boolean getDefaultUseCaches()

public void setDefaultUseCaches(boolean defaultUseCaches)

public static void setDefaultAllowUserInteraction(boolean defaultAllowUserInteraction)

public static boolean getDefaultAllowUserInteraction()

public static FileNameMap getFileNameMap()

public static void setFileNameMap(FileNameMap map)

Unlike the instance methods, these methods can be invoked at any time.
The new defaults will apply only to URLConnection objects constructed
after the new default values are set.

protected URL url:

The url field specifies the URL that this URLConnection connects to. The constructor
sets it when the URLConnection is created and it should not change thereafter.

You can retrieve the value by calling the getURL() method. 

A simple example of using the getURL():

import java.io.*;
import java.net.*;

public class URLPrinter{
	public static void main(String[] args){
		try{
			URL u = new URL("http://www.oreilly.com/");
			URLConnection uc = u.openConnection();
			System.out.println(uc.getURL());
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

protected boolean connected:

The boolean field connected is true if the connection is open and false if it's closed.
Because the connection has not yet opened when a new URLConnection object is 
created, its initial value is false. 

This variable can be accessed only by instances of java.net.URLConnection and its subclasses.

There are no methods that directly read or change the value of connected. However,
any method that causes the URLConnection to connect should set this variable
to true, including connect(), getInputStream(), and getOutputStream().

Any method that causes the URLConnection to disconnect, should set this field
to false. There are no such methods in java.net.URLConnection, but some 
of its subclasses, such as java.net.HttpURLConnection have disconnect() methods.

If you subclass URLConnection to write a protocol handler, you are responsible
for setting connected to true when you are connected and resetting it to false
when the connection closes. Many methods in java.net.URLConnection read this 
variable to determine what they do.

If it's set incorrectly, your program can have many severe bugs that are hard
to diagnose.

protected boolean allowUserInteraction:

Some URLConnections need to interact with a user. For example, 
a web browser may need to ask for a username and password. However,
many applications cannot assume that a user is present to interact with it.

For instance, a search engine robot is probably running in the background
without any user to provide a username and PW. As its name suggets,
the allowUserInteraction specifies wether user interaction is allowed.
By default, it is false.

This variable is protected, but the public getAllowUserInteraction() method
can read its value and the public setAllowUserInteraction() method can change
it:

public void setAllowUserInteraction(boolean allowUserInteraction)

public boolean getAllowUserInteraction()

The value true indicates that user interaction is allowed, false 
indicates that there is no user interaction. The value may 
be read at any time but may be set only before the URLConnection
is connected.

Calling setAllowUserInteraction() when the URLConnection is connected,
throws an IllegalStateException.

For example, this example showcases a URL that can ask for authentication:

URL u = new URL("http://www.example.com/passwordProtectedPage.html");
URLConnection uc = u.openConnection();
uc.setAllowUserInteraction(true);
InputStream in = uc.getInputStream();

Java does not include a default GUI for asking the user for a username
and PW. If the request is made from an applet, the browser's usual
authentication dialog can be relied on. In a standalone app,
you first need to install an Authenticator.

If you cancel a dialog that attempts authentication, you get a 
401 Authorization required error and whatever the Server sends
to unauthorized users.

However, if you press OK and then No, refusing authorization,
then getInputStream() triggers ProtocolException.

The static methods getDefaultAllowUserInteraction() and 
setDefaultAllowUserInteraction() determine the default
behavior for URLConnection objects that have not 
set allowUserInteraction explicitlly.

Because the allowUserInteraction is static, changing it 
changes the default behavior for all instances of the URLConnection
class that are created after setDefaultAllowUserInteraction() is called.

For example:

if(!URLConnection.getDefaultAllowUserInteraction()){
	URLConnection.setDefaultAllowUserInteraction(true);
}

protected boolean doInput:

A URLConnection can be used for reading from a server, writing to a server,
or both. The protected boolean field doInput is true if the URLConnection
can be used for reading, false if it cannot be.

The default is true. To access this protected variable, use the public getDoInput()
and setDoInput():

public void setDoInput(boolean doInput)

public boolean getDoInput()

For example:

try{
	URL u = new URL("http://www.oreilly.com");
	URLConnection uc = u.openConnection();
	if (!uc.getDoInput()){
		uc.setDoInput(true);
	}
	//Write to the connection
} catch(IOException ex){
	System.err.println(ex);
}

When you set doOutput to true for an http URL, the request method 
is changed from GET to POST. We explore this later on.

protected boolean ifModifiedSince:

Many clients, especially web browsers and proxies, keep caches of 
previously retrieved documents. If the user asks for the same 
document again, it can be retrieved from the cache. However,
it may have changed on the server since it was last recieved.

The only way to tell, is to ask the server. Clients can include
an If-Modified-Since in the client request HTTP header. This
header includes a date and a time. If the document has 
changed since that time, the server should send it.

Otherwise, it should not. Typically, this time is the last
time the client fetched the document. For example, this
client request says the document should be returned only if it
has changed since 7:22:07 AM, October 31, 2014 GMT:

GET /HTTP 1.1
Host: login.biblio.org:5642
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close
If-modified-Since: Fri, 31 Oct 2014 19:22:07 GMT

If the document has changed since that time, the server will 
send it as usual. Otherwise, it replies with a 304 Not Modified message,
like this:

HTTP/1.0 304 Not Modified
Server: WN/1.15.1
Date: Sun, 02 Nov 2014 16:26:16 GMT
Last-modified: Fri, 29 Oct 2004 23:40:06 GMT

The client then loads the document from its cache. Not all web servers
respect the If-Modified-Since field. Some will send the content regardless.

The ifModifiedSince field in the URLConnection class specifies the date (in milisecs
since the epoch), which will be placed in the If-Modified-Since header field. 

Since it's protected, we use setters and getters for it:

public long getIfModifiedSince()

public void setIfModifiedSince(long ifModifiedSince)

The following example, sets the ifModified to 24 hours prior to now,
and downloads and displays the document, if it has been modified in the last
24 hours:

import java.io.*;
import java.net.*;
import java.util.*;

public class Last24{
	public static void main(String[] args){
		//initialize a date object with current date and time
		Date today = new Date();
		long millisecondsPerDay = 24 * 60 * 60 * 1000;

		for (int i = 0; i < args.length; i++){
			try{
				URL u = new URL(args[i]);
				URLConnection uc = u.openConnection();
				System.out.println("Original, if modified since: " + new Date(uc.getIfModifiedSince()));

				uc.setIfModifiedSince((new Date(today.getTime() - millisecondsPerDay)).getTime());

				System.out.println("Will retrieve file if it's modified since " + new Date(uc.getIfModifiedSince()));

				try(InputStream in = new BufferedInputStream(uc.getInputStream())){
					Reader r = new InputStreamReader(in);
					int c;
					while ((c = r.read()) != -1){
						System.out.println((char) c);
					}
					System.out.println();
				}
			} catch (IOException ex){
				System.err.println(ex);
			}
		}
	}
}

protected boolean useCaches:

Some clients, notably web browsers, can retrieve a document from a local cache
rather then retrieving it from a server. Applets may have access to the 
browser's cache.

Standalone apps can use java.net.ResponseCache class. The useCaches variable
determines wether a cache will be used if it's available. The default
value is true, meaning that the cache will be used; false means the
cache won't be used.

Because useCaches is protected, programs access it using the getUseCaches()
and setUseCaches():

public void setUseCaches(boolean useCaches)

public boolean getUseCaches()

The following example disables caching to ensure that the latest document
is always retrieved, by setting useCaches to false:

try{
	URL u = new URL("http://www.sourcebot.com/");
	URLConnection uc = u.openConnection();
	uc.setUseCaches(false);
	//Read the document
} catch (IOException ex){
	System.err.println(ex);
}

Two methods define the initial value of the useCaches field,
getDefaultUseCaches() and setDefaultUseCaches():

public void setDefaultUseCaches(boolean useCaches)

public boolean getDefaultUseCaches()

Although nonstatic, these methods do set and get a static field
that determines the default behaviour for all instances of the URLConnection class
created after the change.

The next code fragment disables caching by default; after this code runs, URLConnections
that want caching must enable it explicitly using setUseCaches(true):

if (uc.getDefaultUseCaches()){
	uc.setDefaultUseCaches(false);
}

Timeouts:

Four methods query and modify the timeout values for connections; that is,
how long the underlying socket will wait for a response from the remote end
before throwing a SocketTimeoutException. These are:

public void setConnectionTimeout(int timeout)

public int getConnectionTimeout()

public void setReadTimeout(int timeout)

public int getReadTimeout()

The setConnectTimeout()/getConnectTimeout() methods control how long 
the socket wait for the initial connection. The setReadTimeout()/getReadTimeout()
methods control how long the input stream waits for data to arrive.

All four methods measure timeouts in milliseconds. All four interpet zero
as meaning never time out. Both setter methods throw an IllegalArgumentException
if the timeout is negative.

For example, this code fragment requests a 30-second connect timeout and a 
45-second read timeout:

URL u = new URL("http://www.example.org");
URLConnection uc = u.openConnection();
uc.setConnectTimeout(30000);
uc.setReadTimeout(45000);

Configuring the Client Request HTTP header:

An HTTP client (e.g a browser) sends the server a request line and
a header. For example, here's an HTTP header that chrome sends:

Accept:text/html, application/xhtml+xml, application/xml;q=0.9,*/*;q=0.8
Accept-Charset:ISO-8859-1,utf-8;q=0.7,*;q=0.3
Accept-Encoding:gzip,deflate,sdch
Accept-Language:en-US, en;q=0.8
Cache-Control:max-age=0
Connection:keep-alive
Cookie:reddit_first=<stuff>
DNT:1
Host:lesswrong.com
User-Agent:Mozilla/5.0(Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.31
	(KHTML, like Gecko) Chrome/26.0.1410.65 Safari/537.31

A web server can use this information to serve different pages to different
clients, to get and set cookies, to authenticate users through passwords, and
more.

Placing different fields in the header that the client sends and the server
responds with does all of this.

It's important to understand that this is not the HTTP header that
the server sends to the client that is read by getHeaderField()
and getHeaderFieldKey(). It is the HTTP header that the client
sends to the server.

Each URLConnection sets a number of different name-value pairs in the header
by default. Here's the HTTP header that a connection from the SourceViewer2
program sends:

User-Agent: Java/1.7.0_17
Host: httpbin.org
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

As you can see, it's a little simpler than the one Chrome sends, and it
has a different user agent and accepts different kind of files.

However, you can modify these and add new fields before connecting.
You add headers to the HTTP header using the setRequestProperty() method
before you open the connection:

public void setRequestProperty(String name, String value)

The setRequestProperty() method adds a field to the header of this
URLConnection with a specified name and value. This method can be
used only before the connection is opened.

It throws an IllegalStateException if the connection is already open.
The getRequestProperty() method returns the value of the named field
of the HTTP header used by this URLConnection.

HTTP allows a single named request property to have multiple values.
In this case, the separate values will be seperated by commas.
For example, the Accept header sent by Java 7 in the previous code
snippet has the four values text/html, image/gif, image/jpeg, and *.

These methods only really have meaning when the URL being connected
to is an HTTP URL, because only the HTTP protocol makes use of headers
like this. Though they could possibly have other meanings in other
protocols, such as NNTP, this is really just an example of a poor API design.

These methods should be part of the more specific HttpURLConnection
class, not the generic URLConnection class.

For instance, web servers and clients store some limited persistent
information with cookies. A cookie is a collection of name-value pairs.

The server sends a cookie to a client using the response HTTP header.
From that point forward, whenever the client requests a URL from that
server, it includes a Cookie field in the HTTP request header
that looks like this:

Cookie: username=elharo; password=<string>; session=<stuff>

This particular Cookie field sends three name-value pairs to
the server. There is no limit to the number of name-value pairs
that can be included in any one cookie. Given a URLConnection object uc,
you could add this cookie to the connection as follows:

uc.setRequestProperty("Cookie", "username=elharo; password=<string>; session=<stuff>");

You can set the same property to a new value, but this changes the existing
property value. To add an additional property value, use the addRequestProperty()
method instead:

public void addRequestProperty(String name, String value)

There's no fixed list of legal headers. Servers usually ignore any headers
they don't recognize. HTTP does put a few restrictions on the content 
of the names and values of header fields. For instance, the names can't
contain whitespace and and the values can't contain linebreaks.

Java enforces this restriction on fields containing line breaks, but not
much else. If a field contains a line break, setRequestProperty()
and addRequestProperty() throw an IllegalArgumentException.

Otherwise, it's quite easy to make URLConnection send malformed headers
to the server, so be careful. Some servers will handle the malformed
headers gracefully. Some will ignore the bad header and return the 
requested document anyway, but some will reply with an HTTP 400,
Bad request error.

If, for some reason, you need to inspect the headers in a URLConnection,
there's a standard getter method:

public String getRequestProperty(String name)

Java also includes a method to get all the request properties for a connection
as a Map:

public Map<String, List<String>> getRequestProperties()

The keys are the header field names. The values are lists of property values.
Both names and values are stored as strings.

Writing Data to a Server:

Sometimes you need to write data to a URLConnection, for example, when 
you submit a form to a web server using POST or upload a file using PUT.

The getOutputStream() method returns an OutputStream on which you can write 
data for transmission to a server:

public OutputStream getOutputStream()

A URLConnection doesn't allow output by default, so you have to call
setDoOutput(true) before asking for an output stream. When you set
doOutput to true for an http URL, the request method is changed from GET to POST.

In chap 5, you saw how to send data to server-side programs with GET. However,
GET should be limited to safe operations, such as search requests or page
navigation, and not used for unsafe operations that create or modify
a resource, such as posting a comment on a web page or ordering a pizza.

Safe operations can be bookmarked, cached, spidered, prefetched,
and so on. Unsafe operations should not be.

Once you have an OutputStream, buffer it by chaining it to a BufferedOutputSTream
or a BufferedWriter. You may also chain it to a DataOutputStream, an OutputStreamWriter
or some other class that's more convenient to use than a raw OutputStream.

For example:

try{
	URL u = new URL("http://www.somehost.com/cgi-bin/acgi");
	//Open the connection and prepare it to POST
	URLConnection uc = u.openConnection();
	uc.setDoOutput(true);

	OutputStream raw = uc.getOutputStream();
	OutputStream buffered = new BufferedOutputStream(raw);
	OutputStreamWriter out = new OutputStreamWriter(buffered, "8859_1");

	out.write("first=Julie&middle=&last=Harting&work=String+Quartet\r\n");
	out.flush();
	out.close();
} catch (IOException ex){
	System.err.println(ex);
}

Sending data with POST is almost as easy as with GET. Invoke setDoOutput(true)
and use the URLConnection's getOutputStream() method to write the query string
rather than attaching it to the URL.

Java buffers all the data written onto the output stream until the stream is 
closed. This enables it to calculate the value for the Content-length header.

The complete transaction, including client request and server response,
looks something like this:

% telnet www.cafeaulait.org 80
Trying 152.19.134.41...
Connected to www.cafeaulait.org
Escape character is '^]'.
POST /books/jnp3/postquery.phtml HTTP/1.0
Accept: text/plain
Content-type: application/x-www-form-urlencoded
Content-length: 63
Connection: close
Host: www.cafeaulait.org

username=Elliotte+Rusty+Harold&email=elharo%40ibiblio%2eorg
HTTP/1.1 200 OK
Date: Sat, 04 May 2013 13:27:24 GMT
Server: Apache
Content-Style-Type: text/css
Content-Length: 864
Connection: close
Content-Type: text/html; charset=utf-8

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<title>Query Results</title>
</head>
<body>

<h1>Query Result</h1>
<p>You submitted the following name/value pairs:</p>

<ul>
<li>username = Elliotte Rusty Harold</li>
<li>email = elharo@ibiblio.org</li>
</ul>

<hr />
Last Modified July 25, 2012

</body>
</html>
Connection closed by foreign host.

For that matter, as long as you control both the client and the server,
you can use any other sort of data encoding you like. For instance, SOAP
and XML-RPC both POST data to webservers as XML rather than an x-www-form-url-encoded query string.

The next example, is a program called FormPoster that uses URLConnection class and 
the QueryString class from Chapter 5 to post form data. The constructor
sets the URL.

The query String is built using the add() method. The post() method actually
sends the data to the server by opening a URLConnection to the specified URL,
setting its doOutput field to true, and writing the query string on the output stream.

It then returns the input stream containing the server's response.

The main() method is a simple test for this program that sends the name 
"Elliotte Rusty Harold" and the email address elharo@biblio.org to the
resource at http://www.cafeaulait.org/books/jnp4/postquery.phtml.

This resource is a simple form tester that accepts any input using either
the POST or GET method and returns an HTML page showing the names and values
that were submitted.

The data returned is HTML; this example simply displays the HTML rather than
attempting to parse it. It would be easy to extend this program by adding
a user interface that lets you enter the name and email address to be posted.

But because doing that, triples the size of program while showing nothing
more of network programming, it is left as an exercise for the reader.
Once you understand this example, it should be easy to write java PRograms
that communicate with other server-side scripts.

import java.io.*;
import java.net.*;

public class FormPoster{
	private URL url;
	private QueryString query  = new QueryString();

	public FormPoster (URL url){
		if (!url.getProtocol().toLowerCase().startsWith("http")){
			throw new IllegalArgumentException("Posting only works for http URLs");
		}
		this.url = url;
	}

	public void add(String name, String value){
		query.add(name, value);
	}

	public URL getURL(){
		return this.url;
	}

	public InputStream post() throws IOException{
		//open the connection and prepare it to POST
		URLConnection uc = url.openConnection();

		uc.setDoOutput(true);

		try(OutputStreamWriter out = new OutputStreamWriter(uc.getOutputStream(), "UTF-8")){
			//The Post line, the Content-type header,
			// and the Content-length headers are sent by the URLConnection.
			// We just need to send the data

			out.write(query.toString());
			out.write("\r\n");
			out.flush();
		}

		//Return the response
		return uc.getInputStream();
	}

	public static void main(String[] args){
		URL url;
		if (args.length > 0){
			try{
				url = new URL(args[0]);
			} catch (MalformedURLException ex) {
				System.err.println("Usage: java FormPoster url");
				return;
			}
		} else {
			try{
				url = new URL("http://www.cafeaulait.org/books/jnp4/postquery.phtml");
			} catch (MalformedURLException ex){
				System.err.println(ex);
				return;
			}
		}

		FormPoster poster = new FormPoster(url);
		posted.add("name", "Elliotte Rusty Harold");
		poster.add("email", "elharo@ibiblio.org");

		try (InputStream in = poster.post()){
			//read the response
			Reader r = new InputStreamReader(in);
			int c;
			while((c = r.read()) != -1){
				System.out.println((char) c);
			}
			System.out.println();
		} catch (IOException ex) {
			System.err.println(ex);
		}
	}
}

Here's the response from the server:

% java -classpath .:jnp4e.jar FormPoster
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<title>Query Result</title>
</head>
<body>

<h1>Query Results</h1>
<p>You submitted the following name/value pairs:</p>

<ul>
<li>name = Elliotte Rusty Harold</li>
<li>email = elharo@ibiblio.org</li>
</ul>

<hr />
Last Modified May 10, 2013

</body>
</html>

The main() method tries to read the first command-line argument from
args[0]. The argument is optional; if there is an argument, it is assumed
to be a URL that can be POSTed to. If there are no arguments, main() initializes
url with a default URL, http://www.cafeaulait.org/books/jnp4/postquery.phtml.

main() then constructs a FormPoster object. Two name-value pairs are added to
this FormPoster object. Next, the post() method is invoked and its response
read and printed on System.out.

The post() method is the heart of the class. It first opens a connection 
to the URL stored in the url field. It sets the doOutput field of this
connection to true because this URL Connection needs to send output 
and chains the OutputStream for this URL to an ASCII OutputStreamWriter
that sends the data, then flushes and closes the stream.

Do not forget to close the stream. If the stream is not closed, no data
will be sent. Finally, the URLConnection's InputStream is returned.

To summarize, posting data to a form requires these steps:

1. Decide what name-value pairs you'll send to the server-side program.

2. Write the server-side program that will accept and process the request.
If it does not use any custom data encoding, you can test this program
using a regular HTML form and a web browser.

3. Create a query string in your Java Program. The string should look like this:

name1=value1&name2=value2&name3=value3

Pass each name and value in the query string to URLEncoder.encode()
before adding it to the query string.

4. Open a URLConnection to the URL of the program that will accept the data.

5. set doOutput to true by invoking setDoOutput(true)

6. Write the query string onto the URLConnection's OutputStream

7. Close the URLConnection's OutputStream

8. Read the server response from the URLConnection's InputStream.

GET should only be used for safe operations that can be bookmarked and linked
to. POST should be used for unsafe operations that should not be bookmarked
or linked to.

The getOutputStream() method is also used for the PUT request method,
a means of storing files on a web server. The data to be stored
is written onto the OutputStream that getOutputStream() returns.

However, this can be done only from within the HttpURLConnection 
subclass of URLConnection, so discussion of PUT will have to wait 
a little while.

Security Considerations for URLConnections:

URLConnection objects are subject to all the usual security restrictions
about making network connections, reading or writing files, and so forth.

For instance, a URLConnection can be created by an untrusted applet only
if the URLConnection is pointing to the host that the applet came from.

However, the details can be a little tricky because different URL
schemes and their corresponding connections can have different security
implications.

For example, a jar URL that points into the applet's own jar file, should
be fine. However, a file URL that points to a local harddrive, should not be.

Before attempting to connect a URL, you may want to know wether the connection
will be allowed. For this purpose, the URLConnection class has a getPermission()
method:

public Permission getPermission() throws IOException

This returns a java.security.Permission object that specifies what
permission is needed to connect to the URL. It returns null if no
permission is needed (e.g, there is no security manager in place).

Subclasses of URLConnection return different subclasses of java.security
.Permission. For instance, if the underlying URL points to www.gwbush.com,
getPermission() returns a java.net.SocketPermission for the host 
www.gwbush.com with the connect and resolve actions.

Guessing MIME Media Types:

If this were the best of all possible worlds, every protocol and 
every server would use standard MIME types to correctly specify
the type of file being transferred. Unfortunately, that is not the case.

Not only do we have to deal with older protocols such as FTP that
predate MIME but many HTTP servers that should use MIME don't provide MIME
headers at all or lie and provide headers that are incorrect (Usually
cause the server has been misconfigured).

THe URLConnection class provides two static methods to help
programs figure out the MIME type of some data; you can use these
if the content type just isn't available or if you have reason 
to believe that the content type you're given is not correct.

The first, is the URLConnection.guessContentTypeFromName():

public static String guessContentTypeFromName(String name)

This method tries to guess the content type of an object based
on the extensions in the filename portion of the object's URL.

It returns its best guess about the content type as a String.
This guess is likely to be correct, people follow some fairly regular
conventions when thinking up filenames.

The guesses are determined by the content-types.properties file,
normally located in the jre/lib dir. On Unix, Java may also look at the
mailcap file to help it guess.

This method is not infallible by any means. For instance, it omits various
XML applications such as RDF (.rdf), XSL (.xsl) and so on that should have
the MIME type application/xml. It also does not provide a MIME type 
for CSS stylesheets (.css). However, its a good start.

The second MIME type guesser method, is URLConnection.guessContentTypeFromStream():

public static String guessContentTypeFromStream(InputStream in)

This method tries to guess the content type by looking at the first few
bytes of data in the stream. For this method to work, the InputStream
must support marking so that you can return to the beginning of the stream
after the first bytes have been read.

Java inspects the first 16 bytes of the InputStream, although sometimes
fewer bytes are needed to make an identification. These guesses are 
often not as reliable as the guesses made by guessContentTypeFromName().

For example, a XML document that begins with a comment rather than an XML declaration
would be mislabeled as an HTML file. This method, thus, should only be used for a last resort.

HttpURLConnection:

The java.net.HttpURLConnection class is an abstract subclass of URLConnection.
It provides some additional methods that are helpful when working specifically
with http URLs.

In particular, it contains methods to get and set the request method, decide
wether to follow redirects, get the response code and message, and figure out wether
a proxy server is being used.

It also includes several dozen mnemonic constants matching the various HTTP response
codes. Finally, it overrides the getPermission() method from the URLConnection superclass,
although it does not change the semantics of this method at all.

Because this class is abstract and its only constructor is protected,
you can't directly create instances of HttpURLConnection. However, if
you construct a URL object using an http URL and invoke its openConnection()
method, the URLConnection object returned will be an instance of HttpURLConnection.

Cast that URLConnection to HttpURLConnection like this:

URL u = new URL("http://lesswrong.com");
URLConnection uc = u.openConnection();
HttpURLConnection http = (HttpURLConnection) uc;

or

URL u = new URL("http://lesswrong.com");
HttpURLConnection http = (HttpURLConnection) u.openConnection();

The Request Method:

When a web client contacts a web server, the first thing it sends 
is a request line. Typically, the line begins with GET and is followed
by the path of the resource that the client wants to retrieve and the version
of the HTTP protocol that the client understands.

For example:

GET /catalog/jfcnut/index.html HTTP/1.0

However, web clients can do more than simply GET files from web servers.
They can POST responses to forms. They can PUT a file on a web server or
DELETE a file from a server.

And they can ask for just the HEAD of a document. They can ask the web server
for a list of the OPTIONS supported at a given URL. They can even TRACE the
request itself.

All of these are accomplished by changing the request method from a GET to
a different keyword.

for example, here is how a browser would ask just for the head of the document:

HEAD /catalog/jfcnut/index.html HTTP/1.1
Host: www.oreilly.com
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

By default, HttpURLConnection uses the GET method. However,
you can change this with the setRequestMethod() method:

public void setRequestMethod(String method) throws ProtocolException

The method argument should be one of these seven case-sensitive strings:

GET

POST

HEAD

PUT

DELETE

OPTIONS

TRACE

If it's some other method, then a java.net.ProtocolException, a subclass
of IOException, is thrown. However, it's generally not enough to 
simply set the request method. Depending on what you're trying to do,
you may need to adjust the HTTP header and provide a message body as well.

For instance, POSTing a form requires provide a Content-length header. We've
already explored the GET and POST methods. Let us look at the 5 other possibilities.

Some web servers support additional, nonstandard request methods.
For instance, WebDAV requires servers to support PROPFIND, PROPPATH,
MKCOL, COPY, MOVE, LOCK and UNLOCK. However, Java does not support any of these.

HEAD:

The HEAD function is possibly the simplest of all the request methods.
It behaves much like GET. However, it tells the server only to return the
HTTP header, not to actually send the file. The most common use of this
method is to check wether a file has been modified since the last
time it was cached.

The following program, showcases how to get the time of when a URL was last changed:

import java.io.*;
import java.net.*;
import java.util.*;

public class LastModified{
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				URL u = new URL(args[i]);
				httpURLConnection http = (HttpURLConnection) u.openConnection();
				http.setRequestMethod("HEAD");
				System.out.println(u + " was last modified at " + new Date(http.getLastModified()));
			} catch (MalformedURLException ex){
				System.err.println(args[i] + " is not a URL i understand.");
			} catch (IOException ex){
				System.err.println(ex);
			}
			System.out.println();
		}
	}
}

It was not absolutely nessecary to use the HEAD method here. You would have
gotten the same results with GET. But if you used GET, the entire file at http://www.ibiblio.org/xml/
would have been sent across the network, where of  you just cared about one line in the Header.

When you can use HEAD; it is much more efficient.

DELETE:

The DELETE method removes a file at a specified URL from a web server.
Because this request is an obvious security risk, not all servers are 
configured to support it, and those that do, demand some kind of authentication.

A typical DELETE request looks as follows:

DELETE /javafaq/2008march.html HTTP/1.1
Host: www.ibiblio.org
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

The server is free to refuse this request or ask for authorization, as follows:

HTTP/1.1 405 Method Not Allowed
Date: Sat, 04 May 2013 13:22:12 GMT
Server: Apache
Allow: GET, HEAD, POST, OPTIONS, TRACE
Content-Length: 334
Connection: close
Content-Type: text/html; charset=iso-8859-1

<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html><head>
<title>405 Method Not Allowed</title>
</head><body>
<h1>Method Not Allowed</h1>
<p>The requested method DELETE is not allowed for the
URL /javafaq/2008march.html.</p>
<hr>
<address>Apache Server at www.ibiblio.org Port 80</address>
</body></html>

Even if the server accepts this request, its response is implementation
dependant. Some servers may delete the files, others simply move it to a 
trash dir. Others simply mark it as not readable. Details are left up to the 
server vendor.

PUT:

Many HTML editors and other programs that want to store files on a web server
use the PUT method. It allows clients to place documents in the abstract
hiearchy of the site without necessarily knowing how the site maps to the
actual local filesystem.

This contrasts with FTP, where the user has to know the actual dir structure
as opposed to the server's virtual dir structure.

Here's how an editor might PUT a file on a web server:

PUT /blog/wp-app.php/service/pomdoros.html HTTP/1.1
Host: www.elharo.com
Authorization: Basic <token>
Content-Type: application/atom+xml;type=entry
Content-Length: 329
If-Match: "e180ee84f0671b1"

<?xml version="1.0" ?>
<entry xmlns="http://www.w3.org/2005/Atom">
	<title>The Power of Pomodoros</title>
	<id>urn:uuid:1225c695-cfb8-4ebb-aaaa-etc..</id>
	<updated>2013-02-23T19:22:11Z</updated>
	<author><name>Elliotte Harold</name></author>
	<content>Until recently, i hadn't paid much attention to SLAP</content>
</entry>

As with deleting files, some sort of authentication is usually required
and the server must be specifically configured to support PUT. The details 
vary from server to server. Most web servers do not support PUT out of the box.

OPTIONS:

The OPTIONS request method asks what options are supported for a particular
URL. If the request URL is an asterisk(*), the request applies to the
server as a whole, rather than to one particular URL on the server. For example:

OPTIONS /xml/HTTP/1.1
Host: www.ibiblio.org
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

The server responds to an OPTIONS request by sending an HTTP header
with a list of commands allowed on that URL. For example, where
the previous command was sent, here's what Apache responded with:

HTTP/1.1 200 OK
Date: Sat, 04 May 2013 13:52:53 GMT
Server: Apache

Allow: GET, HEAD, POST, OPTIONS, TRACE
Content-Style-Type: text/css
Content-Length: 0
Connection: close
Content-Type: text/html; charset=utf-8

The list of legal commands is found in the Allow field. However, in practice
these are just the commands the server understands, not necessarily the
ones it will actually perform on that URL.

TRACE:

The TRACE request method sends the HTTP header that the server recieved
from the client. The main reason for this information is to see what any
proxy servers between the server and client might be changing.

For example, suppose this TRACE request is sent:

TRACE /xml/HTTP/1.1
Hello: Push me
Host: www.ibiblio.org
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

The server should respond like this:

HTTP/1.1 200 OK
Date: Sat, 04 May 2013 14:41:40 GMT
Server: Apache
Connection: close
Content-Type: message/http

TRACE /xml/HTTP/1.1
Hello: Push me
Host: www.ibiblio.org
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: close

The first five lines are the server's normal response HTTP header.
The lines from TRACE /xml/HTTP/1.1 on are the echo of the original client request.

In this case, the echo is faithful. However, if there were a proxy server between
the client and server, it might not be.

Disconnect from the Server:

HTTP 1.1 supports persistent connections that allow multiple requests
and responses to be sent over a single TCP socket. However, when Keep-Alive
is used, the server won't immedeatly close a connection simply because it 
has sent the last byte of data to the client.

The client may, after all, send another request. Servers will time out and 
close the connection in as little as 5 seconds of inactivity. However,
it's still preferred for the client to close the connection as soon as it knows it's done.

The HttpURLConnection class transparently supports HTTP Keep-Alive unless
you explicitly turn it off. That is, it will reuse sockets if you connect
to the same server again before the server has closed the connection.

Once you know you're done talking to a particular host, disconnect() method enables
a client to break the connection:

public abstract void disconnect()

If any streams are still open on this connection, disconnect() closes them.
However, the reverse, is not true. Closing a stream on a persistent connection,
does not close the socket and disconnect.

Handling Server Responses:

The first line of an HTTP server's response includes a numeric code
and a message indicating what sort of response is made. For instance,
the most common response is 200 OK, indicating that the requested
document was found. For example:

HTTP/1.1 200 OK
Cache-Control:max-age=3, must-revalidate
Connection:Keep-Alive
Content-Type:text/html; charset=UTF-8
Date:Sat, 04 May 2013 14:01:16 GMT
Keep-Alive:timeout=5, max=200
Server: Apache
Transfer-Encoding:chunked
Vary:Accept-Encoding, Cookie
WP-Super-Cache:Served supercache file from PHP

<HTML>
<HEAD>
//rest of doc follows

Another response that we are familiar with, is 404, indicating
that the URL  you requested no longer points to a document.
For example:

HTTP/1.1 404 Not Found
Date: Sat, 04 May 2013 14:05:43 GMT
Server: Apache
Last-Modified: Sat, 12 Jan 2013 00:19:15 GMT
ETag: <string>
Accept-Ranges: bytes
Content-Length: 11166
Connection: close
Content-Type: text/html; charset=ISO-8859-1

<html>
<head>
<title>Lost and lost lol</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1>
</head>
<body bgcolor="#FFFFFF">
	<h1>404 FILE NOT FOUND</h1>
//rest of error message follows

There are many other, less common responses. For instance, code 301 indicates
 that the resource has permanently moved to a new location and the browser
 should redirect itself to the new location and update any bookmarks that 
 point ot the old location:

HTTP/1.1 301 Moved Permanently
Connection: Keep-Alive
Content-Length: 299
Content-Type: text/html; charset=iso-8859-1
Date: Sat, 04 May 2013 14:20:58 GMT
Keep-Alive: timeout=5, max=200
Location: http://www.careaulait.org/
Server: Apache

Often all you need from the response message is the numeric response code.
HttpURLConnection also has a getResponseCode() method to return this as an int:

public int getResponseCode() throws IOException

The text string that follows the response code is called the response message,
and is returned by the aptly named getResponseMessage() method:

publit String getResponseMessage() throws IOException

HTTP 1.0 defined 16 respone codes. HTTP 1.1 expanded this to 40 different ones.
Although some numbers, notably 404, are famous, some are less known.

The HttpURLConnection class includes 36 named constants such as HttpURLConnection.OK
and HttpURLConnection.NOT_FOUND representing the most common response codes.

We summarized them earlier.

The following example is an example of a SourceViewer that includes the response 
code and message:

import java.io.*;
import java.net.*;

public class SourceViewer3 {
	public static void main(String[] args){
		for (int i = 0; i < args.length; i++){
			try{
				//Open the URLConnection for reading
				URL u = new URL(args[i]);
				HttpURLConnection uc = (HttpURLConnection) u.openConnection();

				int code = uc.getResponseCode();
				String response = uc.getResponseMessage();
				System.out.println("HTTP/1.x " + code + " " + response);

				for (int j = 1; ;j++){
					String header = uc.getHeaderField(j);
					String key = uc.getHeaderFieldKey(j);
					if (header == null || key == null) break;
					System.out.println(uc.getHeaderFieldKey(j) + ": " + header);
				}
				System.out.println();

				try(InputStream in = new BufferedInputStream(uc.getInputStream())){
					//Chain the inputstream to a reader
					Reader r = new InputStreamReader(in);
					int c;
					while ((c = r.read()) != -1){
						System.out.println((char) c);
					}
				}
			} catch (MalformedURLException ex){
				System.err.println(args[0] + " is not a parseable URL.");
			} catch (IOException ex){
				System.err.println(ex);
			}
		}
	}
}

The only thing this program doesn't read that the server sends,is the version of HTTP
the server is using. There's currently no method to specifically return that.

However, we can retrieve the code and the version by accessing the first line:

uc.getHeaderField(0)

The result of our just written example would be:

% java SourceViewer3 http://www.oreilly.com
HTTP/1.x 200 OK
Date: Sat, 04 May 2013 11:59:52 GMT
Server: Apache
Last-Modified: Sat, 04 May 2013 11:41:06 GMT
Accept-Ranges: bytes
Content-Length: 80165
Content-Type: text/html; charset=utf-8
Cache-Control: max-age=14400
Expires: Sat, 04 May 2013 15:59:52 GMT
Vary: Accept-Encoding
Keep-Alive: timeout=3, max=100
Connection: Keep-Alive

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Translational/EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

Error Conditions:

On ocassion, the server encounters an error but returns useful info in the 
message body nonetheless. For example, when a client requests a nonexistent page
from the www.ibiblio.org website, rather than simply returning a 404 error code, the server
sends a search page, to help figure out where the missing page has gone.

The getErrorStream() method returns an InputStream containing this page or null
if no error was encountered or no data returned:

public InputStream getErrorStream()

Generally, you'll invoke getErrorStream() inside a catch block after getInputStream()
has failed. The following example, demonstrates a program that reads from the input stream.
If it fails for any reason, it then reads from the error stream instead:

import java.io.*;
import java.net.*;

public class SourceViewer4{
	public static void main(String[] args){
		try{
			URL u = new URL(args[0]);
			HttpURLConnection uc = (HttpURLConnection) u.openConnection();
			try(InputStream raw = uc.getInputStream()){
				printFromStream(raw);
			} catch (IOException ex){
				printFromStream(uc.getErrorStream());
			}
		} catch (MalformedURLException ex){
			System.err.println(args[0] + " is not a parseable URL");
		} catch (IOException ex){
			System.err.println(ex);
		}
	}

	private static void printFromStream(InputStream raw) throws IOException{
		try (InputStream buffer = new BufferedInputStream(raw)){
			Reader reader = new InputStreamReader(buffer);
			int c;
			while ((c = reader.read()) != -1){
				System.out.println((char) c);
			}
		}
	}
}

Redirects:

The 300-level response codes all indicate some sort of redirect.
That is, the requested resource is no longer available at the
expected location but it may be found at some other location.

When encountering such a response, most browsers automatically
load the document from its new location. However, this can be a 
security risk, because it has the potentional to move the user
from a trusted site to an untrusted one, perhaps without 
the user even noticing.

By default, an HttpURLConnection follwos redirects. However, the
HttpURLConnection class has two static methods that let you decide
wether to follow redirects:

public static boolean getFollowRedirects()

public static void setFollowRedirects(boolean follow)

The getFollowRedirects() method returns true if redirects are being followed,
false if they are not. With an argument of true, the setFollowRedirects()
method makes HttpURLConnection objects follow redirects.

If false, it prevents them from following redirects. Because it is 
static, it affects all created objects to which are made after this
method is set.

The setFollowRedirects() method may throw a SecurityException if the
security manager disallows the change. Applets especially are not allowed
to change this value.

Java has two methods to configure redirections on an instance-by-instance basis.
These are:

public boolean getInstanceFollowRedirects()

public void setInstanceFollowRedirects(boolean followRedirects)

If setInstanceFollowRedirects() is not invoked on a given HttpURLConnection,
that HttpURLConnection simply follows the default behavior as set by the
class method HttpURLConnection.setFollowRedirects()

Proxies:

Many users behind firewalls or using AOL or other high-volume ISPs access
the web through proxy servers. The usingProxy() method tells you wether
the particular HttpURLConnection is going through a proxy server:

public abstract boolean usingProxy()

It returns true if a proxy is being used, false if not. In some contexts,
the use of a proxy server may have security implications.

Streaming Mode:

Every request sent to an HTTP server has an HTTP header. One field 
in this header is the Content-Length (i.e, the number of bytes in the body
of the request.) The header comes before the body.

However, to write the header you need to know the length of the body, which
you may not have yet. Normally, the way Java resolves this is by caching everything
you write onto the OutputStream retrieved from the HttpURLConnection until
the stream is closed.

At that point, it knows how many bytes are in the body so it has enough 
info to write the Content-length header.

This scheme is fine for small requests sent in response to typical web forms.
however, it is burdensome for responses to very long forms or some SOAP messages.
It's very wasteful and slow for medium or large documents sent with HTTP PUT.

It's much more efficient if Java doesn't have to wait for the last byte of data
to be written before sending the first byte of data over the network. Java offers
two solutions to this problem.

If you know the size of the data, for instance, you are uploading a file of known
size using HTTP PUT - you can tell the HttpURLConnection object the size 
of that data. If you don't know the size of your data in advance, you can use
chunked transfer encoding instead.

In chunked transfer encoding, the body of the request is sent in multiple pieces,
each with its own separate content length. To turn on chunked transfer encoding,
just pass the size of the chunks you want to the setChunkedStreamingMode()
before you connect the URL:

public void setChunkedStreamingMode(int chunkLength)

Java will then use a slightly different form of HTTP than the examples 
in this book. However, to the Java Programmers, the difference is irrelevant.

As long as you're using the URLConnection class instead of raw sockets and
as long as the server supports chunked transfer encoding, it should
all just work without further changes to your code.

However, chunked transfer encoding does get in the way of authentication and
redirection. If you're trying to send chunked files to a redirected URL
or one that requires password authentication, an HttpRetryException will be thrown.

You'll then need to retry the request at the new URL or at the old URL with the
appropiate credentials. and this all needs to be done manually without the full support
of the HTTP protocol handler you normally have.

Therefore, don't use chunked transfer encoding unless you really need it.
As with most performance advice, this means you should not implement this optimization
unless measurements prove the nonstreaming default is a bottleneck.

If you do happen to know the size of the request data in advance, you can 
optimize the connection by providing this information to the HttpURLConnection object.
if you do this, Java can start streaming the data over the network immedeatly.

Otherwise, it has to cache everything you write in order to determine the content length,
and only send it over the network after you've closed the stream. If you know exactly
how big your data is, pass that number to the setFixedLengthStreamingMode():

public void setFixedLengthStreamingMode(int contentLength)

public void setFixedLengthStreamingMode(long contentLength)

Because this number can actually be larger than the maximum size of an int,
there is a long version as well.

Java will use this number in the Content-length HTTP header field.
However,if you then try to write more or less than the number of bytes given here,
java will throw an IOException.

Of course, that happens alter, when you are writing data, not when you first
call this method.

The setFixedLengthStreamingMode() method itself will throw an IllegalArgumentException
if you pass in a negative number, or an IllegalStateException if the connection is
connected or has already been set to chunked transfer encoding.

(You CANNOT use both chunked transfer encoding and fixed-length streaming mode on the 
same request)

Fixed-length streaming mode is transparent on the server side. Servers neither
know nor care how the Content-length was set, as long as it is correct. However,
like chunked transfer encoding, streaming mode does interfere with authentication
and redirection. 

If either of these is required for a given URL, an HttpRetryException will be thrown,
you have to manually retry. Therefore, don't use this mode unless you really need it.

Sockets For Clients:

Data is transmitted across the Internet in packets of finite size called datagrams.
Each datagram contains a header and a payload. The header contains the address
and port to which the packet is going, the address and port from which the packet came,
a checksum to detect data corruption, and various other housekeeping info used
to ensure reliable transmission.

The payload contains the data itself. However, because datagrams have a finite
length, it's often necessary to split the data across multiple packets and 
reassmeble them at it's destination.

It's also possible that one or more packets may be lost or corrupted in 
transit and need to be retransmitted or that that packets arrive out of order
and need to be reordered.

Keeping track of this - splitting the data into packets, generating headers,
parsing the headers of incoming packets, keeping track of what packets 
have and have not been received, and so on - is a lot of work and requires
a lot of intricate code.

Fortunately, we don't have to do that ourselves. Sockets allow the programmer
to treat a network connection as just another stream onto which bytes can be
written and from which bytes can be read. Sockets shield the programmer 
from low-level details of the network, such as error detection, packet sizes,
packet splitting, packet retransmission, network addresses and more.

Using Sockets:

A socket is a connection between two hosts. It can perform seven basic
operations:

Connect to a Remote machine

Send data

Receive Data

Close a Connection

Bind to a Port

Listen for incoming data

Accept connections from remote machines on the bound port

Java's Socket class, which is used by both clients and servers, has methods
 that correspond to the first four of these operations. The last three operations
 are needed only by servers, which wait for clients to connect to them.

They are implemented by the ServerSocket class, which is discussed in the next
chapter. Java programs normally use client sockets in the following fashion:

The program creates a new socket with a consructor

The soket attempts to connect to the remote host.

Once the connection is established, the local and remote hosts get input and
output streams from the socket and use those streams to send data to each other.

This connection is full-duplex. Both hosts can send and receive data simultaneously.
What the data means depends on the protocol; different commands are sent to an
FTP server than to a HTTP server. There will normally be some agreed-upon handshaking
followed by the transmission of data from one to the other.

When the transmission of data is complete, one or both sides close the connection.
Some protocols, such as HTTP 1.0, require the connection to be closed after each
request is serviced. 

Others, such as FTP and HTTP 1.1,allow multiple requests to be processed in a single
connection.

Investigating Protocols with Telnet:

In this chapter, you'll see clients that use sockets to communicate with a number
of wellknown Internet services such as time, dict and more. The sockets themselves
are simple enough; however, the protocols to communicate with different servers
make life complex.

To get a feel for how a protocol operates, you can use Telnet to connect to a 
server, type different commands to it, and watch its responses. By default,
Telnet attempts to connect to port 23. To connect to servers on different ports,
specify the port you want to connect to, like this:

$ telnet localhost 25

This requests a connection to port 25, the SMTP port, on the local machine;
SMTP is the protocol used to transfer email between servers or between a 
mail client and a server.

If you know the commands to interact with an SMTP server, you can send
email without going through a mail program. This trick can be used to
forge email. 

An example of interaction with SMTP is as follows:

telnet localhost 25
Trying 127.0.0.1 ...
Connected to localhost.sunspot.noao.edu.
Escape character is '^]'.
220 flare.sunspot.noao.edu Hello localhost [127.0.0.1], pleased to meet you.
MAIL FROM: bart
250 bart.. Sender ok
RCPT TO: local@sunspot.noao.edu
250 local@sunspot.noao.edu.. Recipient ok
DATA
354 Enter mail, end with "." on a line by itself.

<text>

250 Mail accepted
QUIT
221 flare.sunspot.noao.edu delivery mail
Connection closed by foreign host

Since the 20 years ago this occurred, most SMTP servers have added
a little more security than shown here. They tend to require 
usernames and passwords, and only accept connections from clients in the local
networks and other trusted mail servers.

However, it is still the case that you can use Telnet to simulate a client,
see how the client and the server interact, and thus learn what your java program
needs to do. Although this session does not demonstrate all of the features of the
SMTP protocol, it's sufficient to enable you to deduce how a simple email
client talks to a server.

Reading from Servers with Sockets:

Let's begin with a simple example. You're going to connect to the daytime
server at the NIST and ask it for the current time.

This protocol is defined in RFC 867. Reading that, you see that the 
daytime server listens on port 13, and that the server sends the time
in a human-readable format and closes the connection.

You can test the daytime server with Telnet like this:

$ telnet time.nist.gov 13
Trying 129.6.15.28...
Connected to time.nist.gov.
Escape character is '^]'.

5637 13-03-24 13:37:50 50 0 0 888.8 UTC(NIST)*
Connection closed by foreign host.

The line "56375 13-03-24 13:37:50 <etc>" is sent by the daytime server.
When you read the Socket's InputStream, this is what you will get.
The other lines are produced either by the Unix shell or by the Telnet program.

RFC 867 does not specify any particular format for the output other than that
it be human readable. In this case, you can see the time etc.

The time is dfined as follows:

JJJJ YY-MM-DD HH:MM:SS TT L H msADV UTC(NIST) OTM where:

JJJJ is the "Modified Julain Date" (a different epoch timer, counts whole days since nov 17, 1858)

YY-MM-DD //years, month, day

HH:MM:SS //Hour, minute, second

TT //Indicates US Standard time or Daylight savings, 00 is standard, 50 is Daylight.
Others means just counting down until switchover

L is a one-digit code for leapsecond, 0 for no, 1 yes, 2 to subtract

H represents health of the server. 0 is healthy, 1 is up to 5 seconds off, 
2 means > 5 seconds, 3 is unkonwn accuracy, 4 is Maintance mode.

msADV is a number of miliseconds defined to compensate for network delay, based
on estimation of response to return

UTC(NIST) is a constant and the OTM is almost a constant (a *, unless something is wrong).

These details are all NIST specific, they are not part of the daytime standard.
Although they give a lot of data, if you programatically have to sync with a network
time server, you're better off using the NTP protocol defiend in RFC 5905 instead.

To retrieve the data, just open a socket:

Socket socket = new Socket("time.nist.gov", 13);

This doesn't just create the object. It actually makes the connection across
the network. If the connection times out or fails because the server is not listening
on port 13, then the constructor throws an IOException, so you'll usually
wrap this in a try block.

We can simple try with resources:

try (Socket socket = new Socket("time.nist.gov", 13)){
	//read from teh socket..
} catch (IOException ex){
	System.err.println("Could not connect to time.nist.gov");
}

The next step is optional, but highly recommended. Set a timeout on
the connection using the setSoTimeout() method. Timeouts are measured
in milliseconds, so this statement sets the socket to time out
after 15 seconds of non-responsiveness.

socket.setSoTimeout(15000);

Although a socket should throw a ConnectException pretty quickly 
if the server rejects the connection, or a NoRouteToHostException
if the routers can't figure out how to send you packets to the server,
neither of these help you with the case where a misbehaving server
accepts the connection and then stops talking to you without 
actively closing the connection.

Setting a timeout on the socket means that each read from or
write to the socket will take at most certain number of milisecs.
If a server hangs while you're connected to it, you will be notified
with a SocketTimeoutException.

Exactly how long a timeout to set depends on the needs of your application
and how responsive you expect the server to be. Fifteen seconds is a 
long time for a local intranet server to respond, but it's rather
short for a overencumbered public server.

Once you've opened the socket and set its timeout, call getInputStream()
to return an InputStream you can use to read bytes from the socket.
In general, a server can send any bytes at all, but in this specific
case, the protocol specifies that those bytes must be AScII:


InputStream in = socket.getInputStream();
StringBuilder time = new StringBuilder();

InputStreamReader reader = new InputStreamReader(in, "ASCII");
for (int c = reader.read(); c != -1; c = reader.read()){
	time.append((char) c);
}
System.out.println(time);

Here, i've stored the bytes in a StringBuilder. You can, of course, use any
data structure that fits your problem to hold the data that comes off the network.

The following example puts this all together in a program that also allows you to
choose a different daytime server:

import java.net.*;
import java.io.*;

public class DaytimeClient {
	public static void main(String[] args){
		String hostname = args.length > 0 ? args[0] : "time.nist.gov";
		Socket socket = null;
		try{
			socket = new Socket(hostname, 13);
			socket.setSoTimeout(15000);
			InputStream in = socket.getInputStream();
			StringBuilder time = new StringBuilder();

			InputStreamReader reader = new InputStreamReader(in, "ASCII");
			for (int c = reader.read(); c != -1; c = reader.read()){
				time.append((char) c);
			}
			System.out.println(time);
		} catch (IOException ex){
			System.err.println(ex);
		} finally{
			socket.close();
		} catch (IOException ex){
			//Ignore
		}
	}
}

Typical output will be much the same as if you connected with Telnet

As far as network-specific code goes, that's pretty much it. In most
network programs like this, the real effort is in speaking the protocol
and comprehending the data formats.

For instance, rather than simply printing out the text the servers
sends you, you might want to parse it into java.util.Date object instead.

The following example showcases how to do this:

import java.net.*;
import java.text.*;
import java.util.Date;
import java.io.*;

public class Daytime{
	public Date getDateFromNetwork() throws IOException, ParseException{
		try (Socket socket = new Socket("time.nist.gov", 13)){
			socket.setSoTimeout(15000);
			Inputstream in = socket.getInputStream();
			StringBuilder time = new StringBuilder();

			InputStreamReader reader = new InputStreamReader(in, "ASCII");
			for (int c = reader.read(); c != -1; c = reader.read()){
				time.append((char) c);
			}
			return parseDate(time.toString());
		}
	}

	static Date parseDate(String s) throws ParseException{
		String[] pieces = s.split(" ");
		String dateTime = pieces[1] + " " + pieces[2] + " UTC";
		DateFormat format = new SimpleDateFormat("yy-MM-dd hh:mm:ss z");
		return format.parse(dateTime);
	}
}

When reading data from the network, it's important to keep in mind that
not all protocols use ASCII or even text. For example, 	the time protocol
specified in RFC 868 specifies that the time be sent as the number of seconds
since Midnight, january 1, 1900, GMT.

However, it does not send it in ASCII. It sends it in a 32-bit unsigned
big-endian binary number.

The RFC never actually comes out and says that this is the format used.
It specifies 32 bits and assumes you know that all network protocols
use big-endian numbers. The fact that hte numbers is unsigned can be
determined only by calculating the wraparound date for signed 
and unsigned integers and comparing it to the date given in the
specification (2036).

To make matters worse, the specification gives an example of a 
negative time that can't actually be sent by time servers that
follow the protocol. Time is relativily old protocol, standardized
in the early 1980's.

If you find yourself implementing a not particularly well defined 
protocol, you have to do a significant amount of work to test against
existing implementations to figure out what you need to do.

Because the time protocol doesn't send back text, you can't easily use
Telnet to test such a service, and your program can't read the
server response with a Reader or any sorts of readLine() method.

A Java program that connects to time servers must read the raw
bytes and interpet them appropiately. In this example, that job 
is complicated by Java's lack of 32-bit unsigned int type.

Consequently, you have to read the bytes one at a time, and manually
convert them into a long using bitwise operators << and |.

When speaking with other protocols, you might find even more alien
numbers to Java, such as 64-bit fixed-point numbers. There 
is no shortcut to handle them.

An example of dealing with 32-bit unsigned ints from Time Servers,
follows:

import java.net.*;
import java.text.*;
import java.util.Date;
import java.io.*;

public class Time{
	private static final String HOSTNAME = "time.nist.gov";

	public static void main(String[] args) throws IOException, ParseException{
		Date d = Time.getDateFromNetwork();
		System.out.println("It is " + d);
	}

	public static Date getDateFromNetwork() throws IOException, ParseException{
		//The difference between javas 1970 epoch and Times 1900 epoch

		long differenceBetweenEpochs = 2208988880L;

		Socket socket = null;
		try{
			socket = new Socket(HOSTNAME, 37);
			socket.setSoTimeout(15000);

			InputStream raw = socket.getInputStream();

			long secondsSince1900 = 0;

			for (int i = 0; i < 4; i++){
				secondsSince1900 = (secondsSince1900 << 8) | raw.read();
			}

			long secondsSince1970 = secondsSince1900 - differenceBetweenEpochs;
			long msSince1970 = secondsSince1970 * 1000;
			Date time = new Date(msSince1970);

			return time;
		} finally {
			try{
				if (socket != null) socket.close();
			}
			catch (IOException ex) {}
		}
	}
}

The time protocol is in GMT, but the date class converts to local hsot time.

Writing to Servers with Sockets:

Writing to a server is not noticably harder than reading from a server. You simply
ask the socket for an output stream as well as an input stream. Although it's possible
to send data over the socket using the output stream at the same time you're reading
data over the input stream, most protocols are designed so that you are either
reading or writing over a socket, not both at the same time.

In the most common pattern, the client sends a request. Then the server responds.
The client may send another request, and the server responds again. 
This repeats until one side or the other is done and closes the connection.

One simple bidirectional TCP protocol is dict, defined in RFC 2229. In this
protocol, the client opens a socket to port 2628 on the dict server and sends
commands such as "DEFINE eng-lat gold".

This tells the server to send a definition of the word gold using its English-to-latin
dictionary. (Different servers have different dictionaries installed)

After the first definition is recieved, the client can ask for another. When it's done
it sends the command "quit". You can explore dict with Telnet like this:

$ telnet dict.org 2628
Trying 216.18.20.172...
Connected to dict.org.

Escape character is '^]'.
220 pan.alephnull.com dictd 1.12.0/rf on Linux 3.0.0-14-server
	<auth.mime> <499772.29595.1364340382@pan.alephnull.com>
DEFINE eng-lat gold
150 1 definitions retrieved
151 "gold" eng-lat "English-Latin Freedict dictionary"

//etc.
.
250 ok [d/m/c = 1/0/10; 0.000r 0.000u 0.000s]
DEFINE eng-lat computer
552 no match [d/m/c = 0/0/9; 0.000r 0.000u 0.000s]
quit
221 byte [d/m/c = 0/0/0; 42.000r 0.000u 0.000s]

If no match is found, it returns 552 no match. All of the info about
said protocol is in the RFC.

It is not hard to implement this protocol in Java. First, open a Socket
to a dict server, such as dict.org on port 2628:

Socket socket = new Socket("dict.org", 2628);

Once again you'll want to set a timeout in case the server hangs while you're
connected to it:

socket.setSoTimeout(15000);

In the dict protocol, the client speaks first, so ask for the output stream
using getOutputStream():

OutputStream out = socket.getOutputStream();

The getOutputStream returns a raw output stream for writing data from
your app to the other end of the socket. You usually chain this stream to
a more convenient class like DataOutputStream or OutputStreamWriter
before using it.

For performance reasons, it's a good idea to buffer it as well. 
Because the dict protocol is text based, more specifically UTF-8
based, it's convenient to wrap this in a Writer:

Writer writer = new OutputStreamWriter(out, "UTF-8");

Now write the command over the socket:

writer.write("DEFINE eng-lat gold\r\n");
writer.flush();

//Flush so we are assured its sent over the network

The server should now respond with a definition. You can read it
using the Sockets input Stream:

InputStream in = socket.getInputStream();
BufferedReader reader = new BufferedReader(new InputStreamReader(in, "UTF-8"));
for (String line = reader.readLine(); !line.equals("."); line = reader.readLine()){
	System.out.println(line);
}

When we see a single period alone on a line, we know it's complete.
write the quit

writer.write("quit\r\n");
writer.flush();

The following is an example of a complete dict client:

import java.io.*;
import java.net.*;

public class DictClient{
	public static final String SERVER = "dict.org";
	public static final int PORT = 2628;
	public static final int TIMEOUT = 15000;

	public static void main(String[] args){
		Socket socket = null;
		try{
			socket = new Socket(SERVER, PORT);
			socket.setSoTimeout(TIMEOUT);
			OutputStream out = socket.getOutputStream();

			Writer writer = new OutputStreamWriter(out, "UTF-8");
			writer = new BufferedWriter(writer);

			InputStream in = socket.getInputStream();
			BufferedReader reader = new BufferedReader(new InputStreamReader(in, "UTF-8"));

			for (String word : args){
				define(word, writer, reader);
			}

			writer.write("quit\r\n");
			writer.flush();


		} catch (IOException ex){
			System.err.println(ex);
		} finally {
			if (socket != null){
				try{
					socket.close();
				} catch (IOException ex){
					//ignore
				}
			}
		}
	}

	static void define(String word, Writer writer, BufferedReader reader) throws IOException,
		UnsupportedEncodingException {

		writer.write("DEFINE eng-lat " + word + "\r\n");
		writer.flush();

		for (String line = reader.readLine(); line != null; line = reader.readLine()){
			if (line.startsWith("250")){
				return; 
			} else if (line.startsWith("552 ")) {
				System.out.println("No definition found for " + word);
				return;
			}
			else if (line.matches("\\d\\d\\d .*")) continue;
			else if (line.trim().equals(".")) continue;
			else System.out.println(line);
		}
	}
}

Half-closed sockets:

The close() method shuts down both input and output from the socket. On ocassion,
you may want to shut down only half of the connection, either input or output.
The shutdownInput() and shutdownOutput() methods close only half the connection:

public void shutdownInput() throws IOException

public void shutdownOutput() throws IOException

Neither actually closes the socket. Instead, they just adjust the stream connected
to the socket so that it thinks it's at the end of the stream. Further reads
from the input stream after shutting down input return -1.

Further writes to a socket that had its output shutdown, throws an IOException.

Many protocols, such as finger, whois and HTTP, begin with the client sending
a request to the server, then reading the response. It would be possible
to shut down the output after the client has sent the request.

For example, this example sends a request to a HTTP server and then shuts down
the output, because it won't need to write anything else over this socket:

try (Socket connection = new Socket("www.oreilly.com", 80")){
	Writer out = new OutputStreamWriter(connection.getOutputStream(), "8859_1");
	out.write("GET / HTTP 1.0\r\n\r\n");
	out.flush();
	connection.shutdownOutput();

	//read the response by getting inputStream from connection
} catch (IOException ex){
	ex.printStackTrace();
}

Like earlier stated, shutting down input or output, just causes them to understand
it as EOF. You still have to close them when you're done with em.

The isInputShutdown() and isOutputShutdown() methods tells you wether the input
and output streams are open or closed, respectively. You can use these (rather than
isConnected() and isClosed()), to get a more honest view of the state:

public boolean isInputShutdown()

public boolean isOutputShutDown()

Constructing and Connecting Sockets:

The java.net.Socket class is java's fundamental class for performing 
client-side TCP operations. Other client-oriented classes that make TCP
network connections such as URL, URLConnection, Applet, and JEditorPane 
all ultimately end up invoking the methods of this class.

This class itself uses native code to communicate with the local TCP stack
of the Host OS.

Basic Constructors:

Each Socket constructor specifies the host and the port to connect to.
Hosts may be specified as an InetAddress or a String. Remote ports are 
specified as int values from 1 to 65535:

public Socket(String host, int port) throws UnkonwnHostException, IOException

public Socket(InetAddress host, int port) throws IOException

You feed in the ip and port, and it establishes a connection to said place.
If an error happens, its either a UnkonwnHostException or a IOException.

There are many reasons to why the host you are trying to reach might not accept
your connection on that port: the hsot might not accept connections on that port,
the hotel Wifi might not accept until you pay, or a routing issue may be preventing
your packets from reaching their destination.

We can use the constructor to see if connections to a specific port are allowed:

The following example scans the first 1024 ports of TCP servers on a specified host:

import java.net.*;
import java.io.*;

public class LowPortScanner{
	public static void main(String[] args){
		String host = args.length > 0 ? args[0] : "localhost";

		for (int i = 1; i < 1024; i++){
			try{
				Socket s = new Socket(host, i);
				System.out.println("There is a server on port " + i + " of " + host);
				s.close();
			} catch (UnknownHostException ex){
				System.err.println(ex);
				break;
			} catch (IOException ex){
				//must not be a server on this port
			}
		}
	}
}

We can use this to find servers being run on things. On Unix systems,
we might find out more in /etc/services. If the program runs into
ports that are running servers, but not listed, then that is a problem.

It might also tell us that someone is running servers on certain ports 
, which could be saturating our Broadband.

There are three consturctors for better control, such as defining proxies servers,
or an encryption scheme:

public Socket()

public Socket(Proxy proxy)

protected Socket(SocketImpl impl)

Picking a Local Interface to Connect From:

There are two constructors that allow for defining connecting to and the interface and
port to connect from:

public Socket(String host, int port, InetAddress interface, int localPort) throws IOException,
	UnknownHostException

public Socket(InetAddress host, int port, InetAddress interface, int localPort) throws IOException

This socket connects to the host and port specified in the first two args. 
It connects from the local network interface and port specified by the last two args.
The network interface may be either physical (e.g an Ethernet card) or virtual (a multihomed
host with more than one IP address)

If 0 is passed for the localPort arg, Java chooses a random one between 1024 and 65535

Selecting a particular network interface from which to send data is uncommon,
but a need does come up ocassionally. One situation where you might want to do so,
is when you encounter a router/firewall that uses dual Ethernet ports.

Incoming connections would be accepted on one interface, processesed and forwarded
to the local network from the otehr interface.

Suppose you were writing a program to periodically dump error logs to a printer or send
them over an internal mail server. You'd want to make sure you used the inward-facing
network interface instead of the outward-facing network interface.

For example:

try{
	InetAddress inward = InetAddress.getByName("router");
	Socket socket = new Socket("mail", 25, inward, 0);
	//Work with the sockets
} catch (IOException ex){
	System.err.println(ex);
}

In addition to the previous errors, it might throw a BindException (subclass of IOEXception)
if the socket is unable to bind to the requested local network interface. for instance,
a program running on a.example.com can't connect from b.example.org.

We could take advatange of this to restrict a compiled program to run on only a predetermined
host. It is far from foolproof, cause java programs are easy to disassemble, decompile and 
reverse engineer. And it would require customization on each computer.

Constructing without Connecting:

If we wish to make a Socket without defauling a connection to it, we can just use the Socket() constructor.

try{
	Socket socket = new Socket();
	//Fill in socket options
	SocketAddress address = new InetSocketAddress("time.nist.gov", 13);
	socket.connect(address);
	//Work with the sockets
} catch (IOException ex){
	System.err.println(ex);
}

We can also delimit time of timeout on connect:

public void connect(SocketAddress endpoint, int timeout) throws IOException;

The default is 0, which means forever.

An example of using the noargs socket:

Socket socket = new Socket();
SocketAddress address = new InetSocketAddress(SERVER, PORT);
try{
	socket.connect(address);
	//Work with the socket
} catch(IOException ex){
	System.err.println(ex);
} finally {
	try{
		socket.close();
	} catch (IOException ex){
		//ignore
	}
}

Java 7 has autoclosing Sockets, tho.

Socket Addresses:

The SocketAddress class represents a connection endpoint. It is an empty abstract
class with no methods aside from a default constructor. 

Only TCP/IP Sockets are supported in java, and the addresses we use are all
instaces of InetSocketAddress.

The SocketAddress, acts like a container, to retain info about IPs and Ports,
even after garbage collection.

public SocketAddress getRemoteSocketAddress() //gets the address of the remote connection

public SocketAddress getLocalSocketAddress() //gets the address of the local connection

An example of storing an address:

Socket socket = new Socket("www.yahoo.com", 80);
SocketAddress yahoo = socket.getRemoteSocketAddress();
socket.close();

//Reconnect

Socket socket2 = new Socket();
socket2.connect(yahoo);

The InetSocketAddress class (subclass of SocketAddress) is usually created
with a host and a port (for clients) or just a port (servers)

public InetSocketAddress(InetAddress address, int port)

public InetSocketAddress(String host, int port)

public InetSocketAddress(int port)

You can also use the static factory method createUnresolved() to skip looking up the host in DNS:

public static InetSocketAddress createUnresolved(String host, int port)

Some getters for InetSocketAddress:

public final InetAddress getAddress()

public final int getPort()

public final String getHostName()

Proxy Servers:

We can also instansiate sockets with specific Proxies (or just bypass all, there of):

public Socket(Proxy proxy)

the proxy server is normally set by socksProxyHost and socksProxyPort system props.
but this one allows us to define it ourselves.

We can also, like i said, do Proxy.NO_PROXY, to bypass proxies.

Example of running a low-level proxy: //Socks being the only one

SocketAddress proxyAddress = new InetSocketAddress("myproxy.example.com", 1080); //Proxy to this
Proxy proxy = new Proxy(Proxy.Type.SOCKS, proxyAddress);
Socket s = new Socket(proxy);

SocketAddress remote = new InetSocketAddress("login.ibiblio.org", 25); //against

SOCKS is the only low-level proxy type Java understands. There's also a high level
Proxy.Type.HTTP that works in the application  layer rather than the transport layer
and a Proxy.Type.DIRECT that represents proxyless connections.

Getting INformation about A Socket:

Getters:

public InetAddress getInetAddress() //target ip

public int getPort() //target port

public InetAddress getLocalAddress() //local ip

public int getLocalPort() //local port

There are no setters for Sockets, they are set upon creation.

Unlike the remote port, which (for a client socket) is usually a wellkonwn port
that has been pre-assigned, local ones are randomly chosen from available ones.
They are sent with the Ip address  in the outbound Ip packets, so the server
can send data back to the right port on the client.

We can check to see if a Socket is closed, by isClosed(). It will return false
if the Socket has never connected to begin with, or is closed.

To find out wether it has ever been connected, use isConnected().

To see if a Socket is connected, like, active, we need to run both !isClosed() and isConnected()
isBound() tells if it has successfully bound to the local IP.

To get a wholesome info about a socket, use toString().

Setting Socket Options:

There are 9 options for client-side sockets:

TCP_NODELAY : Sent ASAP. Waits for response of previous packet arriving. Disables buffering.
Throws an exception if Socket does not support TCP_NODELAY.

public void setTcpNoDelay(boolean on) throws SocketException

public boolean getTcpNoDelay() throws SocketException

SO_BINDADDR 

SO_TIMEOUT : The socket does not block for more than set milliseconds. Upon expiration,
InterupptedIoException is thrown, but Socket is not disrupted. Can still read from Socket.

public void setSoTimeout(int milliseconds) throws SocketException

public int getSoTimeout() throws SocketException


SO_LINGER : Amount of time for Sockets to linger with their data. Throws Exception if
its not supported. getSoLinger() can return -1 on it being disabled.

public void setSoLinger(boolean on, int seconds) throws SocketException //can't accept negative values

public int getSoLinger() throws SocketException

SO_SNDBUF / SO_RCVBUF : Small packets benefit from small buffers. Big data from big buffers. Faster
connections can use big buffers.  Maximum speed of a Socket is buffer-size/latency (seconds).
Try to match the "cap" a little bit under the speed of the connection provided.

SO_RCVBUF controls the suggested send buffer size for network input.

SO_SNDBUF controls the suggested send buffer size used for network output.

public void setReceiveBufferSize(int size) throws SocketException, IllegalArgumentException

public int getReceivedBufferSize() throws SocketException

//mirrored vversion for Send version 

The underlying OS might ignore you setting and set its own max (such as 64K buffer on linux/Unix).
The smallest of sending/recieving is used.

You can also increase speed by increaing the buffer sizes of OS, rather than sockets. But most
Modern OS:s automatically scale these buffers.


SO_KEEPALIVE : Sends a ping now and then to see that the server is alive. If the server is dead
for more than 11 minutes, the Socket closes.

The default is false.

OOBINLINE : Java can send urgent data bits or receive such. 

sendUrgentData(int data) throws IOException

Sends teh lowest order byte of its argument almost immedeatly. If needed,
cached data is flushed.

Usual approach is that urgent data ends in Queue, tells it exists, and has
target OS hunt for it in queue.

By default Java ignores urgent data from sockets. if turned on, it puts 
them in teh normal flow, however.

public void setOOBInline(boolean on) throws SocketException

public boolean getOOBInline() throws SocketException

IP_TOS : Defines Traffic interaction.

Uses DSCP (Differentiated Services Code Point) value and low-order two bits 
contain ECN (Explicit Congestion Notification)

Common DSCPs are:

PHB (per hob behavior) 	Binary 			purpose

Default 				000000			best-effort traffic

EF (Expedited forwarding) 101110 		low-loss, low-delay, low-jitter traffi. Limited to <= 30% of network traffic

Assured Forwarding (AF) multiple 		Assured delivery up to a specific rate

Class Selector 			xxx000 			Backward compatible with IPv4 TOS header

EF is good for VOIP. Example of making a socket with it:

Socket s = new Socket("www.yahoo.com", 80);
s.setTrafficClass(0xB8); //10111000 in binary

There is some further "hiearchy" of ordering in terms of preferances,
but a lot of underlying structure can ignore it. Thus, i will skip it.

a more general one: setPerformancePreferences(int connectionTime, int latency, int bandwidth)
Puts rank order of 1, 2 , 3 //higher is higher prio

Socket Exceptions:

BindExceptions occur if you try to construct a Socket or ServerSocket object
on a local port that is in use or that you do not have sufficient privileges to use.

ConnectException is refusal of connection, be that due to busy or no port of that number listened
on remote system.

NoRouteToHostException is timeout.

ProtocolException is when data recieved from the network violates the TCP/IP specification.

Sockets in GUI applications:

The following , are two classes, one that uses the Whois system and the other is a GUI for it:

import java.net.*;
import java.io.*;

public class Whois{
	public final static int DEFAULT_PORT = 43;
	public final static String DEFAULT_HOST = "whois.internic.net";

	private int port = DEFAULT_PORT;
	private InetAddress host;

	public Whois(InetAddress host, int port){
		this.host = host;
		this.port = port;
	}

	public Whois(InetAddress host){
		this(host, DEFAULT_PORT);
	}

	public Whois(String hostname, int port) throws UnknownHostException{
		this(InetAddress.getByName(hostname), port);
	}

	public Whois() throws UnknownHostException{
		this(DEFAULT_HOST, DEFAULT_PORT);
	}

	//Item to search for
	public enum SearchFor{
		ANY("any"), NETWORK("Network"), PERSON("Person"), HOST("Host"),
		DOMAIN("Domain"), ORGANIZATION("Organization"), GROUP("Group"),
		GATEWAY("Gateway"), ASN("ASN");

		private String label;

		private SearchFor(Sring label){
			this.label = label;
		}
	}

	//Categories to search in
	public enum SearchIn{
		ALL(""), NAME("Name"), MAILBOX("Mailbox"), HANDLE("!");

		private String label;

		private SearchIn(String label){
			this.label = label;
		}
	}

	public String lookUpNames(String target, SearchFor category, SearchIn group,
		boolean exactMatch) throws IOException{

		String suffix = "";
		if (!exactMatch) suffix = ".";

		String prefix = category.label + " " + group.label;
		String query = prefix + target + suffix;

		Socket socket = new Socket();

		try{
			SocketAddress address = new InetSocketAddress(host, port);
			socket.connect(address);
			Writer out = new OutputStreamWriter(socket.getOutputStream(), "ASCII");

			BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream(), "ASCII"));

			out.write(query + "\r\n");
			out.flush();

			StringBuilder response = new StringBuilder();
			String theLine = null;
			while ((theLine = in.readLine()) != null){
				response.append(theLine);
				response.append("\r\n");
			}

			return response.toString();
		} finally{
			socket.close();
		}
	}

	public InetAddress getHost(){
		return this.host;
	}

	public void setHost(String host) throws UnknownHostException{
		this.host = InetAddress.getByName(host);
	}
}

The rest is the GUI. For reasons of seeing how delegation to other threads
works, i will write them:

import java.awt.*;
import java.awt.event.*;
import java.net.*;
import javax.swing.*;

public class WhoisGUI extends JFrame{
	private JTextField searchString = new JTextField(30);
	private JTextArea names = new JTextArea(15, 80);
	private JButton findButton = new JButton("Find");

	private ButtonGroup searchIn = new ButtonGroup();
	private ButtonGroup searchFor = new ButtonGroup();
	private JCheckBox exactMatch = new JCheckBox("Exact Match", true);
	private JTextField chosenServer = new JTextField();

	private Whois server;

	public WhoisGUI(Whois whois){
		super("Whois");
		this.server = whois;
		Container pane = this.getContentPane();

		Font f = new Font("Monospaced", Font.PLAIN, 12);
		name.setFont(f);
		names.setEditable(false);

		JPanel centerPanel = new JPanel();
		centerPanel.setLayout(new GridLayout(1, 1, 10, 10));

		JScrollPane jsp = new JScrollPane(names);
		centerPanel.add(jsp);
		pane.add("Center", centerPanel);

		//Panel stuff

		ActionListener al = new LookupNames();
		findButton.addActionListener(al);
		searchString.addActionListener(al);
	}
	private JPanel initRecordType(){
		JPanel p = new JPanel();

		//Stuff

		JRadioButton any = new JRadioButton("Any", true);
		any.setActionCommand("Any");
		searchFor.add(any);
		p.add(any);

		//Stuff

		return p;
	}

	private JRadioButton makeRadioButton(String label){
		JRadioButton button = new JRadioButton(label, false);
		button.setActionCommand(label);
		searchFor.add(button);
		return button;
	}

	//The only real new part is the SwingWorker which delegates
	to background threading operations

	private class LookupNames implements ActionListener{
		@Override
		public void actionPerformed(ActionEvent event){
			names.setText("");
			SwingWorker<String, Object> worker = new Lookup(); //perform the lookup on a Worker thread
			worker.execute();
		}
	}

	//Also including eventQueue for asynch queing
	public static void main(String[] args){
		try{
			Whois server = new Whois();
			WhoisGUI a = new WhoisGUI(server);

			a.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);
			a.pack();
			EventQueue.invokeLater(new FrameShower(a)); //Delegate thread dispatching on thread
			//Dispatch thread, to avoid deadllock, race conditions and what not
		} catch (UnknownHostException ex){
			JOptionPane.showmessageDialog(null, "Could not locate default host " + Whois.DEFAULT_HOST,
				"Error", JOptionPane.ERROR_MESSAGE);
		}
	}

	private static class FrameShower implements Runnable{
		private final Frame frame;

		FrameShower(Frame frame);

		this.frame = frame;
	}

	@Override
	public void run(){
		frame.setVisible(true);
	}
}

The most important thing to denote for Asynch graphical stuff:

All updates to Swing components happen on the event dispatch thread.

No slow blocking operations, especially I/O, happen on the event dispatch
thread. 

Two methods that are of relevance in terms of concepts: //They are both abstract, override in subclass
//of SwingWorker

doInBackground(), performs long running
I/O heavy ops. Does not interact with GUI. can return any type and throw any exception.

done(), invoked on event dispatch thread after the doInBackground() returns. Can call get()
to get the value from doInBackground(). done() can interact with the GUI.

Sockets for Servers:

Server Sockets work functionally as the opposite of normal Client Sockets. They respond to incoming
calls, and get activated when connected to. after handshake and processing, the result gets sent back
over a Regular socket that the server Socket setup.

Using ServerSockets:

The ServerSocket class contains everything you need to write servers in Java.
It has constructors that create new ServerSocket objects, methods that listen
for connections on a specified port, methods that configure the various
socket options, and the usual misc methods such as toString().

The basic life cycle of a server program in Java, is this:

A new ServerSocket is created on a particular port using a ServerSocket() constructor.

The ServerSocket listens for incoming connection attempts on that port using its
accept() method. accept() blocks until a client attempts to make a connection,
at which point accept() returns a Socket object connecting the client and the server.

Depending on the type of server, either the Socket's getInputStream() method,
getOutputStream() method or both are called to get input and output streams 
that communicate with the client.

The server and the client interact according to an agreed-upon protocol until it
is time to close the connection.

The server, client or both, close the connection.

The server returns to step 2 (listening for connections).

The following example showcases how to make a simple server:

ServerSocket server = new ServerSocket(13);

Socket connection = server.accept(); //blocks until connection is made

//Chain the OutputStreamWriter cause of text writing

OutputStream out = connection.getOutputStream();

Writer writer = new OutputStreamWriter(out, "ASCII"); //error in book, its to chain to the outPutStream,
//Also we could buffer it

//writ something to the server

Date now = new Date();

out.write(now.toString(), "\r\n"); //Always erminate with a carriage return

out.flush(); //Flush and close
connection.close();

An example of a iterative (very simple, looping Server that is good for very simple protocols and small
requests, and works with a single connection. However, for bigger, we need multiple threads and Asynch I/O)

ServerSocket server = new ServerSocket(port);
while (true){
	try (Socket connection = server.accept()){
		Writer out = new OutputStreamWriter(connection.getOutputStream());
		Date now = new Date();

		out.write(now.toString() + "\r\n");
		out.flush();
	} catch (IOException ex){
		//Problem with one client, do not terminate server
		System.err.println(ex.getMessage());
	}
}

A simple showcase of the entire iterative server, where handling single requests does not shut down the server
and you have to kill the process manually:

import java.net.*;
import java.io.*;
import java.util.Date;

public class DaytimeServer{
	public final static int PORT = 13;

	public static void main(String[] args){
		try (ServerSocket server = new ServerSocket(PORT)){
			while (true){
				try (Socket connection = server.accept()){
					Writer out = new OutputStreamWriter(connection.getOutputStream());
					Date now = new Date();

					out.write(now.toString() + "\r\n");
					out.flush();
					connection.close();
				} catch (IOException ex) {}
			}
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

The following three examples, illustrates a few couple of Key points. The first, being
writing binary, nontext data:

import java.io.*;
import java.net.*;
import java.util.Date;

public class TimeServer{
	public final static int PORT = 37;

	public static void main(String[] args){
		long differenceBetweenEpochs = 2208988800L;

		try (ServerSocket server = new ServerSocket(PORT)){
			while (true){
				try (Socket connection = server.accept()){
					OutputStream out = connection.getOutputStream();
					Date now = new Date();
					long msSince1970 = now.getTime();

					long secondsSince1970 = msSince1970/1000;

					long secondsSince1900 = secondsSince1970 + differenceBetweenEpochs;

					byte[] time = new Byte[4];

					time[0] = (byte) ((secondsSince1900 & 0x0000000000FF000000L) >> 24);
					time[1] = (byte) ((secondsSince1900 & 0x00000000000FF00000L) >> 16);
					time[2] = (byte) ((secondsSince1900 & 0x00000000000000FF00L) >> 8);
					time[3] = (byte) (secondsSince1900 & 0x0000000000000000FFL);

					out.write(time);
					out.flush();
				} catch (IOException ex){
					System.err.println(ex.getMessage());
				}
			}
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

The next design, is a Thread per connection design, that circumvents the problem of a slow client
attempting to access into the Queue and hogging the main thread for processing connections.

The limit is defined by the OS (the max cap), whilst the default is 50 for Java. You can put
a higher cap, but never higher than the OS. The connections are stored in a first-in first-out
stack, which acts as a container for connections.

The following, is a multithreaded  daytime server approach:

import java.net.*;
import java.io.*;
import java.util.Date;

public class MultithreadedDaytimeServer{
	public final static in PORT = 13;

	public static void main(String[] args){
		try(ServerSocket server = new ServerSocket(PORT)){
			while(true){
				try{
					Socket connection = server.accept();
					Thread task = new DayTimeThread(connection);
					task.start();
				} catch (IOException ex){}
			}
		} catch (IOException ex){
			System.err.println("Couldn't start server");
		}
	}

	private static class DaytimeThread extends Thread{
		private Socket connection;

		DaytimeThread(Socket connection){
			this.connection = connection;
		}

		@Override
		public void run(){
			try{
				Writer out = new OutputStreamWriter(connection.getOutputStream());
				Date now = new Date();

				out.write(now.toString() + "\r\n");
				out.flush();
			} catch (IOException ex){
				System.err.println(ex);
			} finally {
				try{
					connection.close();
				} catch (IOException e){
					//ignore
				}
			}
		}
	}
}

The above design is flawed tho, as it can contain infinite connections,
meaning it can crash.

To delegate this, we make a thread pool, limiting the amount of threads:

import java.io.*;
import java.net.*;
import java.util.*;
import java.util.concurrent.*;

public class PooledDaytimeServer{
	public final static int PORT = 13;

	public static void main(String[] args){
		ExecutorService pool = Executors.newFixedThreadPool(50);

		try(ServerSocket server = new ServerSocket(PORT)){
			while (true){
				try{
					Socket connection = server.accept();
					Callable<Void> task = new DaytimeTask(connection);
					pool.submit(task);
				} catch (IOException ex){}
			}
		} catch (IOException ex){
			System.err.println("Couldn't start server");
		}
	}

	private static class DaytimeTask implements Callable<Void>{
		private Socket connection;

		DaytimeTask(Socket connection){
			this.connection = connection;
		}

		@Override
		public void call(){
			try{
				Writer out = new OutputStreamWriter(connection.getOutputStream());
				Date now = new Date();

				out.write(now.toString() + "\r\n");
				out.flush();
			} catch (IOException ex){
				System.err.println(ex);
			} finally {
				try{
					connection.close();
				} catch (IOException e){
					//ignore
				}
			}

			return null;
		}
	}
}

Writing to Servers with Sockets:

The main trick of writing to a server is to undersand when to write and when
to read.

What follows is an example of a echo program, communicating with a server:

import java.nio.*;
import java.nio.channels.*;
import java.net.*;
import java.util.*;
import java.io.IOException;

public class EchoServer{
	public static int DEFAULT_PORT = 7;

	public static void main(String[] args){
		int port;

		try{
			port = Integer.parseInt(args[0]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}
		System.out.println("Listening for connections on port " + port);

		ServerSocketChannel serverChannel;

		Selector selector;
		try{
			serverChannel = ServerSocketChannel.open();
			ServerSocket ss = serverChannel.socket();


			InetSocketAddress address = new InetSocketAddress(port);
			ss.bind(address);

			serverChannel.configureBlocking(false);
			selector = Selector.open();
			serverChannel.register(selector, SelectionKey.OP_ACCEPT);
 		} catch (IOException ex){
 			ex.printStackTrace();
 			return;
 		}

 		while (true){
 			try{
 				selector.select();
 			} catch (IOException ex){
 				ex.printStackTrace();
 				break;
 			}

 			Set<SelectionKey> readKeys = selector.selectedKeys();
 			Iterator<SelectionKey> iterator = readKeys.iterator();

 			while(iterator.hasNext()){
 				SelectionKey key = iterator.next();
 				iterator.remove();
 				try{
 					if(key.isAcceptable()){
 						ServerSocketChannel server = (ServerSocketChannel) key.channel();
 						SocketChannel client = server.accept();
 						System.out.println("accepted connection from " + client);
 						client.configureBlocking(false);
 						SelectionKey clientKey = client.register(selector, SelectionKey.OP_WRITE |
 							SelectionKey.OP_READ);

 						ByteBuffer buffer = ByteBuffer.allocate(100);
 						clientKey.attach(buffer);
 					}
 					if (key.isReadable()){
 						SocketChannel client = (SocketChannel) key.channel();
 						ByteBuffer output = (ByteBuffer) key.attachment();

 						output.flip();
 						client.write(output);
 						output.compact();
 					}
 				} catch (IOException ex){
 					key.cancel();
 					try{
 						key.channel().close();
 					} catch (IOException ex) {}
 				}
 			}
 		}
	}
}

Closing Server Sockets:

If you're finished with a server socket, you should close it, especially if 
the program is going to continue to run for some time. This frees up the 
port for other programs who might wish to use that port.

Closing a ServerSocket frees a port on the local host, allowing another server
to bind to that port. It also breaks all current open sockets that the ServerSocket
has accepted.

Server sockets are closed automatically when a program dies, so it's not absolutely
necessary to close them in programs that terminate shortly after the ServerSocket
is no longer needed.

We can do autoclosing with java 7, cause of try-with-resources:

try (ServerSocket server = new ServerSocket(port)){
	//Work with the server socket
}

We can also manually bind a SocketAddress to a ServerSocket:

ServerSocket server = new ServerSocket();
try{
	SocketAddress address = new InetSocketAddress(port);
	server.bind(address);
} finally {
	try{
		server.close();
	} catch (IOException ex){

	}
}

We can see if a socket is closed or bound with isClosed() and isBound()

to see if a Socket is open, you have to return !isClosed() and isBound(),
because isBound() tells if it has ever been bound. And a spawned socket
does not accoutn for being closed until after it has been closed.

Logging:

What to log:

Requests and Server errors.

We can log every request or every connection as we see fit.

The error log is for unexpected exceptions. Errors such as malformed urls and 
disconnects from the client goes in Requests log.

We can create loggers for each class respectively:

private final static Logger auditLogger = Logger.getLogger("requests"); //output to a log namd requests

Multiple loggers can log to teh same file, but each logger logs to one.

An example of logging:

catch(RuntimeException ex){
	logger.log(Level.SEVERE, "unexpected error " + ex.getMessage(), ex);
}

There are 7 levels of severity for logging:

Level.SEVERE (highest)

Level.WARNING

Level.INFO

Level.CONFIG

Level.FINE

Level.FINER

Level.FINEST (lowest)

Generally, logging should include time, date, client addrss and info related to the issue.

An example of a daytime server that logs requests and errors:

import java.io.*;
import java.net.*;
import java.util.Date;
import java.util.concurrent.*;
import java.util.logging.*;

public class LoggingDaytimeServer{
	public final static int PORT = 13;
	private final static Logger auditLogger = Logger.getLogger("requests");
	private final static Logger errorLogger = Logger.getLogger("errors");

	public static void main(String[] args){
		ExecutorService pool = Executors.newFixedThreadPool(50);

		try(ServerSocket server = new ServerSocket(PORT)){
			while (true){
				try{
					Socket connection = server.accept();
					Callable<Void> task = new DaytimeTask(connection);
					pool.submit(task);
				} catch (IOException ex){
					errorLogger.log(Level.SEVERE, "accept error", ex);
				} catch (RuntimeException ex){
					errorLogger.log(Level.SEVERE, "unexpected error " + ex.getMessage(), ex);
				}
			}
		} catch (IOException ex){
			errorLogger.log(Level.SEVERE, "Couldn't start server " + ex);
		} catch (RuntimeException ex){
			errorLogger.log(Level.SEVERE, "Couldn't start server: " + ex.getMessage(), ex);
		}
	}

	private static class DaytimeTask implements Callable<Void> {
		private Socket connection;

		DaytimeTask(Socket connection){
			this.connection = connection;
		}

		@Override
		public Void call(){
			try{
				Date now = new Date();

				//Write the log entry first in case the client disconnects
				auditLogger.info(now + " " + connection.getRemoteSocketAddress());

				Writer out = new OutputStreamWriter(connection.getOutputStream());
				out.write(now.toString(), "\r\n");
				out.flush();
			} catch (IOexception ex){
				//client disconnected, ignore
			} finally {
				try{
					connection.close();
				} catch(IOException ex){
					//ignore;
				}
			}
			return null;
		}
	}
}

An example of a Logging file setup:

handlers=java.util.logging.FileHandler
java.util.logging.FileHandler.pattern = /var/logs/daytime/requests.log
java.util.logging.FileHandler.limit = 100000
java.util.logging.FileHandler.count = 2
java.util.logging.FileHandler.formatter = java.util.logging.SimpleFormatter
java.util.logging.FileHandler.append = true
java.util.logging.SimpleFormatter.format = %4$s: %5$s [%1$tc]%n

request.level = INFO
audit.level = SEVERE

Constructing Server Sockets:

There are four public ServerSocket constructors.

public ServerSocket(int port) throws BindException, IOException

public ServerSocket(int port, int queueLength) throws BindException, IOException

public ServerSocket(int port, int queueLength, InetAddress bindAddress) throws IOException

public ServerSocket() throws IOException

To define a server socket using HTTP on port 80:

ServerSocket httpd = new ServerSocket(80);

To create one on port 80 that accepts 50 queues unaccepted connections at a time:

ServerSocket httpd = new ServerSocket(80, 50);

The third argue defines if we wish to specify to one specific IP.
This can be done to force connections to local endpoints:

InetAddress local = InetAddress.getByName("192.168.210.122");
ServerSocket httpd = new ServerSocket(5776, 10, local); //Force to listen to local connections
//only by virtue of specifying our own local and adding it as an arg

A value of 0 to Port is a random port (available one)

If there is a IOException, it is either due to attempting to access port which
another program is running on, or, you are attempting to run hosting without
root privs on Unix systems.

The following example finds all servers on all ports on the local machine:

import java.io.*;
import java.net.*;

public class LocalPortScanner{
	public static void main(String[] args){
		for (int port = 1; port <= 65535; port++){
			try{
				ServerSocket server = new ServerSocket(port);
			} catch (IOException ex){
				System.out.println("there is a server on port " + port + "");
			}
		}
	}
}

constructing without binding:

The no args constructor can create a ServerSocket that needs to be bound.
can be used for modifying options before binding.

public void bind(SocketAddress endpoint) throws IOException

public void bind(SocketAddress endpoint, int queueLength) throws IOException

General pattern:

ServerSocket ss = new ServerSocket();
//Set socket options
SocketAddress http = new InetSocketAddress(80);
ss.bind(http);

We can also pass null to the InetsocketAddress for port arg, which is basically 
like 0 (random port that is available)

Getting Information About a Server Socket:

to get the hosting address of a ServerSocket:

public InetAddress getInetAddress() //if multiple, returns one of them, returns null if 
//ServerSocket is unbound

To get your local port:

public int getLocalPort() //Returns -1 if port of socket is unbound

A simple example of hosting with a random port:

import java.io.*;
import java.net.*;

public class RandomPort{
	public static void main(String[] args){
		try{
			ServerSocket server = new ServerSocket(0);
			System.out.println("this server runs on port " + server.getLocalPort());
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

Socket Options:

There are three:

SO_TIMEOUT //Time to wait before timeout. 0 is default, which is forever:

public void setSoTimeout(int timeout) throws SocketException

public int getSoTimeout() throws IOException

SO_REUSEADDR  //Wether socket is reusable while data is in transit on said connection

public boolean getReuseAddress() throws SocketException

public void setReuseAddress(boolean on) throws SocketException

Default vlaue is platform dependant.


SO_RCVBUF //Defualt buffer size of the Socket in bytes. higher for faster 
connections. Default is usually fine. Buffer size defines suggestion of size of packets.

Class of Service:

For general classes of traffic for TCP:

Low cost

High reliability

Maximum throughput

Minimum delay

They act as hints, and can be ignored.

public void setPerformancePreferences(int connectionTime, int latency, int bandwidth);

//higher is higher prio, range is 1 to 3

HTTP servers:

A lot of the time, it is better to run a customized server. For performance.
Cause Apache and what not are general and quite bloated with handling different
requests, MIME types, URLs, etc.

An example would be a server that does images, that its smarter to perhaps load all of 
em and then run em from RAM on the server, rather than load from disk every time.

Sites that make heavy use of dynamic content through servlets, PHP pages or others,
gain a lot from putting their stuff onto a Pure java server.

The reason for this is because of the garbage collection, half-interpeted/half-compiled
and dynamic class loading, that java has.

Java is really competetive in terms of Servers when it comes to C, speaking of performance.

A Single-File Server:

The following example, is a Server that sends out one file, regardless of request:

//imports

public class SingleFileHTTPServer{
	private static final Logger logger = Logger.getLogger("SingleFileHTTPServer");

	private final byte[] content;
	private final byte[] header;
	private final int port;
	private final String encoding;

	public SingleFileHTTPServer(String data, String encoding,
		String mimeType, int port) throws UnsupportedEncodingException{
		this(data.getBytes(encoding), encoding, mimeType, port);
	}

	public SingleFileHTTPServer(
		byte[] data, String encoding, String mimeType, int port){
		this.content = data;
		this.port = port;
		this.encoding = encoding;
		String header = "HTTP/1.0 200 OK\r\n"
			+ "Server: OneFile 2.0\r\n"
			+ "Content-length: " + this.content.length + "\r\n"
			+ "Content-type: " + mimeType + "; charset=" + encoding +"\r\n\r\n";
		this.header = header.getBytes(Charset.forName("US-ASCII"));
	}

	public void start(){
		ExecutorService pool = Executors.newFixedThreadPool(100);
		try(ServerSocket server = new ServerSocket(this.port)){
			logger.info("Accepting connections on port " + server.getLocalPort());
			logger.info("Data to be sent");
			logger.info(new String(this.content, encoding));


			while(true){
				try{
					Socket connection = server.accept();
					pool.submit(new HTTPHandler(connection)); 
				} catch (IOException ex){
					logger.log(Level.WARNING, "Exception accepting connection", ex);
				} catch (RuntimeException ex){
					logger.log(Level.SEVERE, "Unexpected error", ex);
				}
			}
		} catch (IOException ex){
			logger.log(Level.SEVERE, "Could not start server", ex);
		}
	}

	private class HTTPHandler implements Callable<Void>{
		private final Socket connection;

		HTTPHandler(Socket connection){
			this.connection = connection;
		}

		@Override
		public void call() throws IOException{
			try{
				OutputStream out = new BufferedOutputStream(connection.getOutputStream());

				InputStream in = new BufferedInputStream(connection.getInputStream());

				//read the first line only, thats all we need
				StringBuilder request = new StringBuilder(80);

				while(true){
					int c = in.read();
					if(c == '\r' || c == '\n' || c == -1) break;
					request.append((char) c);
				}

				//if this is HTTP 1.0 or later, send a MIME header
				if(request.toString().indexOf("HTTP/") != -1){
					out.write(header);
				}

				out.write(content);
				out.flush();
			} catch (IOException ex){
				logger.log(Level.WARNING, "Error writing to client", ex);
			} finally {
				connection.close();
			}
			return null;
		}
	}

	public static void main(String[] args){
		//Set the port to listen on
		int port;
		try{
			port = Integer.parseInt(args[1]);
			if (port < 1 || port > 65535) port = 80;
		} catch (RuntimeException ex){
			port = 80;
		}

		String encoding = "UTF-8";
		if (args.length > 2) encoding = args[2];

		try{
			Path path = Path.get(args[0]);
			byte[] data = Files.readAllBytes(path);

			String contentType = URLConnection.getFileNameMap().getContentTypeFor(args[0]);
			SingleFileHTTPServer server = new SingeFileHTTPServer(data, encoding, contentType, port);

			server.start();
		} catch (ArrayIndexOutOfBoundsException ex){
			System.out.println("Usage: java SingleFileHTTPServer filename prot encoding");
		} catch (IOException ex){
			logger.severe(ex.getMessage());
		}
	}
}

A Redirector:

What follows is an example of a Redirector:

//imports

public class Redirector{
	private static final Logger logger = Logger.getLogger("Redirector");

	private final int port;
	private final String newSite;

	public Redirector(String newSite, int port){
		this.port = port;
		this.newSite = newSite;
	}

	public void start(){
		try(ServerSocket server = new ServerSocket(port)){
			logger.info("Redirecting connections on port " + server.getLocalPort() + " to " + newSite);

			while (true){
				try{
					Socket s = server.accept();
					Thread t = new RedirectThread(s);
					t.start();
				} catch (IOException ex){
					logger.warning("Exception accepting connection");
				} catch (RuntimeException ex){
					logger.log(Level.SEVERE, "Unexpected error", ex);
				}
			}
		} catch (BindException ex){
			logger.log(Level.SEVERE, "Could not start the server", ex);
		} catch (IOException ex){
			logger.log(Level.SEVERE, "Error opening server socket", ex);
		}
	}

	private class RedirectThread extends Thread{
		private final Socket connection;

		RedirectThread(Socket s){
			this.connection = s;
		}

		public void run(){
			try{
				Writer out = new BufferedWriter(new OutputStreamWriter(connection.getOutputStream(), "US-ASCII"));

				Reader in = new InputStreamReader(new BufferedInputStream(connection.getInputStream()));

				//Read first line, all we need
				StringBuilder request = new StringBuilder(80);

				while(true){
					int c = in.read();
					if (c == '\r' || c == '\n' || c == -1) break;
					request.append((char) c);
				}

				String get = request.toString();
				String[] pieces = get.split("\\w*");
				String theFile = pieces[1];

				//Send mime header
				if (get.indexOf("HTTP") != -1){
					out.write("HTTP/1.0 302 FOUND\r\n");
					Date now = new Date();
					out.write("Date:" + now + "\r\n");
					out.write("Server: Redirector 1.1\r\n");
					out.write("Location: " + newSite + theFile + "\r\n");
					out.write("Content-type: text/html\r\n\r\n");
					out.flush();
				}

				//not all browsers support redirection, so we 
				//write manually where it went
				out.write("<HTML><HEAD><TITLE>Document Moved</TITLE></HEAD>\r\n");
				out.write("<BODY><H1>Document Moved</H1>\r\n");
				out.write("The document " + theFile + " has moved to\r\n<A HREF=\"" + newSite + theFile +"\>"
					+ newSite + theFile
					+ "</A>.\r\n Please update your bookmarks<P>");
				out.write("</BODY></HTML>\r\n");
				out.flush();

				logger.log(Level.INFO, "Redirected " + connection.getRemoteSocketAddress());
			} catch(IOException ex){
				logger.log(Level.WARNING,
					"Error talking to " + connection.getRemoteSocketAddress(), ex);
			} finally {
				try{
					connection.close();
				} catch (IOException ex){}
			}
		}
	}

	public static void main(String[] args){
		int thePort;
		String theSite;

		try{
			theSite = args[0];
			//trim trailing slash

			if (theSite.endsWith("/")){
				theSite = theSite.substring(0, theSite.length() -1);
			}
		} catch (RuntimeException ex){
			System.out.println("Usage: java Redirector http://www.newsite.com/ port");
			return;
		}

		try{
			thePort = Integer.parseInt(args[1]);
		} catch (RuntimeException ex){
			thePort = 80;
		}

		Redirector redirector = new Redirector(theSite, thePort);
		redirector.start();
	}
}

Note: Browsers are responsible for converting Relative URLs to absolute URLs that 
begin with /.

Name and version of the server inclusion in the response is used for Web spiders
which determine statistics for the most popular sites.

The next example, is a fullblown HTTP server that can handle everything.
Basically it is like the Single file HTTP server, except that it pays
attention to get requests and uses a thread pooling system to handle requests:

//imports

public class JHTTP{
	private static final Logger logger = Logger.getLogger(JHTTP.class.getCanonicalName());

	private static final int NUM_THREADS = 50;
	private static final String INDEX_FILE = "index.html";

	private final File rootDirectory;
	private final int port;

	public JHTTP(File rootDirectory, int port) throws IOException{
		if(!rootDirectory.isDirectory()){
			throw new IOException(rootDirectory + " does not exist as a dir");
		}
		this.rootDirectory = rootDirectory;
		this.port = port;
	}

	public void start() throws IOException{
		ExecutorService pool = Executors.newFixedThreadPool(NUM_THREADS);
		try(ServerSocket server = new ServerSocket(port)){
			logger.info("Accepting connections on port " + server.getLocalPort());
			logger.info("Document Root: " + rootDirectory);

			while(true){
				try{
					Socket request = server.accept();
					Runnable r = new RequestProcessor(rootDirectory, INDEX_FILE, request);
					pool.submit(r);
				} catch(IOException ex){
					logger.log(Level.WARNING, "Error: Accepting connection " + ex);
				}
			}
		}
	}

	public static void main(String[] args){
		//Get the document root
		File docroot;

		try{
			docroot = new File(args[0]);
		} catch (ArrayIndexOutOfBoundsException ex){
			System.out.println("Usage: java JHTTP docroot port");
			return;
		}

		//Set the port to listen on
		int port;
		try{
			port = Integer.parseInt(args[1]);
			if (port < 0 || port > 65535) port = 80;
		} catch (RuntimeException ex){
			port = 80;
		}

		try{
			JHTTP webserver = new JHTTP(docroot, port);
			webserver.start();
		} catch (IOException ex){
			logger.log(Level.SEVERE, "Server could not start " + ex);
		}
	}
}

//The above class was just the Server per say, we now have to make a class
that handles the incoming requests:

//imports

public class RequestProcessor implements Runnable{
	private final static Logger logger = Logger.getLogger(RequestProcessor.class.getCannonicalName());

	private File rootDirectory;
	private String indexFileName = "index.html";
	private Socket connection;

	public RequestProcessor(File rootDirectory, String indexFileName, Socket connection){
		if(rootDirectory.isFile()){
			throw new IllegalArgumentException("rootDirectory must be a dir, not a file!");
		}
		try{
			rootDirectory = rootDirectory.getCanonicalFile();
		} catch (IOException ex){

		}
		this.rootDirectory = rootDirectory;

		if (indexFileName != null) this.indexFileName = indexFileName;
		this.connection = connection;
	}

	@Override
	public void run(){
		//For security checks
		String root = rootDirectory.getPath();
		try{
			OutputStream raw = new BufferedOutputStream(connection.getOutputStream());

			Writer out = new OutputStreamWriter(raw);

			Reader in = new InputStreamReader(new BufferedInputStream(connection.getInputStream()), "US-ASCII");

			StringBuilder requestLine = new StringBuilder();

			while (true){
				int c = in.read();
				if (c == "\r" || c == "\n") break;
				requestLine.append((char) c);
			}

			String get = requestLine.toString();

			logger.info(connection.getRemoteSocketAddress() + " " + get);

			String[] tokens = get.split("\\s+");
			String method = tokens[0];
			String version = "";

			if (method.equals("GET")){
				String fileName = tokens[1];
				if (fileName.endsWith("/")) fileName += indexFileName;

				String contentType = URLConnection.getFileNameMap().getContentTypeFor(fileName);

				if (tokens.length > 2){
					version = tokens[2];
				}

				File theFile = new File(rootDirectory, fileName.substring(1, fileName.length()));

				if (theFile.canRead()
					//Don't let clients outside the document root
					&& theFile.getCanonicalPath().startsWith(root)){
					byte[] theData = Files.readAllBytes(theFile.toPath());

					if (version.startsWith("HTTP/")){
						sendHeader(out, "HTTP/1.0 200 OK", contentType, theData.length);
					}

					//Send the file; it may be an image or other binary data
					//so use the underlying output stream
					// insteado f the writer
					raw.write(theData);
					raw.flush();
				} else { //Can't find the file
					String body = new StringBuilder("<HTML>\r\n")
						.append("<HEAD><TITLE>File Not Found</TITLE>\r\n")
						.append("</HEAD>\r\n")
						.append("<BODY>")
						.append("<H1>HTTP Error 404: File Not Found</H1>\r\n")
						.append("</BODY></HTML>\r\n").toString();
				if (version.startsWith("HTTP/")) {
					sendHeader(out, "HTTP/1.0 404 File Not Found",
						"text/html; charset=utf-8", body.length());
				}
				out.write(body);
				out.flush();
				}
			} else { //Method is not get
				String body = new StringBuilder("<HTML>\r\n");
					.append("<HEAD><TITLE>Not Implemented</TITLE>\r\n")
					.append("</HEAD>\r\n")
					.append("<BODY>")
					.append("<H1>HTTP Error 501: Not Implemented</H1>\r\n")
					.append("</BODY></HTML>\r\n").toString();
				if(version.startsWith("HTTP/")){
					sendHeader(out, "HTTP/1.0 501 Not Implemented", "text/html; charset=utf-8", body.length());
				}
				out.write(body);
				out.flush();
			}
		} catch (IOException ex){
			logger.log(Level.WARNING, "Error talking to " + connection.getRemoteSocketAddress(), ex);
		} finally {
			try{
				connection.close();
			}
			catch (IOException ex){}
		}
	}

	private void sendHeader(Writer out, String responseCode, String contentType, int length) throws IOException{
		out.write(responseCode + "\r\n");
		Date now = new Date();
		out.write("Date: " + now + "\r\n");
		out.write("Server: JHTTP 2.0\r\n");
		out.write("Content-length: " + length + "\r\n");
		out.write("Content-type: " + contentType + "\r\n\r\n");
		out.flush();
	}
}

There is a number of things we could do more with this server:

A server admin interface

Support for the java Servlet API

Support for other request methods, such as POST, HEAD and PUT.

Support for multiple document roots so indivudal users can have their own sites.

Further more, optimizaiton could be done. Smart-caching most frequent requests, running a low
prio thread to update this. Put the most frequent requested data in a map and cache it from there.

Can also use nonblocking I/O and channels instead of threads and streams. We will epxlore this 
later in Chap 11.

Secure Sockets:

JSSE (Java Secure Sockets Extension), can use SSL (Secure Sockets Layer) and TLS (Transport Layer Security)
protocols and their algorithms. SSL is a security protocol that enables web browsers and other TCP
clients to talk to HTTP and other TCP servers using various levels of confidentiality and authentication.

Secure Communications:

Text is combined with the bits of the key according to a mathematical algorithm, to procude
encrypted Ciphertext. Using keys with bits, makes messages harder to Brute force.

In traditional (symetric) encryption, same key is used for encryption and decryption.

However, we should use asymmeric encryption, meaning we have one public key that is used
for public usage (access to the encrypted file), whilst a private key (secret key)
is used for the decryption.

It can also be used for authentication and message integrity checking.
By virtue of decrypting with a secret key and using the corresponding public key,
integrity is ensured.

They could evne double encrypt the message, once with Gus's public key and once
with her private key. Getting the benefit of all three things (Privacy, Authentication, Integrity)

public-key encryption is much more CPU-intensive and much slower than secret key encryption.
Thus, secret key encryption is used.

One can do a man-in-the-middle attack by replacing the public key used by another, causing
injection in terms of decryption and allows for decryption of own private key later.

JSSE is divided into 4 packages:

javax.net.ssl //Abstract classes for secured network communication

javax.net //Socket factory for secure sockets

java.security.cert //classes for handling public-key certs needed for SSL

com.sun.net.ssl //Encryption algorithms and protocols

Creating Secure Client Sockets:

to get a secured socket, we create a factory and then create a socket from that:

SocketFactory factory = SSLSocketFactory.getDefault();
Socket socket = factory.createSocket("login.ibiblio.org", 7000);

//returns a socket connected to specified host and port, throws exception if they cannot connect

There are five constructors of createSocket: //And they are all abstract

public abstract Socket createSocket(String host, int port) throws IOException, UnknownHostException

public abstract Socket createSocket(InetAddress host, int port) throws IOException

//Returns a socket connected to specified host and port, from specified interface and port

public abstract Socket createSocket(String host, int port, InetAddress interface, int localPort) throws
	IOException, UnkonwnHostException

public abstract Socket createSocket(InetAddress host, int port, InetAddress interface, int localPort)
	throws IOException, UnknownHostException

//Goes through proxy to target destination. Boolean defines if underlying proxy
should turn off when socket is also turned off.

public abstract Socket createSocket(Socket proxy, String host, int port, boolean autoClose)
	throws IOException

An example of writing through a secure socket:

SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();

Socket socket = factory.createSocket("login.ibiblio.org", 7000);

Writer out = new OutputStreamWriter(socket.getOutputStream(), "US-ASCII");
out.write("Name: John Smith\r\n"); //Just write \r\n to finish off sentances and do write calls on data
out.flush();

//Use a StreamWriter cause ASCII text

The following example is one that connects to a HTTPS, runs a GEt and prints out the result:

import java.io.*;
import java.net.ssl.*;

public class HTTPSClient{
	public static void main(String[] args){
		if (args.length == 0){
			System.out.println("Usage: java HTTPS2Client host");
			return;
		}

		int port = 443; //default https port
		String host = args[0];

		SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();

		SSLSocket socket = null;

		try{
			socket = (SSLSocket) factory.createSocket(host, port);

			//Enable all the suites
			String[] supported = socket.getSupportedCipherSuites();
			socket.setEnabledCipherSuites(supported);

			Writer out = new OutputStreamWriter(socket.getOutputStream(), "UTF-8");
			//https requires the full URL in the get line
			out.write("GET http://" + host + "/ HTTP/1.1\r\n");
			out.write("Host: " + host + "\r\n");
			out.write("\r\n");
			out.flush();

			//Read response
			BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));

			//read the header
			String s;
			while (!(s = in.readLine()).equals("")){
				System.out.println(s);
			}
			System.out.println();

			//read the length
			String contentLength = in.readLine();
			int length = Integer.MAX_VALUE;

			try{
				length = Integer.parseInt(contentLength.trim(), 16);
			} catch (NumberFormatException ex){
				//This server does not send the content-length in the first
				//line of the response body
			}
			System.out.println(contentLength);

			int c;
			int i = 0;
			while ((c = in.read()) != -1 && i++ < length){
				System.out.write(c);
			}

			System.out.println();
		} catch (IOException ex){
			System.err.println(ex);
		} finally {
			try{
				if (socket != null) socket.close();
			} catch (IOException ex) {}
		}
	}
}

Note: If we run into the exception "No trusted certification found", update to the
latest minor version of JDK.

Serving stuff over HTTPs takes time, only run it on sensitive data.

Choosing the Cipher Suites:

Different implementations of the JSSE support different combinations of authentication
and encryption algos. Oracle bundles Java 7 with 128-bit AES encryption. There
is a way to get 256-bit AES, but that requires legal agreements and installation of 
JCE Unlimited Strength Jurisdiction Policy Files.

There is the allowed ones(Strong enough), and the possible ones(Too weak, but they exist):
These methods apply to the SSLSocketFactory class

public abstract String[] getSupportedCipherSuites() //Return all possible ones

public abstract String[] getEnabledCipherSuites() //return all supported ones

The suite agreement is resolved at connection time. If no-one is agreed upon, cause
both parts dont have the certificates or are enabled etc., then an exception is thrown.

public abstract void setEnabledCipherSuites(String[] suites)

The ones we can set, is a list as follows:

TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256

//THe list is actually really long, won't write it

Each name has an algo divided into 4 parts: protocol, key exchange algorithm, encryption algo,
checksum.

JDK supports the first 28 of the list. Don't use the ones with NULL, ANON, or EXPORT.

Generally, go for TLS_ECDHE/SHA256 or SHA384

Depenending on protocol, different algos work for different things. Since DES and AES,
encrypt in blocks of variying sizes and pad, they work for HTTPS and FTP.

However, RC4 works better for telnet and chat, because chat and telnet must send each byte
seperately.

An example of enabling suites:

String[] strongSuites = {"TLS_ECHDE_ECDSA_WITH_AES_128_CBC_SHA256"};
socket.setEnableCipherSuites(strongSuites);

Event Handlers:

To get notified of completion of handsaking, implement the interface and 
the method:

public interface HandshakeCompletedListener extends java.util.EventListener

it defines the method:

public void handshakeCompleted(HandshakeCompletedEvent event)

it recieves a object of the:

public class HandshakeCompletedEvent extends java.util.EventObject

The handshake class defines a few methods:

public SSLSession getSession()

public String getCipherSuite()

public X509Certificate[] getPeerCertificateChain() throws SLLPeerUnverifiedfieldException

public SSLSocket getSocket()

The handshakeCompletedListner register with the add and remove methods of their respective kind:

public abstract void addHandshakeCompletedListener(
	HandshakeCompletedListener listener)

public abstract void removeHandshakeCompletedListener(
	HandshakeCompletedListener listener) throws IllegalArgumentException

Session Management:

Since SSL includes overhead, there is a session system, where chunks of 
sockets use the same keys.

In JSSE, we need not care about that, it does so automatically if the sockets
are made within a short amount of time.

However, we can see things about the SSL Sessions through the SSLSession interface:

public byte[] getId()

public SSLSessionContext getSessionContext()

public long getCreationTime()

public long getLastAccessedTime()

public void invalidate()

public void putValue(String name, Object value)

public Object getValue(String name)

public void removeValue(String name)

public String[] getValueNames()

public X509Certificate[] getPeerCeritificateChain() throws SSLPeerUnverifiedException

public String getCipherSuite()

public String getPeerHost()

There are a few more as well:

public abstract SSLSession getSession()

//Sessions are performancewise better, but worse security wise. Evaluate on basis.

public abstract void setEnableSessionCreation(boolean allowSessions) 

//define if they are allowed to be made or not

public abstract boolean getEnableSessionCreation()

//Get if they are on or not

To reuthenticate a connection (Starts over a new fresh session):

public abstract void startHandshake() throws IOException

Client Mode:

We can force sockets to authenticate themselves:

public abstract void setUseClientMode(boolean mode) throws IllegalArgumentException

//if true, will not authenticate itself. Otherwise, it will. This attribute can only be set once.

public abstract boolean getUseClientMode() 

//if authentication is activated on the first handshake

We can set if we wish Sockets to authenticate users or not:

public abstract void setNeedClientAuth(boolean needsAuthentication) throws IllegalArgumentException

NOTE: The Socket must be on the server side.

public abstract void getNeedClientAuth()

Creating Secure Server Sockets:

Of course, to secure Client sockets, there must also be secure server sockets.

public abstract class SSLServerSocket extends ServerSocket

Creation occurs through the factory by the getDefault() method:

public abstract class SSLServerSocketFactory extends ServerSocketFactory

//Getter

public static ServerSocketFactory getDefault()

Akin to the constructors as before:

public abstract ServerSocket createServerSocket(int port) throws IOException

public abstract ServerSocket createServerSocket(int port, int queueLength) throws IOException

public abstract ServerSocket createServerSocket(int port, int queueLength, InetAddress interface)
	throws IOException

THe problem is, the default getter only allows for authentication, not encryption.

To achieve encryption, you have to follow these steps:

Generate public keys and certificates using keytool

pay money to have your certificates authenticated by a trusted third party such as
Comodo

Create an SSLContext for the algorithm you'll use

Create a TrustManagerFactory for the source of certification material you'll be using

Create a KeyManagerFactory for the type of key material you'll be using

Create a KeyStore object for the key and certificate database. (Oracle's default
is JKS)

Fill the KeyStore object with keys and certificates, for instance, by loading 
them from the filesystem using the passphrase they're encrypted with.

Initialize the KeyManager Factory with the KeyStore and its passphrase.

Initialize the context with the necessary key managers from the KeyManagerFactory,
trust managers from the TrustManagerFactory and a source of randomness. 
(Last two are null, if you are willing to accept defaults)

The following example showcases acceptal of orders and printing them out.

//Imports

public class SecureOrderTaker{
	public final static int PORT = 7000;
	public final static String algorithm = "SSL";

	public static void main(String[] args){
		try{
			SSLContext context = SSLContext.getInstance(algorithm);

			//The reference implementation only supports X.509 keys
			KeyManagerFactory kmf = KeyManagerFactory.getInstance("SunX509");

			//Oracle's default kind of key store
			KeyStore ks = KeyStore.getInstance("JKS");

			//For security, every key is encrypted with as passphrase.
			//which must be provided before we can load it
			//it is stored as a char[] array to allow wiping from
			//memory qucikly rather than garbage collection

			char[] password = System.console().readPassword();

			ks.load(new FileInputStream("jnp4e.keys"), password);

			kmf.init(ks, password);
			context.init(kmf.getKeyManagers(), null, null);

			//Wipe it
			Arrays.fill(password, '0');

			SSLServerSocketFactory facotry = context.getServerSocketFactory();

			SSLServerSocket server = (SSLServerSocket) factory.createServerSocket(PORT);

			//add anonymous (non authenticated ) cipher suites
			String[] supported = server.getSupportedCipherSuites();
			String[] anonCipherSuitesSupported = new String[supported.length];

			int numAnonCipherSuitesSupported = 0;
			for (int i = 0; i < supported.length; i++){
				if (supported[i].indexOf("_anon_") > 0){
					anonCipherSuitesSupported[numAnonCipherSuitesSupported++] = supported[i];
				}
			}

			String[] oldEnabled = server.getEnabledCipherSuites();
			String[] newEnabled = new String[oldEnabled.length + numAnonCipherSuitesSupported];

			System.arraycopy(oldEnabled, 0, newEnabled, 0, oldEnabled.length);
			System.arraycopy(anonCipherSuitesSupported, 0, newEnabled, oldEnabled.length,
				numAnonCipherSuitesSupported);

			server.setEnabledCipherSuites(newEnabled);

			//Setup complete, preparing interaction

			while (true){
				//The socket is secure cause of the setup
				try(Socket theConnection = server.accept()){
					InputStream in = theConnection.getInputStream();
					int c;
					while ((c = in.read()) != -1){
						System.out.write(c);
					}
				} catch (IOException ex){
					ex.printStackTrace();
				}
			}
		} catch (IOException | KeyManagementException | KeyStoreException | NoSuchAlgorithmException
			| CertificateException | UnrecoverableKeyExcetpion ex){
			ex.printStackTrace();
		}
	}
}

The next part, was built with the keytool program that comes with JDK.

It loads the nessecary keys and certificates from a file named jnp4e.keys in 
the cwd protected with a pw.

Example of interaction:

$ keytool -genkey -alias ourstore -keystore jnp4e.keys
//Enter KeySTore PW
//Questions
//Confirmation
//Enter key password

We can use non-auth cipher suites, but they are vurnable to middle in the man attacks.

Configuring SSLServerSockets:

Choosing the Cipher Suites:

we have three methods for choosing suites for SSLServerSockets:

public abstract String[] getSupportedCipherSuites()

public abstract String[] getEnabledCipherSuites()

public abstract void setEnabledCipherSuites(String[] suites)

These apply to all SSLSockets.

The following example takes the old list of Ciphers and mashes it together with anon ones:

String[] supported = server.getSupportedCipherSuites();
String[] anonCipherSuitesSupported = new String[supported.length];
int numAnonCipherSuitesSupported = new String[supported.length];

for (int i = 0; i < supported.length; i++){
	if (supported[i].indexOf("_anon_") > 0){
		anonCipherSuitesSupported[numAnonCipherSuitesSupported++] = supported[i];
	}
}

String[] oldEnabled = server.getEnabledCipherSuites();
String[] newEnabled = new String[oldEnabled.length + numAnonCipherSuitesSupported];

System.arraycopy(oldEnabled, 0, newEnabled, 0, oldEnabled.length);
System.arraycopy(anonCipherSuitesSupported, 0, newEnabled, oldEnabled.length,
	numAnonCipherSuitesSupported);

server.setEnabledCipherSuites(newEnabled);

Session Management:

Both client nad server must agree to sessions.

If one does not want for it, they default to the lower level of respective side.

public abstract void setEnableSessionCreation(boolean allowSessions)

public abstract boolean getEnableSessionCreation()

Client Mode:

All of these apply to SSLServerSocket, still.

We can force clients to Authenticat tehsemvles to the server:

public abstract void setNeedClientAuth(boolean flag);

public abstract boolean getNeedClientAuth()

We can also set the ServerSocket to be in Client mode:

public abstract void setUseClientMode(boolean flag)

public abstract boolean getUseClientMode()

Nonblocking I/O:

Spawning new threads can cost up against 1 MB of Ram per thread.
This can be nontrivial in a extreme system of thousands of connections
and processing of data.

It'd be smarter to use a Thread to handle many connections. This leads to 
nonblocking IO. It needs to be supported by the OS. Is not supported on cellphones
and what not, except for Android.

MultiThreaded asynch almost always outperforms NIO. Except, for the situation of 
10.000+ active connections that are kept alive and rarely send data.

ONly when we have proof that we need to do it, should we do it.

A problem with some protocols is that they can be grounds for a Pingpong attack,
packages faking to be something else and causing infinite data production and saturating
the network.

An Example Client:

To begin with the NIO:

SocketAddress rama = new InetSocketAddress("rama.poly.edu", 19);
SocketChannel client = SocketChannel.open(rama);

It opens in blocking mode, meaning it must establish the connection first.

Instead of input and outputstreams, we write ByteBuffers, designated after
the protocols length (76 in this care, 74 ascii, 2 for \r\n)

ByteBuffer buffer = ByteByffer.allocate(74);

Pass it to the client and it returns how many it successfully read:

int bytesRead = client.read(buffer);

To then put the data into system out, we have to spawn a channel:

WriteableByteChannel output = Channels.newChannel(System.out);

//Then flip the buffer, to get it in the right order

buffer.flip();
output.write(buffer);

buffer.clear(); //Reuse the buffer, allowing new data to overwrite hte old

Not all channels are guaranteed to write all the bytes. This one will. It is a blocking one.
It will do so, or throw an Exception if it cannot.

The following is an example of a channel-based chargen client (74 bit length protocol), endless iterative structure, kill with CTRL+C:

//imports

public class ChargenClient{
	public static int DEFAULT_PORT = 19;

	public static void main(String[] args){
		if (args.length == 0){
			System.out.println("Usage: java chargenclient host [port]");
			return;
		}

		int port;
		try{
			port = Integer.parseInt(args[1]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}

		try{
			SocketAddress address = new InetSocketAddress(args[0], port);
			SocketChannel client = SocketChannel.open(address);

			ByteBuffer buffer = ByteBuffer.allocate(74);

			WriteableByteChannel out = Channels.newChannel(System.out);

			while(client.read(buffer) != -1){
				buffer.flip();
				out.write(buffer);
				buffer.clear();
			}
		} catch (IOException ex){
			ex.printStackTrace();
		}
	}
}

So far, it is the same. However, we can make it nonblocking, meaning we can do
something before we have data, if we wish:

client.configureBlocking(false); //Is called on the Server Socket channel

read() may return 0 in nonblocking, cause there is nothing to read.

The loop is a bit different, thus:

while (true){
	//Put whatever code ou want to run here, regardless anything is read orn ot
	int n = client.read(buffer);
	if (n > 0){
		buffer.flip();
		out.write(buffer);
		buffer.clear();
	} else if (n == -1){
		//SHould not happen unless server is misbehaving
		break;
	}
}

NIO simply allows each connection to run at it's own speed.

An Example Server:

The third, and new part for Servers, is Selectors. We have channels and buffers,
but we need selectors to find connectiosn who are ready to recieve output or send input.

As per normal:

ServerSocketChannel serverChannel = ServerSocketChannel.open();

serverChannel.bind(new InetSocketAddress(19));

On Unix, you gotta be root for < 1024 Port connections.

//Accept the channel connections and configure non-blocking

SocketChannel clientChannel = serverChannel.accept();

clientChannel.configureBlocking(false);

Normally, the serverChannel blocks until a connection comes.
We an unblock it, however:

serverChannel.configureBlocking(false);

A nonblocking accept() returns null almost immedeatly, if there are no
incoming connections. Prepare for this.

We then open a selector:

Selector selector = Selector.open(); //In the Asynch IO way, we delegate to threads, but here we delegate to selectors

We can listen to specific operations in terms of Selectors. Serverwise, we are only interested
in Server readiness to recieve connections:

serverChannel.register(selector, SelectionKey.OP_ACCEPT);

Clients need to have alertion of when data is to be written to them:

SelectionKey key = clientChannel.register(selector, SelectionKey.OP_WRITE);

register() returns a SelectionKey object. We are only going to use
them  for client channels, because there can be more than one of em.

We then construct a rotating byte array to sequentially write to buffers.

byte[] rotation = new byte[95*2];
for(byte i = ' '; i <= '~'; i++){
	rotation[i - ' '] = i;
	rotation[i + 95 - ' '] = i;
}

Since we are operating on a 74 bit protocol, we take the 72 first bits
and put them in:

ByteBuffer buffer = ByteBuffer.allocate(74);
buffer.put(rotation, 0, 72);
buffer.put((byte) '\r');
buffer.put((byte) '\n');
buffer.flip();
key2.attach(buffer);

To find all the ready keys, we run selectedKeys(), store them in a set of Selectionkeys,
iterate over them , see taht they have a next value and process them:

Set<SelectionKey> readyKeys = selector.selectedKeys();
Iterator iterator = readyKeys.iterator();

while (iterator.hasNext()){
	SelectionKey key = iterator.next();
	//Remove key from set so we dontp rocess it twice
	iterator.remove();
	//operate on the channel
}

If it is a SocketChannel, it writes as much data as it ccan unto the channel.

If it is a server channel, it adds a new socket channel to the selector by accepting it.

Since it's I/O, they can throw IOException, put them in a try:

try{
	if (key.isAcceptable()){
		ServerSocketChannel server = (ServerSocketChannel) key.channel();
		SocketChannel connection = server.accept();
		connection.configureBlocking(false);

		connection.register(selector, SelectionKey.OP_WRITE);
		//Set up the buffer for the client
	} else if (key.isWritable()){
		SocketChannel client = (SocketChannel) key.channel();
		//Write data to the client
	}
}

In our case, its simple, because server writes, client reads. It is not always
like this, tho.

To read data to the channel, do as follows:

ByteBuffer buffer = (ByteBuffer) key.attachment();
if (!buffer.hasRemaining()){ //bufferi s empty
	//refill the buffer with the next line
	//Figure out where the last line started
	buffer.rewind(); 

	int first = buffer.get(); //Get the first byte of the buffer
	//Increment to the next char
	buffer.rewind();
	int position = first - ' ' + 1; //We use 32 bits, space char, to assign the position in the rotation array
	//thus we calculate for it and rotate the buffer to process it. Here we take the next line nad start there

	buffer.put(rotation, position, 72);
	buffer.put((byte) '\r');
	buffer.put((byte) '\n');
	buffer.flip();
}
client.write(buffer);

When a Chargen protocol is closed, it throws an exception. cancel the key, close the channel:

catch (IOException ex){
	key.cancel();
	try{
		key.channel().close();
	} catch (IOException ex){
		//ignore
	}
}

The following example, puts it all otgether and makes a chargen sever that 
processes multiple connections in a single thread:

//imports

public class ChargenServer{
	public static int DEFAULT_PORT = 19;

	public static void main(String[] args){
		int port;
		try{
			port = Integer.parseInt(args[0]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}

		System.out.println("Listening for connections on port " + port);

		byte[] rotation = new byte[95*2];
		for (byte i = ' ';i <= '~'; i++){
			rotation[i - ' '] = i;
			rotation[i + 95 - ' '] = i;
		}

		ServerSocketChannel serverChannel;
		Selector selector;
		try{
			serverChannel = ServerSocketChannel.open();
			ServerSocket ss = serverChannel.socket();

			InetSocketAddress address = new InetSocketAddress(port);
			ss.bind(address);
			serverChannel.configureBlocking(false);

			selector = Selector.open();
			serverChannel.register(selector, SelectionKey.OP_ACCEPT);
		} catch (IOException ex){
			ex.printStackTrace();
			return;
		}

		while (true){	
			try{
				selector.select();
			} catch (IOException ex){
				ex.printStackTrace();
				break;
			}

			Set<SelectionKey> readyKeys = selector.selectedKeys();
			Iterator<SelectionKey> iterator = readyKeys.iterator();

			while(iterator.hasNext()){
				SelectionKey key = iterator.next();
				iterator.remove();
				try{
					if (key.isAcceptable()){
						ServerSocketChannel server = (ServerSocketChannel) key.channel();
						SocketChannel client = server.accept();
						System.out.println("Accepted connection from " + client);

						client.configureBlocking(false);
						SelectionKey key2 = client.register(selector, SelectionKey.OP_WRITE);

						ByteBuffer buffer = ByteBuffer.allocate(74);
						buffer.put(rotation, 0, 72);
						buffer.put((byte) '\r');
						buffer.put((byte) '\n');
						buffer.flip();
						key2.attach(buffer);
					} else if (key.isWritable()){
						SocketChannel client = (SocketChannel) key.channel();
						ByteBuffer buffer = (ByteBuffer) key.attachment();
						if(!buffer.hasRemaining()){
							//Refill buffer with net line
							buffer.rewind();
							//Get old first char
							int first = buffer.get();

							//Get ready to change the data in the buffer
							buffer.rewind();
							//find the new first chars position in rotation
							int position = first - ' ' + 1;

							//Copy the data from rotation into teh buffer
							buffer.put(rotation, position, 72);

							//Store a line break at end of buffer
							buffer.put((byte) '\r');
							buffer.put((byte) '\n');

							buffer.flip();
						}
						client.write(buffer);
					}
				} catch (IOException ex){
					key.cancel();
					try{
						key.channel().close();
					} catch (IOException cex){}
				}
			}
		}
	}
}

We could delegate to different threads with different responsibilities.
Don't do that unless there is a proven need.

Buffers:

The NIO model auotmatically builds on buffers.

The difference between streams and channels, is that streams are byte-based,
channels are block based.

The second difference between streams and channels/buffers is that channels
and buffers tend to support both reading and writing on the same object.

It is not always true, however.

There are other buffers, but networks always exclusively use ByteBuffers.

Each buffer tracks four pieces of info:

position : public final int position() (get) or public final Buffer position(int newPosition) (set)

capacity : capacity, is set upon creation. can be read with : public final int capacity()

limit: The end of accessible data in the buffer. cannot read or write past this point
without changing the limit, even if capacity has more.	

public final int limit() //get

public final Buffer limit(int newLimit) //set

mark: Go back to a marked point with reset(). mark is discareded if poisiton is < mark.

public final Buffer mark() //sets mark at current pos

public final Buffer reset() //current pos becomes marked pos

Reading from a buffer does not change the data there within, unlike InputStreams.

public final Buffer clear() //clears the buffer, old data is still present tho, can be gotten
by absolute getters

public final Buffer rewind() //Sets pos to 0 but does not change limit

public final Buffer flip() //Sets limit to current pos, and pos to zero, use before draining buffer you just filled

public final int remaining() //Difference between cur pos and limit

public final boolean hasRemaining() //true if remaining elements > 0

Creating Buffers:

Allocate creates empty buffers, wrap methods create data filled byte bufers.
Empty buffers for input, wrappers for output.

Allocation: 

examples:

ByteBuffer buffer1 = ByteBuffer.allocate(100);
IntBuffer buffer2 = IntBuffer.allocate(100);

The general pattern is to retrieve data from buffer, convert it to an array, and then process it.
DO NOT read and then write and then process. Controlled flow.

Changes in the array is reflected in the Buffer.

byte[] data1 = buffer1.array();

int[] data2 = buffer2.array();

We can also do direct allocation from memory or another source, but it's performance is heavily
variying:

ByteBuffer buffer = ByteBuffer.allocateDirect(100);

Wrapping:

If you already have an array of data, you can wrap it:

byte[] data = "Some data".getBytes("UTF-8");
ByteBuffer buffer1 = ByteBuffer.wrap(data);

char[] text = "Some Text".toCharArray();
CharBuffer buffer2 = CharBuffer.wrap(text);

Again, these arrays are references to the same underlying
structure, meaning changes are reflected in the buffer.

Filling and Draining:

buffers operate on sequential operation, and have a position() attribute.

An example:

CharBuffer buffer = CharBuffer.allocate(12);
buffer.put("h");
buffer.put("e");
//Etc.

buffer.flip()

String result = "";
while (buffer.hasRemaining()){
	result += buffer.get();
}

get moves the position forward by 1 and retrieves the info 

We also have put and get (Absolute Getters and Putters):

public abstract byte get(int index)

public abstract ByteBuffer put(int index, byte b)

When you use put, you don't have to flip them, as putting does not change the position.
Order matters not either, as its index based.

Bulk Methods:

There are bulk versions for operating with the data, as is usually better
performancewise:

public ByteBuffer get(byte[] dst, int offset, int length)

public ByteBuffer get(byte[] dst)

public ByteBuffer put(byte[] array, int offset, int length)

public ByteBuffer put(byte[] array)

Note: You need to have sufficient data both in terms of getting and putting, otherwise
you get Overflow and underflow exception

Data Conversion:

Using a empty get call accesses current position

WE have 4 forms of methods for each type:

public abstract char getChar()

public abstract ByteBuffer putChar(char value)

public abstract char getChar(int index)

public abstract ByteBuffer putChar(int index, char value)

The big difference, is that we can choose to interpet things as small endian or big endian,
 as follows:

if (buffer.order().equals(ByteOrder.BIG_ENDIAN)){
	buffer.order(ByteOrder.LITTLE_ENDIAN);
}

By default, data is written and read as BIG_ENDIAN, with the most significant
byte first.

What follows, is an example of a server that sends Integers in byte formats, and 
closes when you shut it down. Eventually, it will wrap into negative numbers.

//imports

public class IntgenServer{
	public static int DEFAULT_PORT = 1919;

	public static void main(String[] args){
		int port;

		try{
			port = Integer.parseInt(args[0]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}

		System.out.println("Listening for connections on port " + port);

		ServerSocketChannel serverChannel;
		Selector selector;
		try{
			serverChannel = serverSocketChannel.open();
			ServerSocket ss = serverChannel.socket();
			InetSocketAddress address = new InetSocketAddress(port);

			ss.bind(address);
			serverChannel.configureBlocking(false);
			selector = Selector.open();
			serverChannel.register(selector, SelectionKey.OP_ACCEPT);
		} catch (IOException ex){
			ex.printStackTrace();
			return;
		}

		while (true){
			try{
				selector.select();
			} catch (IOException ex){
				ex.printStackTrace();
				break;
			}

			Set<SelectionKey> readyKeys = selector.selectedKeys();
			Iterator<SelectionKey> iterator = readyKeys.iterator();

			while (iterator.hasNext()){
				SelectionKey key = iterator.next();
				iterator.remove();

				try{
					if (key.isAcceptable()){ //Beginning value
						ServerSocketChannel server = (ServerSocketChannel) key.channel();
						SocketChannel client = server.accept();

						System.out.println("Accepted connection from " + client);
						client.configureBlocking(false);
						SelectionKey key2 = client.register(selector, SelectionKey.OP_WRITE);

						ByteBuffer output = ByteBuffer.allocate(4);
						output.putInt(0);
						output.flip();
						key2.attach(output);
					} else if (key.isWritable()){
						SocketChannel client = (SocketChannel) key.channel();
						ByteBuffer output = (ByteBuffer) key.attachment();

						if (!output.hasRemaining()){
							output.rewind();
							int value = output.getInt(); //Get the old value
							output.clear(); //clear it
							output.putInt(value + 1); //increment by one
							output.flip(); //Flip to have the right side up
						}
					client.write(output); //Write it out
					}
				} catch (IOException ex){
					key.cancel();
					try{
						key.channel().close();
					}
					catch (IOException cex) {}
				}
			}
		}
	}
}

View Buffers: 

If we know a buffer contains all of one data type, we can define a view Buffer for it,
which has a different capacity limit etc. That draws data from the underlying ByteBuffer.

public abstract ShortBuffer asShortBuffer()
//Etc for each type

An example, where the server is synch, blocking and use a IntBuffer.
WARNING: Non-blocking does not guarantee that the Buffer is of a certain kind.

//imports

public class IntgenClient{
	public static int DEFAULT_PORT = 1919;

	public static void main(String[] args){
		if (args.Length == 0){
			System.out.println("Usage: java Intgenclient host [port]");
			return;
		}

		int port;
		try{
			port = Integer.parseInt(args[1]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}

		try{
			SocketAddress address = new InetSocketAddress(args[0], port);
			SocketChannel client = SocketChannel.open(address);

			ByteBuffer buffer = ByteBuffer.allocate(4);
			IntBuffer view = buffer.asIntBuffer();

			for (int expected = 0 ; expected++ ){
				client.read(buffer);
				int actual = view.get();
				buffer.clear();
				view.rewind();

				if (actual != expected){
					System.err.println("Expected: " + expected + "; was " + actual);
					break;
				}
				System.out.println(actual);
			}
		} catch(IOException ex){
			ex.printStackTrace();
		}
	}
}

Note: It can still only read from ByteBuffers, and we must clear out the byte Buffer and operate
on that one, as the View only acts as a "dependant" upon the original ByteBuffer.

Compacting Buffers:

Compacting basically means when you "compact", the data, you press them down to
shove remaining data to the start and the position gets put ot hte end of the data.

Good for copying or situations where the server needs to read and write.

What follows, is an example of a echo server, that can read and write,
where we use Compacting to use the times of where immedeat output is not met with immedeat input
or vice versa:

//imports

public class EchoServer{
	public static int DEFAULT_PORT = 7;

	public static void main(String[] args){
		int port;

		try{
			port = Integer.parseInt(args[0]);
		} catch (RuntimeException ex){
			port = DEFAULT_PORT;
		}

		System.out.println("listening to connections on port " + port);

		ServerSocketChannel serverChannel;
		Selector selector;
		try{
			serverChannel = ServerSocketChannel.open(); //open a server Socket channel
			ServerSocket ss = serverChannel.socket(); //get the socket

			InetSocketAddress address = new InetSocketAddress(port); //run the address on the port
			ss.bind(address); //bind it to the server socket

			serverChannel.configureBlocking(false); //make it nonblocking
			selector = Selector.open(); //open a selector
			serverChannel.register(selector, SelectionKey.OP_ACCEPT); //Register the selector to the serverChannel
			//That we want to be able to accept requests
		} catch (IOException ex){
			ex.printStackTrace();
			return;
		}

		while (true) {
			try{
				selector.select(); //Select a operation, be that write or read
			} catch (IOException ex){
				ex.printStackTrace();
				break;
			}

			Set<SelectionKey> readyKeys = selector.selectedKeys(); //The keys that are ready
			Iterator<SelectionKey> iterator = readyKeys.iterator(); //iterate over them

			while (iterator.hasNext()){ //While the iteration set has more elements
				SelectionKey key = iterator.next(); //Pick the next key
				iterator.remove(); //remove the item to avoid repetition
				try{
					if (key.isAcceptable()){ //if it is the first time value
						ServerSocketChannel server = (ServerSocketChannel) key.channel(); //get the channel from the key
						SocketChannel client = server.accept(); //Accept the request

						System.out.println("Accepted connection from " + client); //Accepted the connection
						client.configureBlocking(false); //Non-bocking

						SelectionKey clientKey = client.register( //Read or Write to client
							selector, SelectionKey.OP_WRITE | SelectionKey.OP_READ);

						ByteBuffer buffer = ByteBuffer.allocation(100); //The buffer
						clientKey.attach(buffer); //Attach the buffer to the key
					}
					if (key.isReadable()){ //Already has a value and is reading value
						SocketChannel client = (SocketChannel) key.channel(); //get the channel
						ByteBuffer output = (ByteBuffer) key.attachment(); //Aquire a ByteBuffer
						client.read(output); //Read the output
					}

					if (key.isWritable()){ //Has a value and is writing
						SocketChannel client = (SocketChannel) key.channel(); //get hte channel
						ByteBuffer output = (ByteBuffer) key.attachment(); //run a ByteBuffer on the output
						output.flip(); //Flip it
						client.write(output); //write the output
						output.compact(); //Compact it to save space for upcoming things
					}
				} catch (IOException ex){
					key.cancel(); //Server is being terminated, cancel the key
					try{
						key.channel().close(); //close the channel if iti s up
					} catch (IOException cex) {}
				}
			}
		}
	}
}

If a Buffer is too big, it can obscure bugs such as testing when flipping and draining.
(The whole testcase goes in, never triggers flips and drains etc.)

Duplicating Buffers:

public abstract ByteBuffer duplicate() //There are all the different typings for these

Mostly this should be used for reading, as they still act as per "linked" buffers.

They have independant markings, limist and positions tho.

The following example showcases duplication to enable simutalenous buffer usage
to different connections at different speeds:

//imports

public class NonblockingSingleFileHTTPServer{
	private ByteBuffer contentBuffer;
	private int port = 80;

	public NonblockingSingleFileHTTPServer(
		ByteBuffer data, String encoding, String MIMEType, int port){

		this.port = port;
		String header = "HTTP/1.0 200 OK\r\n"
			+ "Server: NonblockingSingleFileHTTPServer\r\n"
			+ "Content-length: " + data.limit() + "\r\n"
			+ "Content-type: " + MIMEType + "\r\n\r\n";

		byte[] headerData = header.getBytes(Charset.forName("US_ASCII"));

		ByteBuffer buffer = ByteBuffer.allocate(data.limit() + headerData.length);

		buffer.put(headerData);
		buffer.put(data);
		buffer.flip();

		this.contentBuffer = buffer;
	}

	public void run() throws IOException{
		ServerSocketChannel serverChannel = ServerSocketChannel.open();
		ServerSocket serverSocket = serverChannel.socket();

		Selector selector = Selector.open();
		InetSocketAddress localPort = new InetSocketAddress(port);

		serverSocket.bind(localPort);
		serverChannel.configureBlocking(false);

		serverChannel.register(selector, SelectionKey.OP_ACCEPT);

		while (true){
			selector.select();
			Iterator<SelectionKey> keys = selector.selectedKeys().iterator();

			while (keys.hasNext()){
				SelectionKey key = keys.next();
				keys.remove();
				try{
					if (key.isAcceptable()){
						ServerSocketChannel server = (ServerSocketChannel) key.channel();
						SocketChannel channel = server.accept();
						channel.configureBlocking(false);
						channel.register(selector, SelectionKey.OP_READ);
					} else if (key.isWritable()){
						SocketChannel channel = (SocketChannel) key.channel();
						ByteBuffer buffer = (ByteBuffer) key.attachment();
						if (buffer.hasRemaining()){
							channel.write(buffer);
						} else { //We are done
							channel.close();
						}
					} else if (key.isReadable()){ //The next time we come here, we do a write operation instead
						//Waste to read the HTTP header

						SocketChannel channel = (SocketChannel) key.channel();
						ByteBuffer buffer = ByteBuffer.allocate(4096);

						channel.read(buffer);

						//Switch to write only mode
						key.interestOps(SelectionKey.OP_WRITE);
						key.attach(contentBuffer.duplicate());
					}
				} catch (IOException ex){
					key.cancel();
					try{
						key.channel().close();
					}
					catch (IOException ex){}
				}
			}
		}
	}

	public static void main(String[]args){
		if (args.length == 0){
			System.out.println("Usage: java NonblockingSingleFileHTTPServer file port encoding");
			return;
		}

		try{
			//Read the file to serve
			String contentType = URLConnection.getFileNameMap().getContentTypeFor(args[0]);

			Path file = FileSystems.getDefault().getPath(args[0]);

			byte[] data = Files.readAllBytes(file);

			ByteBuffer input = ByteBuffer.wrap(data);

			//Set the port to listen to
			int port;
			try{
				port = Integer.parseInt(args[1]);
				if (port < 1 || port > 65535) port = 80;
			} catch (RuntimeException ex) {
				port = 80;
			}

			String encoding = "UTF-8";
			if (args.length > 2) encoding = args[2];

			NonblockingSingleFileHTTPServer server = new NonblockingSingleFileHTTPServer(input, encoding,
				contentType, port);

			server.run();
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

As long as the Buffers share the same underlying data, the overhead is neglectable.

Slicing Buffers:

Slicing is as per we have seen before, where we duplicate based on a certain slicing.

They follow the usual pattern of slicing different return types:

public abstract ByteBuffer slice()

public abstract IntBuffer slice()

public abstract ShortBuffer slice()

//etc

Marking and Resetting:

just the mark and reset function. Works on all buffers.

Object Methods:

Buffers are not serializable or Cloneable.

Two buffers are considered equal if the following requisites are true:

Same type 

Same number of elements remaining in the buffer

Remaining elements at the same relative positions are equal
to each other

Equality does not consider the preceeding positions, the buffers capacity,
limits or marks. 

Since elements are added and subtracted from the Buffers, they do not make
for good HashMaps.

If a shorter buffer runs out of elements before a longer one, upon comparing,
the shorter is considered less.

The toString() is good for these, cause the following:

java.nio.HeapByteBuffer[pos=0 lim=62 cap=62]

Channels:

There are tons of channels, and they provide us ways of moving data.
However, in Networking, there is really only three:

SocketChannel, ServerSocketChannel and DatagramChannels.
Albeit in TCP, we only use the first two.

SocketChannel:

SocketChannels write to and from TCP sockets. The data must be encoded
in ByteBuffer objects for reading and writing.

Each SocketChannel is associated with a peer Socket object that cna be 
used for advanced config.

Connecting:

To connect, we just run with one of the two constructors:

public static SocketChannel open(SocketAddress remote) throws IOException

public static SocketChannel open() throws IOException

As per expected, connections block until they connect

//First variant

SocketAddress address = new InetSocketAddress("www.cafeaulait.org", 80);
SocketChannel channel = SocketChannel.open(address);

//Second version, not instantly connecting

SocketChannel channel = SocketChannel.open();
SocketAddress address = new InetSocketAddress("www.cafeaulait.org", 80);
channel.connect(address);

//Nonblocking version

SocketChannel channel = SocketChannel.open();
SocketAddress address = new InetSocketAddress("www.cafeaulait.org", 80);
channel.configureBlocking(false);
channel.connect();

In nonblocking, this executes immedeatly.

To prevent it, we could conditionalize with finishConnect():

public abstract boolean finishConnect() throws IOException //If ready, true, otherwise, false, if network down,
//Exception

To see if the connection is open or opening:

public abstract boolean isConnected() //True if open

public abstract boolean isConnectionPending() //True if pending

Reading:

To read from a SocketChannel, make a ByteBuffer, fill it:

public abstract int read(ByteBuffer dst) throws IOException //Blocking tries to always deliver 1 at least,
//-1 if EOF. if Nonblocking, may return 0.

To read until buffer is full or EOF:

while (buffer.hasRemaining() && channel.read(buffer) != -1);

We can fill several buffers from one source. It is a scatter, either with full out, or X
amount at index Y:

public final long read(ByteBuffer[] dsts) throws IOException

public final long read(ByteBuffer[] dsts, int offset, int length) throws IOException

To scatter:

ByteBuffer[] buffers = new ByteBuffer[2];
buffers[0] = ByteBuffer.allocate(1000);
buffers[1] = ByteBuffer.allocate(1000);

while (buffers[1].hasRemaining() && channel.read(buffers) != -1); //While it can still read from buffers
//And the latest buffer has data left

Since sequential reading is a thing, we only need pay mind to the latest buffer

writing:

Writing is the opposite of reading. THe sockets are duplex, so they can support read/write.
To write, fill a ByteBuffer, flip it and pass it a write.

public abstract int write(ByteBuffer src) throws IOException

This method is guaranteed to write all the data in one go, if the channel is nonblocking.
However, we can just keep writing until its empty:

while (buffer.hasRemanining() && channel.write(buffer) != 1);

we can read from several buffers into one socket. it is called a Gather.
we could do this with multithreading or overlapping NIO.

The writes are teh same as the reads:

public final long write(ByteBuffer[] dsts) throws IOException

public final long write(ByteBuffer[] dsts, int offset, int length) throws IOException

Closing:

We have auto-close with try-with-resources. But we can manually call close as well:

public void close() throws IOException

To see if something is open:

public boolean isOpen()

ServerSocketChannel:

Their only function is to accept incoming connections. They also have related methods
of Selectors and what not.

Creating server Socket channels:

We create the socket with open(), create an address and assign it:

try{
	ServerSocketChannel server = ServerSocketChannel.open();
	SocketAddress address = new InetSocketAddress(80);
	server.bind(address);
} catch(IOException ex){
	System.err.println("Could not bind to port 80 because " + ex.getMessage());
}

We use teh factory to allow modification closer ot the OS and VM. Note: THe Factory method
is not configurable.

Accepting connections:

To accept a connection, just run accept():

public abstract SocketChannel accept() throws IOException

Can run it in either blocking or nonblocking. Blocking blocks thread until accepting.
Nonblocking does not. Nonblocking cna be used for parallelisation of thread manipulation.

Blocking mode is default.

To change to NIO, configureBlocking(false)

NIO is usually used with selectors.

Accept can throw expected exceptions in terms of Thread handling and connections.

The Channel Class:

Wraps I/O based streams, readers and writers. 

Can convert between types:

public static InputStream newInputStream(ReadableByteChannel ch)

public static OutputStream newOutputStream(WritableByteChannel ch)

public static ReadableByteChannel newChannel(InputStream in)

public static WritableByteChannel newChannel(OutputStream out)

public static Reader newReader(ReadableByteChannel channel, CharsetDecoder decoder,
	int minimumBufferCapacity)

public static Reader newReader(ReadableByteChannel ch, String encoding)

public static Writer newWriter(WritableByteChannel ch, String encoding)

For example, all current XML APIs use streams, files, readers and other traditional
I/O APIs to read the XML document. if you are writing an HTTP server designed
to process SOAP requests, you may want to read the HTTP request bodies using
channels and parse the XML using SAX for performance.

In this case, you'd need to convert these channels into streams before passing
them to XMLReader's parse() method:

SocketChannel channel = server.accept();
processHTTPHeader(channel);
XMLReader parser = XMLReaderFactory.createXMLReader();
parser.setContentHandler(someContentHandlerObject);

InputStream in = Channels.newInputStream(channel);
parser.parse(in);

Asynch Channels:

We can also use AsynchronousSocketChannels and AsyncrhonousServerSocketChannel classes.
They behave like the others for the most part.

Except, reads and writes return immedeatly, even before the I/O is complete.
The data read is further processed by a Future or a CompletionHandler. 
The connect() and accept() methods also execute asynch and return Futures. 
Selectors are not used.

An example:

SocketAddress address = new InetSocketAddress(args[0], port);
AsynchronousSocketChannel client = AsynchronousSocketChannel.open();
Future<Void> connected = client.connect(address);

ByteBuffer buffer = ByteBuffer.allocate(74);

//Wait for connection to finish
connected.get();

//Read from the connection
Future<Integer> future = client.read(buffer);

//Do other things

//wait for the read to finish
future.get();

//Flip and drain the buffer
buffer.flip();
WritableByteChannel out = Channels.newChannel(System.out);
out.write(buffer);

This approach fits where we need a certain order.

However, if we need not a certain order, if we can process each network read
independantly of others, then we can use CompletionHandler instead.

For example, if we have a spider reading stuff and feeds them into a backend,
we can just spawn AsynchronousSocketChannel requests and give each one a 
CompletionHandler that stores the results in teh backend.

The generic CompletionHandler interface defines two methods: completed() //If read successfully
failed() //on IO errors

A simple example of one that writes whatever it recieved on system out:

class LineHandler implements CompletionHandler<Integer, ByteBuffer>{
	@Override
	public void completed(Integer result, ByteBuffer buffer){
		buffer.flip();
		WritableByteChannel out = Channels.newChannel(System.out);
		try{
			out.write(buffer);
		} catch (IOException ex){
			System.err.println(ex);
		}
	}

	@Override
	public void failed(Throwable ex, ByteBuffer attachment){
		System.err.println(ex.getMessage());
	}
}

To use it:

ByteBuffer = ByteBuffer.allocate(74);
CompletionHandler<Integer, ByteBuffer> handler = new LineHandler();
channel.read(buffer, buffer, handler);

You can share AsynchSockets, but only one can read at a time and only one can write at a time.

Socket Options:

SocketChannel, ServerSocketChannel, AsynchronousServerSocketChannel, AsynchronousSocketChannel,
and DatagramChannel all implement the NetworkChannel interface.

The primary purpose is to support the TCP options, such as TCP_NODELAY, SO_TIMEOUT, SO_LINGER etc.

There is, however, only three generic typed methods for getting and setting:

<T> T getOption(SocketOption<T> name) throws IOException

<T> NetworkChannel setOption(SocketOption<T> name, T value) throws IOException

Set<SocketOption<?>> supportedOptions()

There 11 StandardSocketOptions that Java recognizes:

//They are all SocketOptions of some kind, so i will just write their qualifying name

StandardSocketOptions.IP_MULTICAST_IF

StandardSocketOptions.IP_MULTICAST_LOOP

StandardSocketOptions.IP_MULTICAST_TIL

StandardSocketOptions.IP_TOS

StandardSocketOptions.SO_BROADCAST

StandardSocketOptions.SO_KEEPALIVE

StandardSocketOptions.SO_LINGER

StandardSocketOptions.SO_RCFBUF

StandardSocketOptions.SO_REUSEADDR

StandardSocketOptions.SO_SNDBUF

StandardSocketOptions.TCP_NODELAY

An example of setting SO_LINGER for a client network channel:

NetworkChannel channel = SocketChannel.open();
channel.setOption(StandardSocketOptions.SO_LINGER, 240);

The following is a simple program that 	lists all supported options:

//imports

public class OptionSupport{
	public static void main(String[] args) throws IOException{
		printOptions(SocketChannel.open());
		printOptions(ServerSocketChannel.open());
		printOptions(AsynchronousSocketChannel.open());
		printOptions(AsynchronousServerSocketChannel.open());
		printOptions(DatagramChannel.open());
	}

	private static void printOptions(NetworkChannel channel) throws IOException{
		System.out.println(channel.getClass().getSimpleName() + " supports:");
		for (SocketOption<?> option : channel.supportedOptions()){
			System.out.println(option.name() + ": " + channel.getOption(option));
		}
		System.out.println();
		channel.close();
	}
}

Readiness Selection:

For network programming, the second part of the new I/O APIs is
readiness selection, the ability to choose a socket that will not block
when reading or written to.

It is primarily of interest for servers, although clients running multiple
simultaneous connections with several windows open - such as a web spider
or a browser - can take advantage of it as well.

It simply means having selectors and asking for the keys for the ready connections.

The Selector Class:

The only constructor is protected. TO make a socket, call the Factory method selector.open():

public static Selector open() throws IOException;

We then register the selected channel. Not all channels are selectable,
in particular FileChannels, but all network ones are.

The chanel is registered and then returns the keys of which are ready:

public final SelectionKey register(Selector sel, int ops) throws ClosedChannelException

public final SelectionKey register(Selector sel, int ops, Obejct att) throws ClosedChannelException

The first is the Selector, the second is the type of event being registered:

SelectionKey.OP_ACCEPT

SelectionKey.OP_CONNECT

SelectionKey.OP_READ

SelectionKey.OP_WRITE

They are bit-flag int constants (1,2, 3, 4), so to register several, run | (bitwise operator) when registering:

channel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);

The optional third, is a attachment for the key. this object is often used to
store state for the connection. For example, if you were implementing 
a web server, you might attach a FileInputStream or FileChannel connected to the
local file the server streams to the client.

You can query the Selector to see which onesa re ready for different operations.

There are three different selectors, one of which is nonblocking (returns immedeatly 
if there is no connections ready):

public abstract int selectNow() throws IOException

The other two, are blocking:

public abstract int select() throws IOException

public abstract int select(long timeout) throws IOException //Waits for timeout MS before returning 0

Retrieve the ready channels with selectedKeys():

public abstract Set<SelectionKey> selectedKeys()

//Loop with iteration through selectedKeys, remove leement after iterated over it

public abstract void close() throws IOException //releases resources and unlocks threads
being blocked

The SelectionKey class:

SelectionKey objects serve as pointers to channels. They also hold an object
attachment, which is normally how you save the state for the connection on that channel.

SelectionKey objects are returned from registering selectors to channels.
A single channel can be registered with multiple selectors.

We can run checks on what it is ready to do:

public final boolean isAcceptable()

public final boolean isConnectable()

public final boolean isReadable()

public final boolean isWritable()

A channel may be ready to do more than one thing. Depenidng on how many actions it had
registered to actually do (and can do, for that matter)

To retrieve the channel:

public abstract SelectableChannel channel()

If you've stored a holder for state info, you can retrieve it with attachment:

public final Object attachment()

When done with it, cancel the SelectionKey:

public abstract void cancel()

//Only nessecary if you did not close the selector and the channel

UDP:

Setting up TCP is more like a secure transfer, that takes time, both to send, process,
re-assert, slow down, create, tear down, many short transmissions in HTTP etc.

On the other side, is UDP. Which sends data quick, but is unreliable in it's format.

The UDP Protocol:

In some systems TCP works. In systems like Audio, or Video, where small static or corruption
is neglectable, UDP is much more relevant.

Reliability tests can be asserted into the application layer. If a client
sends a short UDP request to a server, it may assume the packet is lost 
if no response is returned within an established amount of time. This is one way
DNS works. (DNS can also operate over TCP)

This is not to say that UDP is impossible to make work with an extra layer of "correction",
which is not part on the UDP, but the app itself. Which, can be done. It's just a lot more work.

UDP can implement protocols that allow for sorting and reassertion. Examples of protocols
using UDP are: NFS (Network file system), Trivial FTP (TFTP), FSP. (NFS can use UDP or TCP)

UDP in Java, is split into two classes: DatagramPacket and DatagramSocket.
The DatagramPacket class stuffs bytes of data into UDP packets called data-grams
and lets you unstuff datagrams that you receive.

A DatagramSocket sends as well as recieves UDP datagrams. To send data, you
put the data in a DatagramPacket and send the packet using a DatagramSocket.

To recieve data, you take a DatagramPacket object from a DatagramSocket and read
the contents.

In UDP, everything is included in the Datagram packet. The socket only 
needs to know the local port on which to listen or send.

UDP is basically just like throwing data at something. No connections, no
streams of Data, just datagrams thrown.

UDP Clients:

Timeouts are far more important in UDP, because no Exception is thrown upon failure.
So, to showcase how to send data, we shall send to the Daytime server asb efore:

DatagramSocket socket = new DatagramSocket(0); //random port

socket.setSoTimeout(10000); //10 seconds timeout

//declare target host

InetAddress host = InetAddress.getByName("time.nist.gov");
DatagramPacket request = new DatagramPacket(new byte[1], 1, host, 13);

//Next, make the response, make the response big enough so that it wont crash
//Crashes are silent in UDP

byte[] data = new byte[1024]; //Empty byte array for response 
DatagramPacket response = new DatagramPacket(data, data.length);

//Send and recieve, they can throw exceptions, tho
socket.send(request);
socket.recieve(response);

//Convert them to a string
String dayTime = new String(responsegetData(), 0, response.getLength(), "US-ASCII");

//Do something with the string response

The following example puts it all together:

//imports

public class DaytimeUDPClient{
	private final static int PORT = 13;
	private static final String HOSTNAME = "time.nist.gov";

	public static void main(String[] args){
		try(DatagramSocket socket = new DatagramSocket(0)){
			socket.setSoTimeout(10000);
			InetAddress host = InetAddress.getByName(HOSTNAME);
			DatagramPacket request = new DatagramPacket(new byte[1], 1, host, PORT);

			DatagramPacket response = new DatagramPacket(new byte[1024], 1024);
			socket.send(request);
			socket.receive(response);
			String result = new String(response.getData(), 0, response.getLength(),
				"US_ASCII");

			System.out.println(result);
		} catch (IOException ex){
			ex.printStackTrace();
		}
	}
}

UDP Servers:

A UDP server follows almost the same pattern as a UDP client, except that
you usually receive before sending and don't choose an anonymous port to bind to.
Unlike TCP, there are no other DatagramServerSocket class.

//ASsign socket to known port

DatagramSocket socket = new DatagramSocket(13); //Need to be root on unix systems to do below 1024

//Create a packet with 1024 space, starting at 0

DatagramPacket request = new DatagramPacket(new byte[1024], 0, 1024);

//recive it

socket.receive(request); //Blocks until requst returns with Byte array , receive returns it

//Make a response packet -> raw data to send, number of bytes, hos to send to and port on that host to address:

String daytime = new Date().toString() + "\r\n";
byte[] data = daytime.getBytes("US-ASCII");

InetAddress host = request.getAddress();
int port = request.getPort();
DatagramPacket response = new DatagramPacket(data, data.length, host, port);

//Send the response back over the same socket

The following is an example of a DAytime serverb uilt on UDP:

//imports

public class DaytimeUDPServer{
	private final static int PORT = 13;
	private final static Logger audit = Logger.getLogger("requests");
	private final static Logger errors = Logger.getLogger("errors");

	public static void main(String[] args){
		try (DatagramSocket socket = new DatagramSocket(PORT)){
			while (true){
				try{
					DatagramPacket request = new DatagramPacket(new byte[1024], 1024);
					socket.receive(request);

					String daytime = new Date()toString();
					byte[] data = daytime.getBytes("US-ASCII");
					DatagramPacket response = new DatagramPacket(data, data.length, request.getAddress(),
						request.getPort());
					socket.send(response);
					audit.info(daytime + " " + request.getAddress());
				} catch (IOException | RuntimeException ex){
					errors.log(Level.SEVERE, ex.getMessage(), ex);
				}
			}
		} catch (IOException ex){
			errors.log(Level.SEVERE, ex.getMessage(), ex);
		}
	}
}

A lot of the time, UDP servers are not multithreaded. Cause they simply send simple
responses, don't have to handle a lot of errors, and cannot be blocked because 
they don't wait for the other end - as it does not handle errors.

Unless a lot of work goes into making the response, an iterative approach works
just fine for UDP servers.

The DatagramPacket Class:

The size limit of a UDP datagram is 65,536 minus 8.

The dataGram is basically three layers: Data, IP header and UDP header.

The UDP header has:

source port, destionation port, combined length of data and UDP header (8-65,515) and destionation
port again.

Data has:

data

IP header:

Version ,header length, type of service, datagram length, identification,
flags, fragment offset, header checksum, protocol, TTL, source address, destination address,
options

The actual limit of size is usally 8K bytes. Sending data larger than 8k truncates to 8k. Be warned.

For maximum safety, go with 512 bytes for data.

UDP datagrams are based in:

public final class DatagramPacket extends Object

Has methods such as:

get/set destionatin address from the IP header

get/set source or destination port 

get/set data

get/set length of data

The rest are inaccessible from pure java code.

The constructors:

DataGrams use different constructors depending on pakcet is being used for
sending data or recieving data.

The adddress and port aren't stored with the socket, as per TCP.

Constructors for receiving datagrams:

public DatagramPacket(byte[] buffer, int length)

public DatagramPacket(byte[] buffer, int offset int length)

First constructor stores from 0 to full or length

Example of DataGram receiving up to 8,192 bytes:

byte[] buffer = new byte[8192];
DatagramPacket dp = new DatagramPacket(buffer, buffer.length);

Second is used for starting at offset.

Providing less data is fine, it fills it out. 8192 is the limit (Due to underlying
network protocols, not UDP itself)

The limmit for IPV4 is 65.507. DataGrams can receive IPV4 packets for 65.507

The theoritecal limit is 65.536 for IPV6. But most protocols such as 
DNS and FTP whom are based on UDP, use packets with 512 packets.

Large data size is 8192. Stick to that. (As OS's split, discard, truncate bigger ones).
And isnce its UDP, no exception is given if the packet is too large. Since its a 
unsecured protocol.

Constructors for sending datagrams:

There are four:

public DatagramPacket(byte[] data, int length, InetAddress destination, int port)

public DatagramPacket(byte[] data, int offset, int length, InetAddress destination, int port)

public DatagramPacket(byte[] data, int length, SocketAddress destination)

public DatagramPacket(byte[] data, int offset, int length, SocketAddress destination)

The optimal size depends on the network you are sending across. On unreliable networks,
such as Radio : use small packets, decereases chanse of corruption.

On optimized LAN networks or highspeed ones, use 8k packets.

UDP does not use private buffers. CHanges in the packet changes it.

An example of sending Data:

String s = "This is a Test";
byte[] data = s.getBytes("UTF-8");

try{
	InetAddress ia = InetAddress.getByName("www.ibilio.org");
	int port = 7;
	DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);
	//Send the packet
} catch(IOException ex){
	
}

String classes have the getBytes() methods for conversion to bytes, but the 
java.io.ByteArrayOutputStream can also be very useful for packeting to bytes.

The get Methods:

DatagramPacket has six methods that gets data from the Datagrams: the actual data,
and fields from its hdear.

public InetAddress getAddress()

Returns an InetAddress object containing the address of the remote host.

if the datagram was received from the internet, the address returned
is the address of the machine that sent it.

If its created locally, it returns the target address.

public int getPort():

returns remote port. If recieved, gets from sender. If sent, gets target port.

public SocketAddress getSocketAddress():

Gets ip and port of remote host. If local, returns desitnation. If recieved,
returns senders info.

In NIO, DatagramChannels accept accept SocketAddress, but not an InetAddress and port.

public byte[] getData():

Gets the data.

If it's string:

String s = new String(dp.getData(), "UTF-8");

If it's non-text:

InputStream in = new ByteArrayInputStream(packet.getData(), packet.getOffset(), packet.getLength());

You MUST use offset and length when creating ByteArrayInputStreams.

//Chain the inputstream to a DataInputStream:

DataInputStream din = new DataInputStream(in); 

We can then call getters to get out the info from this stream, such as readInt(), readLong(),
readChar() etc.

This assumes the data type is the same as the ones understood in Java. It is, for the 
most part. (Not always).

public int getLength():

returns length of data in datagram. Not nessecarily same as long as the actual array length.

public int getOffset():

returns the offset point.

The following, is an example showcasing reading from DatagramPackets:

//import

public class DatagramExample{
	public static void main(String[] args){
		String s = "This is a test.";

		try{
			byte[] data = s.getBytes("UTF-8");
			InetAddress ia = InetAddress.getByName("www.ibiblio.org");
			int port = 7;

			DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);

			System.out.println("This packet is addressed to " + dp.getAddress() + " on port " + dp.getPort());

			System.out.println("There are " + dp.getLength() + " bytes of data in the packet");

			System.out.println(new String(dp.getData(), dp.getOffset(), dp.getLength(), "UTF-8"));
		} catch (UnknownHostException | UnsupportedEncodingException ex){
			System.err.println(ex);
		}
	}
}

The Setter Methods:

Something we wish to reuse datagrams instead of spawning new ones. can be good for performance
on specific situations. Thus, setters can be used.

public void setData(byte[] data):

Changes teh payload. Can be used for breaking a large file into parts of sending

public void setData(byte[] data, int offset, int length):

Puts all the data into one array and send it in chunks. An example:

int offset = 0;
DatagramPacket dp = new DatagramPacket(bigarray, offset, 512);
int bytesSent = 0;
while (bytesSent < bigarray.length){
	socket.send(dp);
	bytesSent += dp.getLength();
	int bytesToSend = bigarray.length - bytesSent;

	int size = (bytesToSend > 512) ? 512 : bytesToSend;
	dp.setData(bigarray, bytesSent, size);
}

This stratergy requires a high confidence in the datas arrival.
Its relativeily hard to attach sequence numbers or other reliability tags
to individual packets when you take this approach.

public void setAddress(InetAddress remote):

Changes address a Datagram is sent to.

An example:

String s = "Really important message";
byte[] data = s.getBytes("UTF-8");

DatagramPacket dp = new DatagramPacket(data, data.length);

dp.setPort(2000);

int network = "128.238.5.";
for (int host = 1; host < 255; host++){
	try{
		InetAddress remote = InetAddress.getByName(network + host);
		dp.setAddress(remote);
		socket.send(dp);
	} catch (IOException ex){
		//Continue with the next host
	}
}

If we were to use this for broadcasting to a specific network, we just 
launch on the address of : <network ip>.255.255. An example:

//network has 128.238.0.0

thens end on 128.238.255.255

This copies it to every host on the network. Can be blocked by firewalls tho.
Or routers.

For more widely spread hosts, use mutlicasting. Multicasting 
uses the same DatagramPackets as here. However, it uses
different IP addresses and a MulticastSocket instead of a DatagramSocket.
More on that later.

public void setPort(int port):

Sets the port of a datagram. Can be used when ports are needed to be changed before
sending the same packet again.

public void setAddress(SocketAddress remote):

Sets the address of the DataGram. an example:

DatagramPacket input = new DatagramPacket(new byte[8192], 8192);
socket.receive(input);
DatagramPacket output = new DatagramPacket("HEllo there".getBytes("UTF-8"), 11);

SocketAddress address = input.getSocketAddress();
output.setAddress(address);
socket.send(output);

public void setLength(int length):

Allows for resetting of length of buffer in the DataGrams. 
Normally, when data is received, future data is truncated to received length.

This allows for resetting of that, to a wanted length. So subsequent ones are not 
truncated.

The DatagramSocket Class:

To send or receive DatagramPackets, we must open datagram sockets:

public class DatagramSocket extends Object

if we are writing a client, we use a anonymous port (random assigned)

When a server constructors a DatagramSocket, it defines port to which it 
is listening on.

Beyond this, they are identical.

public DatagramSocket() throws SocketException

An example of a anonymous port in a datagram socket:

try{
	DatagramSocket client = new DatagramSocket();
	//Send packets
} catch (SocketException ex){
	System.err.println(ex);
}

This is to be used for client to server.

public DatagramSocket(int port) throws SocketException:

Creates a Server listening for connections on the given port.

on Unix systems, requires root for below 1024. 

note: TCP and UDP ports are not related. They can occupy the same port number, but running
on different protocols.

The following example checks to see if there are servers on any ports.

//import

public class UDPPortScanner {
	public static void main(String[] args){
		for (int port = 1024; port <= 65535; port++){
			try{
				//Throws an exception if port is occuppied
				DatagramSocket server = new DatagramSocket(port);
				server.close();
			} catch (SocketException ex){
				System.out.println("There is a server on port " + port + ".");
			}
		}
	}
}

2049 can be NFS. Ports on 30k+ are Remote Procedure Call (RFC) services. Along 
with RPC, common protocols that use UDP includes NFS, TFTP, and FSP.

It's much harder to scan UDP ports on a remote system than to scan for remote 
TCP ports. Since there is no guarantee of package delivery in UDP, 
you have to send it a packet it recognizes and responds to.

public DatagramSocket(int port, inetAddress interface) throws SocketException

This is mostly used for multiHomed hosts. Requires deligated port, inetAddress interface.

Listens for incoming connections on that port and based on that interface.

public DatagramSocket(SocketAddress interface) throws SocketException:

Similar to the previous one, but bases itself on a SocketAddress:

SocketAddress address = new InetSocketAddress("127.0.0.1", 9999);
DatagramSocket socket = new DatagramSocket(address);

protected DatagramSocket(DatagramSocketImpl impl) throws SocketException:

Allows for defining of own UDP protocol. This socket is not initially bound
to a port and must there of be bound:

public void bind(SocketAddress addr) throws SocketException;

You can pass null to this method, picking a random available one (port and address).

Sending and Receiving Datagrams:

A socket can send to and recieve from several hosts at the same time.

public void send(DatagramPacket dp) throws IOException:

Once a DatagramPacket is created and a socket is constructed,
send the packing by passing it to the socket's send() method.

Since it's UDP, it will most likely not throw an exception if one occurs.

It might throw one if you try to send a packet larger than it's specified
size limit. It might also throw one if you attempt to communicate with
one that you are not given clearance to.

However, that is mostly for servlets.

The following is a UDP discard client, that reads data from System.in and 
send it to a Discard server:

//imports

public class UDPDiscardClient{
	public final static int PORT = 9;

	public static void main(String[] args){
		String hostname = args.length > 0 ? args[0] : "localhost";

		try(DatagramSocket theSocket = new DatagramSocket()){
			InetAddress server = InetAddress.getByName(hostname);

			BufferedReader userInput = new BufferedReader(new InputStreamReader(System.in));

			while (true){
				String theLine = userInput.readLine();
				if (theLine.equals(".")) break;
				byte[] data = theLine.getBytes();

				DatagramPacket theOutput = new DatagramPacket(data, data.length, server, PORT);
				theSocket.send(theOutput);
			} //end while
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

The only noteworthy thing here is that discard servers disregard special chars and carriage returns.

public void receive(DatagramPacket dp) throws IOException:

Receives a UDP datagram fron the network and stores it in the delegated DatagramPacket.

Is blocking until it receives something. If doing other operations, delegate to other thread.

The datagrams buffer should be big enough to store whatever it receives. If it isn't, (exceeds
65.507 bytes or 8.192 bytes), it truncates it to that size.

The following is an example of a UDP discard server:

//imports

public class UDPDiscardServer{
	public final static PORT = 9;
	public final static int MAX_PACKET_SIZE = 65507;

	public static void main(String[] args){
		byte[] buffer = new byte[MAX_PACKET_SIZE];

		try (DatagramSocket server = new DatagramSocket(PORT)){
			DatagramPacket packet = new DatagramPacket(buffer, buffer.length);
			while (true){
				try{
					server.receive(packet);
					String s = new String(packet.getData(), 0, packet.getLength(), "8859_1"); //Latin-1 ISO 8859-1 encoding
					System.out.println(packet.getAddress() + " at port " + packet.getPort() + " says " + s);
					//reset length for next packet
					packet.setLength(buffer.length);
				} catch (IOException ex){
					System.err.println(ex);
				}
			}
		} catch (SocketException ex){
			System.err.println(ex);
		}
	}
}

public void close():

Just run try with resources:

try (DatagramSocket server = new DatagramSocket()){
	//use the socket
}

Automatically closes the socket upon completion.

public int getLocalPort():

Get the local port of the Socket. Use when assigned a anonymous socket
to find port:

DatagramSocket ds = new DatagramSocket();
System.out.println("The socket is using port " + ds.getLocalPort());

public InetAddress getLocalAddress():

gets the InetAddress object that presents the local address that the 
socket is bound to.

public SocketAddress getLocalSocketAddress():

returns a SocketAddress object that wraps local interface and port of which
a socket is bound to.

Managing Connections:

By default, datagrams speaks to anyone, unlike TCP. We can change that.
Generally, Datagrams should only be sent to relevant parties.

public void connect(InetAddress host, int port):

Narrows down to whom the DatagramSocket can send packets to and receive packets
from. Must be from specified host and on target port.

Sending to any other place, throws a Exception.

A security check occurrs when connect() is run to see if the VM is allowed
to send to respective place. If so, it passes. if not, a exception.

If connection goes through, send() and receive() no longer make security checks.

public void disconnect():

Removes connection restraint.

public int getPort():

If a DatagramSocket is connected, getPort() returns remote port to which it is
connected. Otherwise, -1.

public InetAddress getInetAddress():

Same as above, but returns address of remote host. Null if not connected.

public InetAddress getRemoteSocketAddress():

If connected, returns remote host address. Otherwise, null.

Socket Options:

There are 6 options for UDP in Java.

SO_TIMEOUT:

TIme before receive() times out. if 0, its never.

can be changed and gotten with set/get:

public void setSoTimeout(int timeout) throws SocketException

public int getSoTimeout() throws IOException

Default is 0. Must be set before receive().

An example :

try {
	byte[] buffer = new byte[2056];
	DatagramPacket dp = new DatagramPacket(buffer, buffer.length);
	DatagramSocket ds = new DatagramSocket(2048);
	ds.setSoTimeout(30000); //30 secs
	try{
		ds.receive(dp);
		//Process packet
	} catch (SocketTimeoutException ex){
		ss.close();
		System.err.println("No connection within 30 seconds");
	}
} catch (SocketException ex){
	System.err.println(ex);
} catch (IOException ex){
	System.err.println("Unexpected IOException " + ex);
}

Another example:

public void printSoTimeout(DatagramSocket ds){
	int timeout = ds.getSoTimeOut();
	if (timeout > 0){
		System.out.println(ds + " will time out after " + timeout + " milliseconds");
	} else if(timeout == 0){
		System.out.println(ds + " will never timeout.");
	} else {
		System.out.println("Something is seriously wrong with " + ds);
	}
}

SO_RCVBUF:

The size of the Buffer for recieved UDP packets. Any surplus data above packet size is discarded. 
TCP resends stuff.

Also defines max size of recievable packages.

Setters and getters:

public void setReceiveBufferSize(int size) throws SocketException

public int getReceiveBufferSize() throws SocketException

As per normal, it is a suggestion, not a written in stone order.



SO_SNDBUF:

as per RCFBUF, but for sending. 

public void setSendBufferSize(int size) throws SocketException

public int getSendBufferSize() throws SocketException

SO_REUSEADDR:

Acts different than for TCP. Controls wether multiple datagram 
sockets can bind to the same port and address at the same time.

If multiple sockets are bound to the same port, received packets 
will be copied to all bound sockets. 

public void setReuseAddress(boolean on) throws SocketException

public boolean getReuseAddress() throws SocketException

Set must be called before the new socket binds. 

Mostly used for multicasting sockets. Datagram channels also spawn
unconnected datagram sockets that can be configured to reuse ports.

SO_BROADCAST:

defines wether a socket is allowed to use broadcasting IPs or not.

Example:

196.168.254.255 (broadcasting IP for) -> 192.168.254.*

Commonly used for DHCP. Controlled with setter and getter:

public void setBroadcast(boolean on) throws SocketException

public boolean getBroadcast() throws SocketException

defaults to being on. Routers and gateways usually don't allow broadcasting IPs.

If you are using broadcasting, use DatagramPacket(int port) constructor.
Sockets bound to specific addresses might not respond to broadcasts.

IP_TOS:

Defines their traffic class level. Between 0 and 255. 

Again, preference, not law.

Some Useful Applications:

The following is a example of a simple UDP Poke class, which sends a UDP
package and reads the result:

//imports

public class UDPPoke{
	private int bufferSize;
	private int timeout;
	private InetAddress host;
	private int port;

	public UDPPoke(InetAddress host, int port, int bufferSize, int timeout){
		this.bufferSize = bufferSize;
		this.host = host;
		if (port < 1 || port > 65535){
			throw new IllegaArgumentException("Port out of range");
		}

		this.port = port;
		this.timeout = timeout;
	}

	public UDPPoke(InetAddress host, int port, int bufferSize){
		this(host, port, bufferSize, 30000);
	}

	public UDPPoke(InetAddress host, int port){
		this(host, port, 8192, 30000);
	}

	public byte[] poke(){
		try (DatagramSocket socket = new DatagramSocket(0)){
			DatagramPacket outgoing = new DatagramPacket(new byte[1], 1, host, port);
			socket.connect(host, port);
			socket.setSoTimeout(timeout);

			socket.send(outgoing);
			DatagramPacket incoming = new DatagramPacket(new byte[bufferSize], bufferSize);

			//blocks until recieved
			socket.receive(incoming);
			int numBytes = incoming.getLength();
			byte[] response = new byte[numBytes];

			System.arraycopy(incoming.getData(), 0, response, 0, numBytes);
			return response;
		} catch (IOException ex){
			return null;
		}
	}

	public static void main(String[] args){
		InetAddress host;
		int port = 0;
		try{
			host = InetAddress.getByName(args[0]);
			port = Integer.parseInt(args[1]);
		} catch (RuntimeException | UnknownHostException ex){
			System.out.println("Usage: java UDPPoke host port");
			return;
		}

		try{
			UDPPoke poker = new UDPPoke(host, port);
			byte[] response = poker.poke();
			if (response == null){
				System.out.println("No response within alloted time");
				return;
			}
			String result = new String(response, "US-ASCII");
			System.out.println(result);
		} catch (UnsupportedEncodingExcetpion ex){
			//Should not occurr
			ex.printStackTrace();
		}
	}
}

By having the UDPPoke class, we can use that on the client end, as follows:

//imports

public class UDPTimeClient{
	public final static int PORT = 37;
	public final static String DEFAULT_HOST = "time.nist.gov";

	public static void main(String[] args){
		InetAddress host;

		try{
			if (args.length > 0){
				host = InetAddress.getByName(args[0]);
			} else {
				host = InetAddress.getByName(DEFAULT_HOST);
			}
		} catch (RuntimeException | UnknownHostException ex){
			System.out.println("Usage: java UDPTimeClient [host]");
			return;
		}

		UDPPoke poker = new UDPPoke(host, PORT);
		byte[] response = poker.poke();
		if (response == null){
			System.out.println("No response within the alloted time");
			return;
		} else if (response.length != 4){
			System.out.println("Unrecognize response format");
			return;
		}

		//The time protocol sets the epoch at 1900,
		// the Java Date class at 1970. This number converts between them

		long differenceBetweenEpochs = 220898880L;

		long secondsSince1900 = 0;
		for(int i = 0; i < 4; i++){
			secondsSince1900 = (secondSince1900 << 8) | (response[i] & 0x000000FF);
		}

		long secondsSince1970 = secondsSince1900 - differenceBetweenEpochs;

		long msSince1970 = secondsSince1970 * 1000;
		Date time = new Date(msSince1970);

		System.out.println(time);
	}
}

The following is a parallelized Server structure that allows for shutdown as well:

//imports

public abstract class UDPServer implements Runnable{
	private final int bufferSize;
	private final int port;

	private final Logger logger = logger.getLogger(UDPServer.class.getCanonicalName());
	private volatile boolean isShutdown = false;

	public UDPServer(int port, int bufferSize){
		this.bufferSize = bufferSize;
		this.port = port;
	}

	public UDPServer(int port){
		this(port, 8192);
	}

	@Override
	public void run(){
		byte[] buffer = new byte[bufferSize];
		try (DatagramSocket socket = new DatagramSocket(port)){
			socket.setSoTimeout(10000); //Check every 10 sec for shutdown
			while (true){
				if(isShutDown) return;
				DatagramPacket incoming = new DatagramPacket(buffer, buffer.length);
				try{
					socket.receive(incoming);
					this.respond(socket, incoming);
				} catch (SocketTimeoutException ex){
					is (isShutDown) return;
				} catch (IOException ex){
					logger.log(Level.WARNING, ex.getMessage(), ex);
				}
			}
		} catch (SocketException ex){
			logger.log(Level.SEVERE, "Could not bind to port: " + port, ex);
		}
	}

	public abstract void respond(DatagramSocket socket, DatagramPacket request) throws IOException;

	public void shutDown(){
		this.isShutDown = true;
	}
}

The above acts as a base for UDPServer builds. The next example, builds a high performing
UDP discard server:

//imports

public class FastUDPDiscardServer extends UDPServer{
	public final static int DEFAULT_PORT = 9;

	public FastUDPDiscardServer(){
		super(DEFAULT_PORT);
	}

	public static void main(String[] args){
		UDPServer server = new FastUDPDiscardServer();
		Thread t = new Thread(server);
		t.start();
	}

	@Override
	public void respond(DatagramSocket socket, DatagramPacket request){
		//Since its a discard, do nothing with the repsonse, basically discarding the data
	}
}

Next up is a UDP echo server. Unlike TCP, UDP does not need multiple threads for multiple
clients:

//imports

public class UDPEchoServer extends UDPServer{
	
	public final static int DEFAULT_PORT = 7;

	public UDPEchoServer(){
		super(DEFAULT_PORT);
	}

	@Override
	public void respond(DatagramSocket socket, DatagramPacket packet) throws IOException
	{
		DatagramPacket outgoing = new DatagramPacket(packet.getData(), 
			packet.getLength(), packet.getAddress(), packet.getPort());
		socket.send(outgoing);
	}

	public static void main(String[] args){
		UDPServer server = new UDPEchoServer();
		Thread t = new Thread(server);
		t.start();
	}
}

The earlier defined UDPPoke is not fit for all protocols. Some protocols requires 
multiple datagrams which requires a different implementation.

Echo, for instance, has TCP and UDP. however, UDP has no guarantee of return.
Thus, we must run UDP to be asynch. There is three parts to this client:

the main UDPEchoClient class, the SenderThread class and the Receiver Thread class.

//imports

public class UDPEchoClient{
	public final static int PORT = 7;

	public static void main(String[] args){
		String hostname = "localhost";
		if(args.length > 0){
			hostname = args[0];
		}

		try{
			InetAddress ia = InetAddress.getByName(hostname);
			DatagramSocket socket = new DatagramSocket();

			SenderThread sender = new SenderThread(socket, ia, PORT);
			sender.start();

			Thread receiver = new ReceiverThread(socket);
			receiver.start();
		} catch (UnknownHostException ex){
			System.err.println(ex);
		} catch (SocketException ex){
			System.err.println(ex);
		}
	}
}

And next, is the Sender Thread:

//imports

class SenderThread extends Thread{
	private InetAddress server;
	private DatagramSocket socket;
	private int port;
	private volatile boolean stopped = false;

	SenderThread(DatagramSocket socket, InetAddress address, int port){
		this.server = address;
		this.port = port;
		this.socket = socket;
		this.socket.connect(server, port);
	}

	public void halt(){
		this.stopped = true;
	}

	@Override
	public void run(){
		try{
			BufferedReader userInput = new BufferedReader(new InputStreamReader(System.in));

			while(true){
				if(stopped) return;
				String theLine = userInput.readLine();

				if(theLine.equals(".")) break;
				byte[] data = theLine.getBytes("UTF-8");

				DatagramPacket output = new DatagramPacket(data, data.length, server, port);

				socket.send(output);
				Thread.yield();
			}
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

Next, is the receiver thread:

//imports

class ReceiverThread extends Thread{
	private DatagramSocket socket;

	private volatile boolean stopped = false;

	ReceiverThread(DatagramSocket socket){
		this.socket = socket;
	}

	public void halt(){
		this.stopped = true;
	}

	@Override
	public void run(){
		byte[] buffer = new byte[65507];
		while (true){
			if(stopped) return;
			DatagramPacket dp = new DatagramPacket(buffer, buffer.length);

			try{
				socket.receive(dp);
				String s = new String(dp.getData(), 0, dp.getLength(), "UTF-8");
				System.out.println(s);
				Thread.yield(); //Yield the thread to give other threads a chanse to run,
				//it has had it's say, make sure the flow is kept up
			} catch (IOException ex){
				System.err.println(ex);
			}
		}
	}
}

DatagramChannel:

It is, like the SocketChannel and ServerSocketChannel are used for NIO TCP apps.
Of course, the DatagramChannel supports selectors.

UDP is much more asynch than TCP, cause no need for verification and what not,
so the netgain of NIO is much smaller.

a UDP can already handle inputs from several different sources, for instance,
so putting in NIO is kinda moot. However, it can be used for return quickly
for network downperiods or unready to send.

Using DatagramChannel:

Opening a Socket:

As per usual, use open to spawn a Channel:

DatagramChannel channel = DatagramChannel.open();

We have to bind it as well:

SocketAddress address = new InetSocketAddress(3141);
channel.bind(address);

Receiving:

receive() reads one datagram packet from the channel into a ByteBuffer.
It returns the address of the host that sent the packet:

public SocketAddress receive(ByteBuffer dst) throws IOException

The following is a example of a UDPDiscardServer based on channels:

//Remember, extra data beyond the buffer capacity is discarded silently, cause UDP, yo.

//imports

public class UDPDiscardServerWithChannels{
	public final static int PORT = 9;
	public final static int MAX_PACKET_SIZE = 65507;

	public static void main(String[] args){
		try{
			DatagramChannel channel = DatagramChannel.open();
			DatagramSocket socket = channel.socket();

			SocketAddress address = new InetSocketAddress(PORT);
			socket.bind(address);
			ByteBuffer buffer = ByteBuffer.allocateDirect(MAX_PACKET_SIZE);
			while(true){
				SocketAddress client = channel.receive(buffer);
				buffer.flip();
				System.out.println(client + " says " );
				while (buffer.hasRemaining()) System.out.write(buffer.get());
				System.out.println();
				buffer.clear();
			}
		} catch (IOexception ex){
			System.err.println(ex);
		}
	}
}

Sending:

send() writes one datagram packet into the channel from a ByteBuffer 
to the address specified as the second arg:

public int send(ByteBuffer src, SocketAddress target) throws IOException

The ByteBuffer can be reused to send the same data to multiple clients.
Remember to rewind (buffers are iteratively gone through)

send() returns the amount of bytes written. It will either be the available bytes
in teh buffer at the time, or zero. Nothing in between.

Its 0 if its NIO and can't be sent at that time.

If its not in NIO, its blocking until sent.

The next example, showcases a UDPEchoServer based on channels:

//imports

public class UDPEchoServerWithChannels{
	public final static int PORT = 7;
	public final static int MAX_PACKET_SIZE = 65507;

	public static void main(String[] args){
		try{
			DatagramChannel channel = DatagramChannel.open();
			DatagramSocket socket = channel.socket();

			SocketAddress address = new InetSocketAddress(PORT);
			socket.bind(address);

			ByteBuffer buffer = ByteBuffer.allocateDirect(MAX_PACKET_SIZE);
			while (true){
				SocketAddress client = channel.receive(buffer);
				buffer.flip();
				channel.send(buffer, client);
				buffer.clear();
			}
		} catch (IOException ex){
			System.err.println(ex);
		}
	}
}

the above program is synch, blocking and iterative.

Since it's UDP, it is not an issue, since it's faster, but less reliable. 
All it realistically waits for is the buffers to be flipped.

Connecting:

When you opened a datagram channel, connect to it:

SocketAddress remote = new InetSocketAddress("time.nist.gov", 37);
channel.connect(remote);

Unlike TCP, this won't send anything acorss this network. It's merely the 
"Elimination" of other allowed hosts and targets.

We can check if it's limited and remove that limitaiton as well:

public boolean isConnected()

public DatagramChannel disconnect() throws IOException

Reading:

read() only works on connected connections.

It reads the data into a ByteBuffer. Returns amount read. 
Acceppts ByteBuffer or array of ByteBuffers or can slice Buffers.

It reads a single datagram from the network.

Returns byets read or -1 on Channel closed.

can return 0:

Buffer is full

Datagram packet contained no data

Channel is non-blocking and was not ready

Writing:

write() only works on connected connections.

Is basically the opposite of read. can be called until depleted buffer.

while (buffer.hasRemaining() && channel.write(buffer) != -1);

The following example is a UDP Echo client based on channels:

//imports

public class UDPEchoClientWithChannels{
	
	public final static int PORT = 7;
	private final static int LIMIT = 100;

	public static void main(String[] args){
		SocketAddress remote;
		try{
			remote = new InetSocketAddress(args[0], port);
		} catch (RuntimeException ex){
			System.err.println("USage: java UDPEchoClientWithChannels host");
			return;
		}

		try(DatagramChannel channel = DatagramChannel.open()){
			channel.configureBlocking(false);
			channel.connect(remote);

			Selector selector = Selector.open();

			channel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);

			ByteBuffer buffer = ByteBuffer.allocate(4);
			int n = 0;
			int numbersRead = 0;
			while (true){
				if (numbersRead == LIMIT) break;
				//WAit one minute for a connection
				selector.select(60000);

				Set<SelectionKey> readyKeys = selector.selectedKeys();

				if(readyKeys.isEmpty() && n == LIMIT){
					//All packets have been writetn and we assume no more are coming
					break;
				}
				else{
					Iterator<SelectionKey> iterator = readyKeys.iterator();
					while(iterator.hasNext()){
						SelectionKey key = (SelectionKey) iterator.next();
						iterator.remove();
						if(key.isReadable()){
							buffer.clear();
							channel.read(buffer);
							buffer.flip();
							int echo = buffer.getInt(); //What to echo
							System.out.println("Read: " + echo);
							numbersRead++;
						}
						if(key.isWritable()){
							buffer.clear();
							buffer.putInt(n);
							buffer.flip();
							channel.write(buffer);
							System.out.printable("Wrote: " + n);
							n++;
							if (n == LIMIT){
								//All packets have been written, switch to reado nly mode
								key.interestOps(SelectionKey.OP_READ);
							}
						}
					}
				}
			}
				System.out.println("Echoed " + numbersRead + " out of " + LIMIT + " send");
				System.out.println("Success rate: " + 100.0 * numbersRead / LIMIT + "%");
			} catch (IOException ex){
				System.err.println(ex);
			}
		}
}


//NOTE: Error of Indention somewhere, shit the samne.

The biggest difference with UDP and TCP is that UDP is connectionless, thus,
having us to check limits for ourselves. We also have to shutdown things ourselves.

A few miles away renders about 90% and a few hops away about 98%. UDP is not THAT bad, just
not fit for all sitautions.

Closing:

to close, just run with try with resources:

try (DatagramChannel channel = DatagramChannel.open()){
	//use the channel
} catch (IOException ex){
	//Handle exceptions
}

Socket Options//Java 7:

Datagram Channels supports 8 socket options:

option 						Type 					Constnat 				Purpose

SO_SNDBUF 					StandardSocketOptions 	Integer 				Size of buffer for sent datagrams

SO_RCVBUF 					StandardSocketOptions. 	Integer 				Size of buffer used for received data
							SO_RCVBUF

SO_REUSEADDR 				StandardSocketOptions. 	Boolean 				Enable/disable address reuse
							SO_REUSEADDR

SO_BROADCAST 				-II-.SO_BROADCAST 		Boolean 				Enable/disable broadcast messages

IP_TOS 						-II-.IP_TOS 			Integer 		 		Traffic class ranking

IP_MULTICAST_IF 			-II-.IP_MULTICAST_IF 	NetworkInterface 		Local network IF for multicast

IP_MULTICAST_TIL 			-II-.IP_MULTICAST_TIL 	Integer 				TTL for multicast datagrams

IP_MULTICAST_LOOP 			-II-.IP_MULTICAST_LOOP 	Boolean 				Enb/Dsb loopback of multicast datagrams

The normal wildcard setters and getters are ture for these:

public <T> DatagramChannel setOption(SocketOption<T> name, T value) throws IOException

public <T> T getOption(SocketOption<T> name) throws IOException

public Set<SocketOption<?>> supportedOptions()

supportedOptions tells you what options are allowed. getOption() tells current values of these.
setOption() changes values.

An example for checking default values of Channels:

//imports

public class DefaultSocketOptionValues {
	public static void main(String[] args){
		try (DatagramChannel channel = DatagramChannel.open()){
			for (SocketOption<?> option : channel.supportedOptions()){
				System.out.println(option.name() + ": " + channel.getOption(option));
			}
		} catch (IOExcetpion ex){
			ex.printStackTrace();
		}
	}
}

IP Multicast:

Previous socket examples have been unicast. They provide from point to point.

Multicasting is when you send to everyone in a specified group. True multicasting, discovered recently,
is when you send to a router close to a certain network and then have that router spread
the info from there, to the rest.

Multicasting, is built on UDP.

multicasting in java uses the DatagramPacket class along with Multicast Socket.

MultiCasting:

Multicast is more wide than point to point, but less so than broadcasting.

The approach of multicast is by making connection trees. Chains of sending data
where data is replicated to send out to others, which branches out to otehrs etc.

Multicasting, is the concept of finding the way to a relevant "head" server, which spreads to subjugate
servers and so forth.

The TTL in Multicasting, which is in the header, is the maximum amount of Routers the datagram is
allowed to go through.

A multicast Address is the shared address of a multicast group.

IPV4 multicasts range from 224.0.0.0 to 239.255.255.255

The 4 first bits of the Multicast addresses are 1110

Most Multicast groups are transient, they are created by virtue of inclusion and exclusion,
they are not permanent. A group ceases to exist when it has no members.

To make a new multicast group, just assign a ip between 225.0.0.0 to 238.255.255.255,
construct an InetAddress of that IP, and start sending it data.

Link-local multicast addresses are responsible for routing protocols and low level activites,
such as gateway discovery and group membership reporting.

They begin with 224.0.0 (224.0.0.0 to 224.0.0.255).

For instance, 224.0.0.1 is a multicast group that includes all systems on the local subnet.
Multicast routers never forward datagrams with destinations in this range.

A list of some of the link-local multicast addresses:

Domain name 				Ip Address 			Purpose

BASE-ADDRESS.MCAST.NET 		224.0.0.0 			The reserved base address. Never assign to any group

ALL-SYSTEMS.MCAST.NET 		224.0.0.1 			All systems on local subnet

ALL-ROUTERS.MCAST.NET 		224.0.0.2 			All routers on local subnet

DVMRP.MCAST.NET 			224.0.0.4 			All Distance Vector Multicasting Routing Protocol routers on this subnet

MOBILE-AGENTS.MCAST.NET 	224.0.0.11 			Mobile agents on the local subnet

DHCP-AGENTS.MCAST.NET 		224.0.0.12 			Allows a client to locate a Dynamic Host Config Protocol (DHCP)
												server or relay agent on the local subnet

RSVP-ENCAPSULATION.MCAST.NET 224.0.0.14 		RSVP encapsulation on this subnet. Protocol to reserve bandwith before an event.

VRRP.MCAST.NET 				-II-.18 			Virtual Router Redundancy protocol Routers (VRRP) routers

							-II-.35 			DXCluster is used to announce foreign amature (DX) stations

							-II-.36 			Digital Transmission Content Protection (DCTP),
												a digital restrictions management (DRM) tech that encrypts
												interconnections between DVD players, televions and similar
												devices.
							-II-.37 - 68 		zeroconf addressing

							-II-.106 			Multicast Router Discovery

//The list goes on, as well as for Permanent list. List exists on iana.org if we need it.

Clients and Servers:

When a host sends Multicasting, it is just sending UDP to a Multicast group.

The TTL values define how far packages can go.

16 is kind of for a organization or their immedeat vicinity.

127 is for the World.

The value can in total go from 1 to 255.

Packets sent to multicast group from 224.0.0.0 to 224.0.0.255 are never 
forwarded beyond the subnet, regarldess of TTL.

General estimation of TTL: //These are not hard and fast values.

Destination 						TTL value

Local host  						0

The local subnet 					1

The local campus, local area 		16

High-bandwith sites in the country 	32

All sites in the country 			48

All sites on the same continent 	64

High-bandwith worldwide 			128

All sites worldwide 				255

The TTL takes a hit of 1-<a few> based on each router it hits.

When it reaches 0, it's discarded.


Routers and Routing:

the big problem with Multicasting is that it requires a Mrouter (a multicast router)

Many ISPs dont actiave Multicasting on their routers.

We multicast with a Multicast Socket:

public class MulticastSocket extends DatagramSocket implements Closeable, AutoCloseable

//Make a multisocket and join a multicast group

MulticastSocket ms = new MulticastSocket(2300);

InetAddress group = InetAddress.getByName("224.2.2.2");
ms.joinGroup(group);

As per normal with recieving data:

byte[] buffer = new byte[8192];
DatagramPacket dp = new DatagramPacket(buffer, buffer.length);
ms.receive(dp);

When we are done:

ms.leaveGroup(group);
ms.close();

We don't need to join a Multicast group to join it:

InetAddress ia = InetAddress.getByName("experiment.mcast.net");
byte[] data = "Here's some multicast data \r\n".getBytes("UTF-8");
int port = 4000;

DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);
MulticastSocket ms = new MulticastSocket();
ms.send(dp);

Multicasting is a massive security hole, though. This causes the Securitymanager
to go amok, basically.

Which is why most environments that execute remote code do not enable multicasting.

The Constructors:

As per usual, pick a explicit port or have a random one.

public MulticastSocket() throws SocketException

public MulticastSocket(int port) throws SocketException

public MulticastSocket(SocketAddress bindAddress) throws IOException

A example:

MulticastSocket ms1 = new MulticastSocket();
MulticastSocket ms2 = new MulticastSocket(4000);

SocketAddress address = new InetSocketAddress("192.168.254.32", 4000);
MulticastSocket ms3 = new MulticastSocket(address);

A MultiCastSocket is a datagram socket as fr as the OS cares. Thus, it cannot
inhabit the same port as one, if one exists and vice versa.

We can pass null to the constructor to not have it bind and put options on it:

MulticastSocket ms = new MulticastSocket(null);
ms.setReuseAddress(false);
SocketAddress address = new InetSocketAddress(4000);
ms.bind(address);

Communicating with a Multicast Group:

A multicast socket can do 4 things:

JOin a multicast group

Send data to the members of said group

receive data from the group

Leave the multicast group

The retreievel and writing is just the same as for Datagrams.

JOining Groups:

public void joinGroup(InetAddress address) throws IOException

public void joinGroup(SocketAddress address, NetworkInterface interface) throws IOException

An example of receiving:

try{
	MulticastSocket ms = new MulticastSocket(4000);
	InetAddress ia = InetAddress.getByName("224.2.2.2");
	ms.joinGroup(ia);

	byte[] buffer = new byte[8192];
	while (true){
		DatagramPacket dp = new DatagramPacket(buffer, buffer.length);
		ms.receive(dp);

		String s = new String(dp.getData(), "8859_1");
		System.out.println(s);
	}
} catch (IOException ex){
	System.err.println(ex);
}

If the address is not am ulticast (ie not between 224.0.0.0 and 239.255.255.255), the joinGroup() throws
an IOException.

Multicast sockets can join several multicast groups. There is no limit to sockets on the same machine either,
if all the sockets subscribe to the same network they all get a copy of the same data.

We can join groups based on network interfaces names as well:

MulticastSocket ms = new MulticastSocket();
SocketAddress group = new InetSocketAddress("224.2.2.2", 40);

NetworkInterface ni = NetworkInterface.getByName("eth0");
if (ni != null){ //join the group at the specified network interface
	ms.joinGroup(group, ni);
} else { //Otherwise, just try to join the group on all interfaces
	ms.joinGroup(group);
}

Leaving groups and closing connections:

Just use try with resources.

public void leaveGroup(InetAddress address) throws IOException

public void leaveGroup(SocketAddress multicastAddress, NetworkInterface interface) throws IOException

try(MulticastSocket socket = new MulticastSocket()){
	//Connect to the server
} catch (IOException ex){
	ex.printStackTrace();
}

Sending multicast data:

Same as per usual. Albeit, you can set the TTL. It defauls to 1

try{
	InetAddress ia = InetAddress.getByName("experiment.mcast.net");
	byte[] data = "Here's some multicast data\r\n".getBytes();
	int port = 4000;

	DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);
	MulticastSocket ms = new MulticastSocket();

	ms.send(dp);
} catch (IOException ex){
	System.err.println(ex);
}

We can change the TTL of ai nviidual package by passing a int as the first arg to the constructor..

An example of setting the default value: //There exists a getter as well for this, getTimeToLive()

try{
	InetAddress ia = InetAddress.getByName("experiment.cast.net");
	byte[] data = "Here's some multicast data\r\n".getBytes();
	int port = 4000;

	DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);
	MulticastSocket ms = new MulticastSocket();

	ms.setTimeToLive(64);
	ms.send(dp);
} catch (IOException ex){
	System.err.println(ex);
}

Loopback Mode:

Depending on platform, we might have loopback of packages sent or not.

Getters and setters:

NOTE: THey work as hints, not written in stone

public void setLoopbackMode(boolean disable) throws SocketException

public boolean getLoopbackMode() throws SocketException //Returns true if not looping back, false otehrwise

Network Interfaces:

We can define the interface doing the multicasting:

public void setInterface(InetAddress address) throws SocketException

public InetAddress getInterface() throws SocketException

public void setNetworkInterface(NetworkInterface interface) throws SocketException

public NetworkInterface getNetworkInterface() throws SocketException

The interface works on basis of name giving, not IP. 
Set it instantly after assining the Address:

try{
	InetAddress ia = InetAddress.getByName("www.ibilio.org");
	MulticastSocket ms = new MulticastSocket(2048);
	ms.setInterface(ia);
	//Send and receive data
} catch (UnkonwnHostException ue){
	System.err.println(ue);
} catch (SocketException se){
	System.err.println(se);
}

To get the network interaface of a socket:

NetworkInterface intf = ms.getNetworkInterface();
System.out.println(intf.getName());

If none has been set, it returns a PH object with "0.0.0.0" and index -1.

Most multicast data is binary and won't be intellible when read.

The following is a Multicast sniffer example: //basically reads that you are getting stuff from am ulticast

//imports

public class MulticastSniffer{
	public static void main(String[] args){
		InetAddress group = null;
		int port = 0;

		//Read the address from CMD line
		try{
			group = InetAddress.getByName(args[0]);
			port = Integer.parseInt(args[1]);
		} catch (ArrayIndexOutOfBoundsException | NumberFormatException | UnknownHostExcetpion ex){
			System.err.println("Usage: java multicastsniffer multicast_address port");
			System.exit(1);
		}

		MulticastSocket ms = null;
		try{
			ms = new MulticastSocket(port);
			ms.joinGroup(group);

			byte[] buffer = new Byte[8192];
			while (true){
				DatagramPacket dp = new DatagramPacket(buffer, buffer.length);
				ms.receive(dp);

				String s = new String(dp.getData(), "8859_1");
				System.out.println(s);
			}
		} catch (IOException ex){
			System.err.println(ex);
		} finally {
			if (ms != null){
				try{
					ms.leaveGroup(group);
					ms.close();
				} catch (IOException ex){}
			}
		}
	}
}

Most multicasting things will only tell when they connect or query stuff.
Others might send more often.

The second example, is a Multicasting sender:

//imports

public class MulticastSender{
	public static void main(String[] args){
		InetAddress ia = null;
		int port = 0;
		byte ttl = (byte) 1;

		//Read the address from teh CMD line
		try{
			ia = InetAddress.getByName(args[0]);
			port = Integer.parseInt(args[1]);

			if(args.length > 2) ttl = (byte) Integer.parseInt(args[2]);
		} catch (NumberFormatException | IndexOutOfBoundsException | UnknownHostException ex){
			System.err.println(ex);
			System.err.println("Usage java Multicastsender multicast_address port ttl");
			System.exit(1);
		}

		byte[] data = "Here's some multicast data\r\n".getBytes();
		DatagramPacket dp = new DatagramPacket(data, data.length, ia, port);

		try(MulticastSocket ms = new MulticastSocket()){
			ms.setTimeToLive(ttl);
			ms.joinGroup(ia);

			for(int i = 1; i < 10; i++){
				ms.send(dp);
			}

			ms.leaveGroup(ia);
		} catch (SocketException ex){
			System.err.println(ex);
		} catch (IOExcetpion ex){
			System.err.println(ex);
		}
	}
}


The above example just sends data to a specified Multicast network and can
have its stuff sent to other stuff on that network, and assumes that they have Multicast Routers,
and that the routers between them have multicast enables.